{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDWOriL7QMnUU3F4aRhL5r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patero22/GNN-Reaserch_project/blob/main/Message_passing_and_peak_memory_updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e57kSve1reG7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddfbe8fa-09f7-4d94-9105-ae2bb4064742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1) (12.5.82)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1) (1.3.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: dgl==2.1.0 in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (3.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (4.66.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (5.9.5)\n",
            "Requirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (0.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==2.1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==2.1.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==2.1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==2.1.0) (2024.7.4)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.5.0->dgl==2.1.0) (2.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (1.13.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl==2.1.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata>=0.5.0->dgl==2.1.0) (1.3.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: memory-profiler in /usr/local/lib/python3.10/dist-packages (0.61.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory-profiler) (5.9.5)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.2.1 torchvision torchaudio\n",
        "!pip install torch-geometric\n",
        "!pip install dgl==2.1.0\n",
        "!pip install memory-profiler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install  dgl -f https://data.dgl.ai/wheels/torch-2.3/cu121/repo.html"
      ],
      "metadata": {
        "id": "rcZ1dTupsjtN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# torch.utils.data.datapipes.utils.common.DILL_AVAILABLE = torch.utils._import_utils.dill_available()\n",
        "# import torchdata"
      ],
      "metadata": {
        "id": "Xg73b3xPtM-3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ImportError: cannot import name 'DILL_AVAILABLE' from 'torch.utils.data.datapipes.utils.common' (/usr/local/lib/python3.10/dist-packages/torch/utils/data/datapipes/utils/common.py)\n"
      ],
      "metadata": {
        "id": "m52bPfyisrMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, PNAConv\n",
        "from dgl.nn.pytorch import GraphConv, GATConv as GATConvDGL, SAGEConv as SAGEConvDGL"
      ],
      "metadata": {
        "id": "cLfDvwOUrkHn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Models (GCN, GAT, GraphSAGE, PNA)"
      ],
      "metadata": {
        "id": "5O1LHCBfsKMy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyG Models"
      ],
      "metadata": {
        "id": "HfgeND5fuuqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 16)\n",
        "        self.conv2 = GCNConv(16, out_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GAT, self).__init__()\n",
        "        self.conv1 = GATConv(in_channels, 8, heads=8)\n",
        "        self.conv2 = GATConv(8*8, out_channels, heads=1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, 16)\n",
        "        self.conv2 = SAGEConv(16, out_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class PNA(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(PNA, self).__init__()\n",
        "        aggregators = ['mean', 'min', 'max', 'std']\n",
        "        scalers = ['identity', 'amplification', 'attenuation']\n",
        "        self.conv1 = PNAConv(in_channels, 16, aggregators, scalers)\n",
        "        self.conv2 = PNAConv(16, out_channels, aggregators, scalers)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "yf2ls6INuzF0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DGL Models"
      ],
      "metadata": {
        "id": "YS6graJVu3BX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_feats, out_feats):\n",
        "        super(GCN_DGL, self).__init__()\n",
        "        self.conv1 = GraphConv(in_feats, 16)\n",
        "        self.conv2 = GraphConv(16, out_feats)\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(g, x)\n",
        "        return x\n",
        "\n",
        "class GAT_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_feats, out_feats):\n",
        "        super(GAT_DGL, self).__init__()\n",
        "        self.conv1 = GATConvDGL(in_feats, 8, num_heads=8)\n",
        "        self.conv2 = GATConvDGL(8*8, out_feats, num_heads=1)\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(g, x)\n",
        "        return x\n",
        "\n",
        "class GraphSAGE_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_feats, out_feats):\n",
        "        super(GraphSAGE_DGL, self).__init__()\n",
        "        self.conv1 = SAGEConvDGL(in_feats, 16, 'mean')\n",
        "        self.conv2 = SAGEConvDGL(16, out_feats, 'mean')\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(g, x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "l6wgM7TLu5Ng"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Functions for COO and CSR Message Passing\n",
        "\n",
        "For COO and CSR message passing, we'll leverage scipy for conversion and torch-sparse for COO operations."
      ],
      "metadata": {
        "id": "hOhT94uOu8JM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import coo_matrix, csr_matrix\n",
        "\n",
        "# Conversion Functions\n",
        "def convert_to_coo(edge_index, num_nodes):\n",
        "    row, col = edge_index\n",
        "    data = torch.ones(row.size(0))\n",
        "    coo = coo_matrix((data.numpy(), (row.numpy(), col.numpy())), shape=(num_nodes, num_nodes))\n",
        "    return coo\n",
        "\n",
        "def convert_to_csr(edge_index, num_nodes):\n",
        "    row, col = edge_index\n",
        "    data = torch.ones(row.size(0))\n",
        "    csr = csr_matrix((data.numpy(), (row.numpy(), col.numpy())), shape=(num_nodes, num_nodes))\n",
        "    return csr"
      ],
      "metadata": {
        "id": "R-uGYhjyvD_J"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Profiling Function"
      ],
      "metadata": {
        "id": "sF_Qo1EawMNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Profiling Function\n",
        "from memory_profiler import memory_usage\n",
        "import time\n",
        "\n",
        "def profile_model(model, data, device, dgl=False, format='coo'):\n",
        "    data = data.to(device)\n",
        "    model = model.to(device)\n",
        "\n",
        "    def forward_pass():\n",
        "        if dgl:\n",
        "            model(data, data.ndata['feat'])\n",
        "        else:\n",
        "            model(data)\n",
        "\n",
        "    # Measure time\n",
        "    start_time = time.time()\n",
        "    for _ in range(100):\n",
        "        forward_pass()\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Measure peak memory usage\n",
        "    mem_usage = memory_usage(forward_pass, interval=0.1)\n",
        "\n",
        "    return (end_time - start_time) / 100, max(mem_usage)"
      ],
      "metadata": {
        "id": "Kcn-heVRwRzk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Datasets (Karate Club and Citeseer)"
      ],
      "metadata": {
        "id": "DLhmuWPiwZaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import KarateClub, Planetoid\n",
        "from dgl.data import KarateClubDataset, CiteseerGraphDataset"
      ],
      "metadata": {
        "id": "MwEVACsqwfNM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load PyG Datasets\n",
        "dataset_karate_pyg = KarateClub()\n",
        "data_karate_pyg = dataset_karate_pyg[0]\n",
        "\n",
        "dataset_citeseer_pyg = Planetoid(root='data/Citeseer', name='Citeseer')\n",
        "data_citeseer_pyg = dataset_citeseer_pyg[0]"
      ],
      "metadata": {
        "id": "xfwxXSsswgZ2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load DGL Datasets\n",
        "def load_karate_dgl():\n",
        "    dataset = KarateClubDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "def load_citeseer_dgl():\n",
        "    dataset = CiteseerGraphDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "graph_karate_dgl = load_karate_dgl()\n",
        "graph_citeseer_dgl = load_citeseer_dgl()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKAD2-mjwlur",
        "outputId": "c0f559a8-5c92-4dee-e2bc-2fa7627eb660"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Models with COO and CSR on CPU and GPU"
      ],
      "metadata": {
        "id": "7CvDNY88woUM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define devices"
      ],
      "metadata": {
        "id": "Bl-4O69hw3PI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "TclZ_ZdZw6ZP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test GCN on CPU and GPU for PyG Karate ClubB"
      ],
      "metadata": {
        "id": "TKpJPlFNw8X8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_model_pyg = GCN(dataset_karate_pyg.num_features, dataset_karate_pyg.num_classes)\n",
        "time_cpu, mem_cpu = profile_model(gcn_model_pyg, data_karate_pyg, device_cpu, format='coo')\n",
        "time_gpu, mem_gpu = profile_model(gcn_model_pyg, data_karate_pyg, device_gpu, format='coo')\n",
        "print(f'PyG Karate Club GCN on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "print(f'PyG Karate Club GCN on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnZNIRzCxA-w",
        "outputId": "d93e5516-1645-45c8-fd55-c5e9a7d358dc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyG Karate Club GCN on CPU: 0.005395 seconds per iteration, 728.23 MB peak memory\n",
            "PyG Karate Club GCN on GPU: 0.002583 seconds per iteration, 728.40 MB peak memory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test GCN on CPU and GPU for PyG Citeseer"
      ],
      "metadata": {
        "id": "SG8-Gyq1xD8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_model_pyg = GCN(dataset_citeseer_pyg.num_features, dataset_citeseer_pyg.num_classes)\n",
        "time_cpu, mem_cpu = profile_model(gcn_model_pyg, data_citeseer_pyg, device_cpu, format='csr')\n",
        "time_gpu, mem_gpu = profile_model(gcn_model_pyg, data_citeseer_pyg, device_gpu, format='csr')\n",
        "print(f'PyG Citeseer GCN on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "print(f'PyG Citeseer GCN on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA1BpiguxLEH",
        "outputId": "b8408860-3492-4877-92b8-27dc6e9c3b94"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyG Citeseer GCN on CPU: 0.037767 seconds per iteration, 732.36 MB peak memory\n",
            "PyG Citeseer GCN on GPU: 0.049320 seconds per iteration, 732.62 MB peak memory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test GCN on CPU and GPU for DGL Karate Club"
      ],
      "metadata": {
        "id": "g8Ohm2YZxNCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`feat` error solver -v"
      ],
      "metadata": {
        "id": "_30haT4xyOnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Karate Club dataset\n",
        "dataset_karate_dgl = KarateClubDataset()\n",
        "graph_karate_dgl = dataset_karate_dgl[0]\n",
        "\n",
        "# Add dummy features (e.g., use one-hot encoding for simplicity)\n",
        "num_nodes = graph_karate_dgl.num_nodes()\n",
        "graph_karate_dgl.ndata['feat'] = torch.eye(num_nodes)\n",
        "\n",
        "# Add labels\n",
        "graph_karate_dgl.ndata['label'] = torch.tensor(graph_karate_dgl.ndata['label'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaOYF3EwyD6Q",
        "outputId": "236d2403-a9cf-406e-911a-bedb821f4731"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-5a57f9503770>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  graph_karate_dgl.ndata['label'] = torch.tensor(graph_karate_dgl.ndata['label'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_model_dgl = GCN_DGL(graph_karate_dgl.ndata['feat'].shape[1], graph_karate_dgl.ndata['label'].max().item() + 1)\n",
        "time_cpu, mem_cpu = profile_model(gcn_model_dgl, graph_karate_dgl, device_cpu, dgl=True, format='coo')\n",
        "time_gpu, mem_gpu = profile_model(gcn_model_dgl, graph_karate_dgl, device_gpu, dgl=True, format='coo')\n",
        "print(f'DGL Karate Club GCN on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "print(f'DGL Karate Club GCN on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWygavUzxUk1",
        "outputId": "e56cf2b1-0a6b-4c6d-a68f-75c0920f5f82"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DGL Karate Club GCN on CPU: 0.004457 seconds per iteration, 735.27 MB peak memory\n",
            "DGL Karate Club GCN on GPU: 0.005188 seconds per iteration, 735.27 MB peak memory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test GCN on CPU and GPU for DGL Citeseer"
      ],
      "metadata": {
        "id": "j16XGpR7xZo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_model_dgl = GCN_DGL(graph_citeseer_dgl.ndata['feat'].shape[1], graph_citeseer_dgl.ndata['label'].max().item() + 1)\n",
        "time_cpu, mem_cpu = profile_model(gcn_model_dgl, graph_citeseer_dgl, device_cpu, dgl=True, format='csr')\n",
        "time_gpu, mem_gpu = profile_model(gcn_model_dgl, graph_citeseer_dgl, device_gpu, dgl=True, format='csr')\n",
        "print(f'DGL Citeseer GCN on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "print(f'DGL Citeseer GCN on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niT3DJBsyeUV",
        "outputId": "af415ff1-1248-404c-b501-21257d1b308a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DGL Citeseer GCN on CPU: 0.116792 seconds per iteration, 782.54 MB peak memory\n",
            "DGL Citeseer GCN on GPU: 0.057592 seconds per iteration, 782.58 MB peak memory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "C6FNIdooz1mB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More coplex datasets"
      ],
      "metadata": {
        "id": "T9heMbv6yg_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Complex Datasets and Profiling\n",
        "Define Profiling Function"
      ],
      "metadata": {
        "id": "s8Wl1xB4z0up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def profile_model(model, data, device, dgl=False, format='coo'):\n",
        "    model = model.to(device)\n",
        "    data = data.to(device)\n",
        "\n",
        "    def run_model():\n",
        "        model.train()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "        for _ in range(1):  # Run for one epoch to measure time\n",
        "            optimizer.zero_grad()\n",
        "            if dgl:\n",
        "                if format == 'csr':\n",
        "                    logits = model(data, data.ndata['feat'])\n",
        "                else:\n",
        "                    logits = model(data, data.ndata['feat'])\n",
        "            else:\n",
        "                logits = model(data)\n",
        "            loss = F.cross_entropy(logits[data.y_index], data.y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Measure time\n",
        "    start_time = time.time()\n",
        "    run_model()\n",
        "    end_time = time.time()\n",
        "    time_taken = end_time - start_time\n",
        "\n",
        "    # Measure memory\n",
        "    mem_usage = memory_usage(run_model, max_usage=True, retval=False)\n",
        "    peak_memory = max(mem_usage)\n",
        "\n",
        "    return time_taken, peak_memory"
      ],
      "metadata": {
        "id": "tzO6MQiFz6tS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Complex Datasets"
      ],
      "metadata": {
        "id": "stnNJsyuPwdR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load PyG Datasets"
      ],
      "metadata": {
        "id": "xJgdsgUuQRe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import Reddit, Amazon"
      ],
      "metadata": {
        "id": "eOf49A9WP3Vr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_reddit_pyg = Reddit(root='/tmp/Reddit')\n",
        "data_reddit_pyg = dataset_reddit_pyg[0]\n",
        "\n",
        "dataset_amazon_pyg = Amazon(root='/tmp/Amazon', name='Computers')\n",
        "data_amazon_pyg = dataset_amazon_pyg[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "m8j8CWSZP7Hf",
        "outputId": "5617a6a1-39d2-4fb9-e383-eb45401193ce"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-e6be4f71c878>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset_reddit_pyg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReddit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/tmp/Reddit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_reddit_pyg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_reddit_pyg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset_amazon_pyg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAmazon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/tmp/Amazon'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Computers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata_amazon_pyg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_amazon_pyg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/datasets/reddit.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform, force_reload)\u001b[0m\n\u001b[1;32m     61\u001b[0m         super().__init__(root, transform, pre_transform,\n\u001b[1;32m     62\u001b[0m                          force_reload=force_reload)\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/in_memory_dataset.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path, data_cls)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBaseData\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;34mr\"\"\"Loads the dataset from the file path :obj:`path`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/io/fs.py\u001b[0m in \u001b[0;36mtorch_load\u001b[0;34m(path, map_location)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtorch_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfsspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1024\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m                 return _load(opened_zipfile,\n\u001b[0m\u001b[1;32m   1027\u001b[0m                              \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m                              \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1408\u001b[0;31m             \u001b[0mtyped_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1371\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverall_storage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstorage_offset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstorage_offset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_untyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m         \u001b[0;31m# swap here if byteswapping is needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbyteorderdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load DGL Datasets"
      ],
      "metadata": {
        "id": "P_Z60L5OQZlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dgl.data import RedditDataset, AmazonCoBuyComputerDataset"
      ],
      "metadata": {
        "id": "NhPU8h1rQcrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_reddit_dgl():\n",
        "    dataset = RedditDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "def load_amazon_dgl():\n",
        "    dataset = AmazonCoBuyComputerDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "graph_reddit_dgl = load_reddit_dgl()\n",
        "graph_amazon_dgl = load_amazon_dgl()"
      ],
      "metadata": {
        "id": "zRe38T83QeOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Models on Complex Datasets"
      ],
      "metadata": {
        "id": "tVi6OyLeQkER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define devices\n",
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "y4UKYg6_QmOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define and test models"
      ],
      "metadata": {
        "id": "TSXvUKvGQpi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'GCN': (GCN, GCN_DGL),\n",
        "    'GAT': (GAT, GATConvDGL),\n",
        "    'GraphSAGE': (GraphSAGE, SAGEConvDGL),\n",
        "    'PNA': (PNA, PNAConv)\n",
        "}\n",
        "\n",
        "datasets_pyg = {\n",
        "    'Reddit': data_reddit_pyg,\n",
        "    'Amazon': data_amazon_pyg\n",
        "}\n",
        "\n",
        "datasets_dgl = {\n",
        "    'Reddit': graph_reddit_dgl,\n",
        "    'Amazon': graph_amazon_dgl\n",
        "}"
      ],
      "metadata": {
        "id": "EyP3KR5UQsI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, (ModelPyG, ModelDGL) in models.items():\n",
        "    for dataset_name, data_pyg in datasets_pyg.items():\n",
        "        # PyG Models\n",
        "        model_pyg = ModelPyG(data_pyg.num_features, data_pyg.num_classes)\n",
        "        time_cpu, mem_cpu = profile_model(model_pyg, data_pyg, device_cpu, format='coo')\n",
        "        time_gpu, mem_gpu = profile_model(model_pyg, data_pyg, device_gpu, format='coo')\n",
        "        print(f'PyG {dataset_name} {model_name} on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "        print(f'PyG {dataset_name} {model_name} on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n",
        "\n",
        "    for dataset_name, graph_dgl in datasets_dgl.items():\n",
        "        # DGL Models\n",
        "        model_dgl = ModelDGL(graph_dgl.ndata['feat'].shape[1], graph_dgl.ndata['label'].max().item() + 1)\n",
        "        time_cpu, mem_cpu = profile_model(model_dgl, graph_dgl, device_cpu, dgl=True, format='coo')\n",
        "        time_gpu, mem_gpu = profile_model(model_dgl, graph_dgl, device_gpu, dgl=True, format='coo')\n",
        "        print(f'DGL {dataset_name} {model_name} on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "        print(f'DGL {dataset_name} {model_name} on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')"
      ],
      "metadata": {
        "id": "u0pnOONpQvPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ERROR : Your session crashed after using all available RAM"
      ],
      "metadata": {
        "id": "LMmkbIwST5PL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intermediate Complexity Datasets"
      ],
      "metadata": {
        "id": "0tMEurshUask"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Intermediate Complexity Datasets"
      ],
      "metadata": {
        "id": "KvMgph9BUiug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "from dgl.data import CoraGraphDataset, PubmedGraphDataset, CiteseerGraphDataset\n",
        "\n",
        "# Load PyG Datasets\n",
        "dataset_cora_pyg = Planetoid(root='/tmp/Cora', name='Cora')\n",
        "data_cora_pyg = dataset_cora_pyg[0]\n",
        "\n",
        "dataset_pubmed_pyg = Planetoid(root='/tmp/Pubmed', name='Pubmed')\n",
        "data_pubmed_pyg = dataset_pubmed_pyg[0]\n",
        "\n",
        "dataset_citeseer_pyg = Planetoid(root='/tmp/Citeseer', name='Citeseer')\n",
        "data_citeseer_pyg = dataset_citeseer_pyg[0]\n",
        "\n",
        "# Load DGL Datasets\n",
        "def load_cora_dgl():\n",
        "    dataset = CoraGraphDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "def load_pubmed_dgl():\n",
        "    dataset = PubmedGraphDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "def load_citeseer_dgl():\n",
        "    dataset = CiteseerGraphDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "graph_cora_dgl = load_cora_dgl()\n",
        "graph_pubmed_dgl = load_pubmed_dgl()\n",
        "graph_citeseer_dgl = load_citeseer_dgl()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUwXlZpKUj5X",
        "outputId": "a44c6833-6f06-4d8f-e4ba-2c2ca4fd7166"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n",
            "  NumNodes: 19717\n",
            "  NumEdges: 88651\n",
            "  NumFeats: 500\n",
            "  NumClasses: 3\n",
            "  NumTrainingSamples: 60\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Models on Intermediate Datasets"
      ],
      "metadata": {
        "id": "5AeZ-5-aVL0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define devices\n",
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define and test models\n",
        "models = {\n",
        "    'GCN': (GCN, GCN_DGL),\n",
        "    'GAT': (GAT, GATConvDGL),\n",
        "    'GraphSAGE': (GraphSAGE, SAGEConvDGL),\n",
        "    'PNA': (PNA, PNAConv)\n",
        "}\n",
        "\n",
        "datasets_pyg = {\n",
        "    'Cora': data_cora_pyg,\n",
        "    'PubMed': data_pubmed_pyg,\n",
        "    'CiteSeer': data_citeseer_pyg\n",
        "}\n",
        "\n",
        "datasets_dgl = {\n",
        "    'Cora': graph_cora_dgl,\n",
        "    'PubMed': graph_pubmed_dgl,\n",
        "    'CiteSeer': graph_citeseer_dgl\n",
        "}\n",
        "\n",
        "for model_name, (ModelPyG, ModelDGL) in models.items():\n",
        "    for dataset_name, data_pyg in datasets_pyg.items():\n",
        "        # PyG Models\n",
        "        model_pyg = ModelPyG(data_pyg.num_features, data_pyg.num_classes)\n",
        "        time_cpu, mem_cpu = profile_model(model_pyg, data_pyg, device_cpu, format='coo')\n",
        "        time_gpu, mem_gpu = profile_model(model_pyg, data_pyg, device_gpu, format='coo')\n",
        "        print(f'PyG {dataset_name} {model_name} on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "        print(f'PyG {dataset_name} {model_name} on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n",
        "\n",
        "    for dataset_name, graph_dgl in datasets_dgl.items():\n",
        "        # DGL Models\n",
        "        model_dgl = ModelDGL(graph_dgl.ndata['feat'].shape[1], graph_dgl.ndata['label'].max().item() + 1)\n",
        "        time_cpu, mem_cpu = profile_model(model_dgl, graph_dgl, device_cpu, dgl=True, format='coo')\n",
        "        time_gpu, mem_gpu = profile_model(model_dgl, graph_dgl, device_gpu, dgl=True, format='coo')\n",
        "        print(f'DGL {dataset_name} {model_name} on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "        print(f'DGL {dataset_name} {model_name} on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "K0_fuc0RVNYj",
        "outputId": "6561738f-e359-4d22-ebad-0d62bbf98916"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'GlobalStorage' object has no attribute 'num_classes'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-3460f4bc3888>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_pyg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets_pyg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# PyG Models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mmodel_pyg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelPyG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_pyg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_pyg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mtime_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprofile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_pyg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_pyg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtime_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprofile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_pyg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_pyg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    557\u001b[0m                 \u001b[0;34m\"dataset, remove the 'processed/' directory in the dataset's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m                 \"root folder and try again.\")\n\u001b[0;32m--> 559\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_store\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/storage.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;34mf\"'{self.__class__.__name__}' object has no attribute '{key}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             ) from None\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'num_classes'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hb8LlkCjVRaZ"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}