{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPibB98vdA3XO0giLtLAuHX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patero22/GNN-Reaserch_project/blob/main/Message_passing_and_peak_memory_updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e57kSve1reG7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "058b4e57-bdb0-4047-a71a-e71d58ec67a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1) (12.5.82)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1) (1.3.0)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n",
            "Requirement already satisfied: dgl==2.1.0 in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (3.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (4.66.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (5.9.5)\n",
            "Requirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (0.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==2.1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==2.1.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==2.1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==2.1.0) (2024.7.4)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.5.0->dgl==2.1.0) (2.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (1.13.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl==2.1.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata>=0.5.0->dgl==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: memory-profiler in /usr/local/lib/python3.10/dist-packages (0.61.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory-profiler) (5.9.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.2.1 torchvision torchaudio\n",
        "!pip install torch-geometric\n",
        "!pip install dgl==2.1.0\n",
        "!pip install memory-profiler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install  dgl -f https://data.dgl.ai/wheels/torch-2.3/cu121/repo.html"
      ],
      "metadata": {
        "id": "rcZ1dTupsjtN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# torch.utils.data.datapipes.utils.common.DILL_AVAILABLE = torch.utils._import_utils.dill_available()\n",
        "# import torchdata"
      ],
      "metadata": {
        "id": "Xg73b3xPtM-3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ImportError: cannot import name 'DILL_AVAILABLE' from 'torch.utils.data.datapipes.utils.common' (/usr/local/lib/python3.10/dist-packages/torch/utils/data/datapipes/utils/common.py)\n"
      ],
      "metadata": {
        "id": "m52bPfyisrMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, PNAConv\n",
        "from dgl.nn.pytorch import GraphConv, GATConv as GATConvDGL, SAGEConv as SAGEConvDGL\n",
        "from dgl.nn import PNAConv"
      ],
      "metadata": {
        "id": "cLfDvwOUrkHn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Models (GCN, GAT, GraphSAGE, PNA)"
      ],
      "metadata": {
        "id": "5O1LHCBfsKMy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyG Models"
      ],
      "metadata": {
        "id": "HfgeND5fuuqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 16)\n",
        "        self.conv2 = GCNConv(16, out_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GAT, self).__init__()\n",
        "        self.conv1 = GATConv(in_channels, 8, heads=8)\n",
        "        self.conv2 = GATConv(8*8, out_channels, heads=1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, 16)\n",
        "        self.conv2 = SAGEConv(16, out_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class PNA(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(PNA, self).__init__()\n",
        "        aggregators = ['mean', 'min', 'max', 'std']\n",
        "        scalers = ['identity', 'amplification', 'attenuation']\n",
        "        self.conv1 = PNAConv(in_channels, 16, aggregators, scalers)\n",
        "        self.conv2 = PNAConv(16, out_channels, aggregators, scalers)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "yf2ls6INuzF0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DGL Models"
      ],
      "metadata": {
        "id": "YS6graJVu3BX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_feats, out_feats):\n",
        "        super(GCN_DGL, self).__init__()\n",
        "        self.conv1 = GraphConv(in_feats, 16)\n",
        "        self.conv2 = GraphConv(16, out_feats)\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(g, x)\n",
        "        return x\n",
        "\n",
        "class GAT_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_feats, out_feats):\n",
        "        super(GAT_DGL, self).__init__()\n",
        "        self.conv1 = GATConvDGL(in_feats, 8, num_heads=8)\n",
        "        self.conv2 = GATConvDGL(8*8, out_feats, num_heads=1)\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(g, x)\n",
        "        return x\n",
        "\n",
        "class GraphSAGE_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_feats, out_feats):\n",
        "        super(GraphSAGE_DGL, self).__init__()\n",
        "        self.conv1 = SAGEConvDGL(in_feats, 16, 'mean')\n",
        "        self.conv2 = SAGEConvDGL(16, out_feats, 'mean')\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(g, x)\n",
        "        return x\n",
        "\n",
        "class PNA_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(PNA_DGL, self).__init__()\n",
        "        aggregators = ['mean', 'min', 'max', 'std']\n",
        "        scalers = ['identity', 'amplification', 'attenuation']\n",
        "        self.conv1 = PNAConv(in_channels, 16, aggregators, scalers)\n",
        "        self.conv2 = PNAConv(16, out_channels, aggregators, scalers)\n",
        "\n",
        "    def forward(self, graph):\n",
        "        x = graph.ndata['feat']\n",
        "        x = self.conv1(graph, x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(graph, x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "l6wgM7TLu5Ng"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Functions for COO and CSR Message Passing\n",
        "\n",
        "For COO and CSR message passing, we'll leverage scipy for conversion and torch-sparse for COO operations."
      ],
      "metadata": {
        "id": "hOhT94uOu8JM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import coo_matrix, csr_matrix\n",
        "\n",
        "# Conversion Functions\n",
        "def convert_to_coo(edge_index, num_nodes):\n",
        "    row, col = edge_index\n",
        "    data = torch.ones(row.size(0))\n",
        "    coo = coo_matrix((data.numpy(), (row.numpy(), col.numpy())), shape=(num_nodes, num_nodes))\n",
        "    return coo\n",
        "\n",
        "def convert_to_csr(edge_index, num_nodes):\n",
        "    row, col = edge_index\n",
        "    data = torch.ones(row.size(0))\n",
        "    csr = csr_matrix((data.numpy(), (row.numpy(), col.numpy())), shape=(num_nodes, num_nodes))\n",
        "    return csr"
      ],
      "metadata": {
        "id": "R-uGYhjyvD_J"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Profiling Function"
      ],
      "metadata": {
        "id": "sF_Qo1EawMNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Profiling Function\n",
        "from memory_profiler import memory_usage\n",
        "import time\n",
        "\n",
        "def profile_model(model, data, device, dgl=False, format='coo'):\n",
        "    data = data.to(device)\n",
        "    model = model.to(device)\n",
        "\n",
        "    def forward_pass():\n",
        "        if dgl:\n",
        "            model(data, data.ndata['feat'])\n",
        "        else:\n",
        "            model(data)\n",
        "\n",
        "    # Measure time\n",
        "    start_time = time.time()\n",
        "    for _ in range(100):\n",
        "        forward_pass()\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Measure peak memory usage\n",
        "    mem_usage = memory_usage(forward_pass, interval=0.1)\n",
        "\n",
        "    return (end_time - start_time) / 100, max(mem_usage)"
      ],
      "metadata": {
        "id": "Kcn-heVRwRzk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Datasets (Karate Club and Citeseer)"
      ],
      "metadata": {
        "id": "DLhmuWPiwZaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import KarateClub, Planetoid\n",
        "from dgl.data import KarateClubDataset, CiteseerGraphDataset"
      ],
      "metadata": {
        "id": "MwEVACsqwfNM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load PyG Datasets\n",
        "dataset_karate_pyg = KarateClub()\n",
        "data_karate_pyg = dataset_karate_pyg[0]\n",
        "\n",
        "dataset_citeseer_pyg = Planetoid(root='data/Citeseer', name='Citeseer')\n",
        "data_citeseer_pyg = dataset_citeseer_pyg[0]"
      ],
      "metadata": {
        "id": "xfwxXSsswgZ2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load DGL Datasets\n",
        "def load_karate_dgl():\n",
        "    dataset = KarateClubDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "def load_citeseer_dgl():\n",
        "    dataset = CiteseerGraphDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "graph_karate_dgl = load_karate_dgl()\n",
        "graph_citeseer_dgl = load_citeseer_dgl()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKAD2-mjwlur",
        "outputId": "96ba2f35-8e76-42b4-e1fd-b1cd04216274"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w9wXLUL5vFXD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KHs6gS4svGTv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data\n",
        "import dgl\n",
        "from dgl.nn.pytorch import GATConv as GATConvDGL, GraphConv, SAGEConv as SAGEConvDGL, PNAConv as PNAConvDGL\n",
        "\n",
        "# Define GAT model for PyG\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GAT, self).__init__()\n",
        "        self.conv1 = torch_geometric.nn.GATConv(in_channels, 8, heads=8)\n",
        "        self.conv2 = torch_geometric.nn.GATConv(8 * 8, out_channels, heads=1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Define GAT model for DGL\n",
        "class GAT_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GAT_DGL, self).__init__()\n",
        "        self.conv1 = GATConvDGL(in_channels, 8, num_heads=8)\n",
        "        self.conv2 = GATConvDGL(8 * 8, out_channels, num_heads=1)\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features).flatten(1)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(g, x).mean(1)\n",
        "        return x\n",
        "\n",
        "# Define GraphSAGE model for PyG\n",
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = torch_geometric.nn.SAGEConv(in_channels, 16, aggr='mean')\n",
        "        self.conv2 = torch_geometric.nn.SAGEConv(16, out_channels, aggr='mean')\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Define GraphSAGE model for DGL\n",
        "class GraphSAGE_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GraphSAGE_DGL, self).__init__()\n",
        "        self.conv1 = SAGEConvDGL(in_channels, 16, aggregator_type='mean')\n",
        "        self.conv2 = SAGEConvDGL(16, out_channels, aggregator_type='mean')\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(g, x)\n",
        "        return x\n",
        "\n",
        "# Define PNA model for PyG\n",
        "class PNA(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, deg):\n",
        "        super(PNA, self).__init__()\n",
        "        self.conv1 = torch_geometric.nn.PNAConv(in_channels, 16, aggregators=['mean', 'max', 'min'], scalers=['identity'], deg=deg)\n",
        "        self.conv2 = torch_geometric.nn.PNAConv(16, out_channels, aggregators=['mean', 'max', 'min'], scalers=['identity'], deg=deg)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Define PNA model for DGL\n",
        "class PNA_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(PNA_DGL, self).__init__()\n",
        "        self.conv1 = PNAConvDGL(in_channels, 16)\n",
        "        self.conv2 = PNAConvDGL(16, out_channels)\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(g, x)\n",
        "        return x\n",
        "\n",
        "# Ensure features and labels are set for DGL graphs\n",
        "def ensure_dgl_features_and_labels(graph, pyg_data):\n",
        "    graph.ndata['feat'] = pyg_data.x.clone().detach()\n",
        "    graph.ndata['label'] = pyg_data.y.clone().detach()\n",
        "    return graph\n",
        "\n",
        "graph_karate_dgl = ensure_dgl_features_and_labels(graph_karate_dgl, data_karate_pyg)\n",
        "graph_citeseer_dgl = ensure_dgl_features_and_labels(graph_citeseer_dgl, data_citeseer_pyg)\n",
        "\n",
        "# Define devices\n",
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define and test models on COO and CSR formats\n",
        "formats = ['coo', 'csr']\n",
        "models = {\n",
        "    'GCN': (GCN, GCN_DGL),\n",
        "    'GAT': (GAT, GAT_DGL),\n",
        "    'GraphSAGE': (GraphSAGE, GraphSAGE_DGL),\n",
        "    'PNA': (PNA, PNA_DGL)\n",
        "}\n",
        "\n",
        "datasets_pyg = {\n",
        "    'Karate Club': (dataset_karate_pyg, data_karate_pyg),\n",
        "    'Citeseer': (dataset_citeseer_pyg, data_citeseer_pyg)\n",
        "}\n",
        "\n",
        "datasets_dgl = {\n",
        "    'Karate Club': graph_karate_dgl,\n",
        "    'Citeseer': graph_citeseer_dgl\n",
        "}\n",
        "\n",
        "for model_name, (ModelPyG, ModelDGL) in models.items():\n",
        "    for dataset_name, (dataset_pyg, data_pyg) in datasets_pyg.items():\n",
        "        # Calculate degree tensor for PyG PNA model\n",
        "        if model_name == 'PNA':\n",
        "            deg = torch_geometric.utils.degree(data_pyg.edge_index[0], data_pyg.num_nodes).float()\n",
        "        for fmt in formats:\n",
        "            if model_name == 'PNA':\n",
        "                model_pyg = ModelPyG(dataset_pyg.num_features, dataset_pyg.num_classes, deg=deg)\n",
        "            else:\n",
        "                model_pyg = ModelPyG(dataset_pyg.num_features, dataset_pyg.num_classes)\n",
        "            time_cpu, mem_cpu = profile_model(model_pyg, data_pyg, device_cpu, format=fmt)\n",
        "            time_gpu, mem_gpu = profile_model(model_pyg, data_pyg, device_gpu, format=fmt)\n",
        "            print(f'PyG {dataset_name} {model_name} ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "            print(f'PyG {dataset_name} {model_name} ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n",
        "\n",
        "    for dataset_name, graph_dgl in datasets_dgl.items():\n",
        "        for fmt in formats:\n",
        "            input_dim = graph_dgl.ndata['feat'].shape[1]\n",
        "            output_dim = graph_dgl.ndata['label'].max().item() + 1\n",
        "            model_dgl = ModelDGL(input_dim, output_dim)\n",
        "            time_cpu, mem_cpu = profile_model(model_dgl, graph_dgl, device_cpu, dgl=True, format=fmt)\n",
        "            time_gpu, mem_gpu = profile_model(model_dgl, graph_dgl, device_gpu, dgl=True, format=fmt)\n",
        "            print(f'DGL {dataset_name} {model_name} ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "            print(f'DGL {dataset_name} {model_name} ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n"
      ],
      "metadata": {
        "id": "VYpLk2fou8GO",
        "outputId": "16b1b816-96f1-455e-8e72-fcbee99f5545",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyG Karate Club GCN (COO) on CPU: 0.004552 seconds per iteration, 750.07 MB peak memory\n",
            "PyG Karate Club GCN (COO) on GPU: 0.003334 seconds per iteration, 750.07 MB peak memory\n",
            "PyG Karate Club GCN (CSR) on CPU: 0.004868 seconds per iteration, 750.07 MB peak memory\n",
            "PyG Karate Club GCN (CSR) on GPU: 0.002522 seconds per iteration, 750.07 MB peak memory\n",
            "PyG Citeseer GCN (COO) on CPU: 0.031435 seconds per iteration, 750.07 MB peak memory\n",
            "PyG Citeseer GCN (COO) on GPU: 0.018954 seconds per iteration, 750.07 MB peak memory\n",
            "PyG Citeseer GCN (CSR) on CPU: 0.018596 seconds per iteration, 750.07 MB peak memory\n",
            "PyG Citeseer GCN (CSR) on GPU: 0.018586 seconds per iteration, 750.07 MB peak memory\n",
            "DGL Karate Club GCN (COO) on CPU: 0.003319 seconds per iteration, 750.14 MB peak memory\n",
            "DGL Karate Club GCN (COO) on GPU: 0.003041 seconds per iteration, 750.14 MB peak memory\n",
            "DGL Karate Club GCN (CSR) on CPU: 0.003578 seconds per iteration, 750.14 MB peak memory\n",
            "DGL Karate Club GCN (CSR) on GPU: 0.003509 seconds per iteration, 750.14 MB peak memory\n",
            "DGL Citeseer GCN (COO) on CPU: 0.058810 seconds per iteration, 797.14 MB peak memory\n",
            "DGL Citeseer GCN (COO) on GPU: 0.066025 seconds per iteration, 797.14 MB peak memory\n",
            "DGL Citeseer GCN (CSR) on CPU: 0.058981 seconds per iteration, 797.14 MB peak memory\n",
            "DGL Citeseer GCN (CSR) on GPU: 0.076830 seconds per iteration, 797.14 MB peak memory\n",
            "PyG Karate Club GAT (COO) on CPU: 0.001989 seconds per iteration, 750.14 MB peak memory\n",
            "PyG Karate Club GAT (COO) on GPU: 0.001972 seconds per iteration, 750.14 MB peak memory\n",
            "PyG Karate Club GAT (CSR) on CPU: 0.001870 seconds per iteration, 750.14 MB peak memory\n",
            "PyG Karate Club GAT (CSR) on GPU: 0.002062 seconds per iteration, 750.14 MB peak memory\n",
            "PyG Citeseer GAT (COO) on CPU: 0.056092 seconds per iteration, 753.78 MB peak memory\n",
            "PyG Citeseer GAT (COO) on GPU: 0.067704 seconds per iteration, 753.72 MB peak memory\n",
            "PyG Citeseer GAT (CSR) on CPU: 0.055529 seconds per iteration, 753.43 MB peak memory\n",
            "PyG Citeseer GAT (CSR) on GPU: 0.066521 seconds per iteration, 753.81 MB peak memory\n",
            "DGL Karate Club GAT (COO) on CPU: 0.003063 seconds per iteration, 746.68 MB peak memory\n",
            "DGL Karate Club GAT (COO) on GPU: 0.002826 seconds per iteration, 746.68 MB peak memory\n",
            "DGL Karate Club GAT (CSR) on CPU: 0.002959 seconds per iteration, 746.68 MB peak memory\n",
            "DGL Karate Club GAT (CSR) on GPU: 0.002771 seconds per iteration, 746.68 MB peak memory\n",
            "DGL Citeseer GAT (COO) on CPU: 0.051185 seconds per iteration, 751.86 MB peak memory\n",
            "DGL Citeseer GAT (COO) on GPU: 0.063503 seconds per iteration, 751.86 MB peak memory\n",
            "DGL Citeseer GAT (CSR) on CPU: 0.051554 seconds per iteration, 754.30 MB peak memory\n",
            "DGL Citeseer GAT (CSR) on GPU: 0.058901 seconds per iteration, 754.30 MB peak memory\n",
            "PyG Karate Club GraphSAGE (COO) on CPU: 0.000890 seconds per iteration, 754.30 MB peak memory\n",
            "PyG Karate Club GraphSAGE (COO) on GPU: 0.000644 seconds per iteration, 754.30 MB peak memory\n",
            "PyG Karate Club GraphSAGE (CSR) on CPU: 0.000611 seconds per iteration, 754.30 MB peak memory\n",
            "PyG Karate Club GraphSAGE (CSR) on GPU: 0.000705 seconds per iteration, 754.30 MB peak memory\n",
            "PyG Citeseer GraphSAGE (COO) on CPU: 0.254456 seconds per iteration, 879.79 MB peak memory\n",
            "PyG Citeseer GraphSAGE (COO) on GPU: 0.290937 seconds per iteration, 892.02 MB peak memory\n",
            "PyG Citeseer GraphSAGE (CSR) on CPU: 0.251612 seconds per iteration, 882.71 MB peak memory\n",
            "PyG Citeseer GraphSAGE (CSR) on GPU: 0.251087 seconds per iteration, 879.72 MB peak memory\n",
            "DGL Karate Club GraphSAGE (COO) on CPU: 0.001717 seconds per iteration, 754.30 MB peak memory\n",
            "DGL Karate Club GraphSAGE (COO) on GPU: 0.001470 seconds per iteration, 754.30 MB peak memory\n",
            "DGL Karate Club GraphSAGE (CSR) on CPU: 0.001489 seconds per iteration, 754.30 MB peak memory\n",
            "DGL Karate Club GraphSAGE (CSR) on GPU: 0.001674 seconds per iteration, 754.30 MB peak memory\n",
            "DGL Citeseer GraphSAGE (COO) on CPU: 0.031380 seconds per iteration, 747.92 MB peak memory\n",
            "DGL Citeseer GraphSAGE (COO) on GPU: 0.031594 seconds per iteration, 747.92 MB peak memory\n",
            "DGL Citeseer GraphSAGE (CSR) on CPU: 0.045907 seconds per iteration, 747.92 MB peak memory\n",
            "DGL Citeseer GraphSAGE (CSR) on GPU: 0.030706 seconds per iteration, 747.92 MB peak memory\n",
            "PyG Karate Club PNA (COO) on CPU: 0.001837 seconds per iteration, 748.36 MB peak memory\n",
            "PyG Karate Club PNA (COO) on GPU: 0.001778 seconds per iteration, 748.36 MB peak memory\n",
            "PyG Karate Club PNA (CSR) on CPU: 0.001734 seconds per iteration, 748.36 MB peak memory\n",
            "PyG Karate Club PNA (CSR) on GPU: 0.001744 seconds per iteration, 748.36 MB peak memory\n",
            "PyG Citeseer PNA (COO) on CPU: 9.655188 seconds per iteration, 1874.16 MB peak memory\n",
            "PyG Citeseer PNA (COO) on GPU: 9.630101 seconds per iteration, 1807.79 MB peak memory\n",
            "PyG Citeseer PNA (CSR) on CPU: 9.626566 seconds per iteration, 1874.84 MB peak memory\n",
            "PyG Citeseer PNA (CSR) on GPU: 9.576192 seconds per iteration, 1852.33 MB peak memory\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "PNAConv.__init__() missing 3 required positional arguments: 'aggregators', 'scalers', and 'delta'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-b70edfd2e7e3>\u001b[0m in \u001b[0;36m<cell line: 121>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_dgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0moutput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_dgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mmodel_dgl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelDGL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mtime_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprofile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dgl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_dgl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mtime_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprofile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dgl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_dgl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-b70edfd2e7e3>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPNA_DGL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPNAConvDGL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPNAConvDGL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: PNAConv.__init__() missing 3 required positional arguments: 'aggregators', 'scalers', and 'delta'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5dSk_GMDvHbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "55tHCyAXvID8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "import torch_geometric\n",
        "import dgl\n",
        "from dgl.nn.pytorch import GATConv, GraphConv, SAGEConv, PNAConv\n",
        "\n",
        "# Define GAT model for PyG\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GAT, self).__init__()\n",
        "        self.conv1 = torch_geometric.nn.GATConv(in_channels, 8, heads=8)\n",
        "        self.conv2 = torch_geometric.nn.GATConv(8 * 8, out_channels, heads=1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Define GAT model for DGL\n",
        "class GAT_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GAT_DGL, self).__init__()\n",
        "        self.conv1 = GATConvDGL(in_channels, 8, num_heads=8)\n",
        "        self.conv2 = GATConvDGL(8 * 8, out_channels, num_heads=1)\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features).flatten(1)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(g, x).mean(1)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Define PNA model for DGL\n",
        "class PNA_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(PNA_DGL, self).__init__()\n",
        "        aggregators = ['mean', 'min', 'max', 'std']\n",
        "        scalers = ['identity', 'amplification', 'attenuation']\n",
        "        self.conv1 = PNAConv(in_channels, 16, aggregators, scalers)\n",
        "        self.conv2 = PNAConv(16, out_channels, aggregators, scalers)\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(g, x)\n",
        "        return x\n",
        "\n",
        "# Ensure features and labels are set for DGL graphs\n",
        "def ensure_dgl_features_and_labels(graph, pyg_data):\n",
        "    graph.ndata['feat'] = pyg_data.x.clone().detach()\n",
        "    graph.ndata['label'] = pyg_data.y.clone().detach()\n",
        "    return graph\n",
        "\n",
        "graph_karate_dgl = ensure_dgl_features_and_labels(graph_karate_dgl, data_karate_pyg)\n",
        "graph_citeseer_dgl = ensure_dgl_features_and_labels(graph_citeseer_dgl, data_citeseer_pyg)\n",
        "\n",
        "# Define devices\n",
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define and test models on COO and CSR formats\n",
        "formats = ['coo', 'csr']\n",
        "models = {\n",
        "    'GCN': (GCN, GCN_DGL),\n",
        "    'GAT': (GAT, GAT_DGL),\n",
        "    'GraphSAGE': (GraphSAGE, GraphSAGE_DGL),\n",
        "    'PNA': (PNA, PNA_DGL)\n",
        "}\n",
        "\n",
        "datasets_pyg = {\n",
        "    'Karate Club': (dataset_karate_pyg, data_karate_pyg),\n",
        "    'Citeseer': (dataset_citeseer_pyg, data_citeseer_pyg)\n",
        "}\n",
        "\n",
        "datasets_dgl = {\n",
        "    'Karate Club': graph_karate_dgl,\n",
        "    'Citeseer': graph_citeseer_dgl\n",
        "}\n",
        "\n",
        "for model_name, (ModelPyG, ModelDGL) in models.items():\n",
        "    for dataset_name, (dataset_pyg, data_pyg) in datasets_pyg.items():\n",
        "        for fmt in formats:\n",
        "            model_pyg = ModelPyG(dataset_pyg.num_features, dataset_pyg.num_classes)\n",
        "            time_cpu, mem_cpu = profile_model(model_pyg, data_pyg, device_cpu, format=fmt)\n",
        "            time_gpu, mem_gpu = profile_model(model_pyg, data_pyg, device_gpu, format=fmt)\n",
        "            print(f'PyG {dataset_name} {model_name} ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "            print(f'PyG {dataset_name} {model_name} ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n",
        "\n",
        "    for dataset_name, graph_dgl in datasets_dgl.items():\n",
        "        for fmt in formats:\n",
        "            input_dim = graph_dgl.ndata['feat'].shape[1]\n",
        "            output_dim = graph_dgl.ndata['label'].max().item() + 1\n",
        "            model_dgl = ModelDGL(input_dim, output_dim)\n",
        "            time_cpu, mem_cpu = profile_model(model_dgl, graph_dgl, device_cpu, dgl=True, format=fmt)\n",
        "            time_gpu, mem_gpu = profile_model(model_dgl, graph_dgl, device_gpu, dgl=True, format=fmt)\n",
        "            print(f'DGL {dataset_name} {model_name} ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "            print(f'DGL {dataset_name} {model_name} ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n"
      ],
      "metadata": {
        "id": "JdEmDhqJpEk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Models with COO and CSR on CPU and GPU"
      ],
      "metadata": {
        "id": "7CvDNY88woUM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define devices"
      ],
      "metadata": {
        "id": "Bl-4O69hw3PI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "TclZ_ZdZw6ZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test GCN on CPU and GPU for PyG Karate ClubB"
      ],
      "metadata": {
        "id": "TKpJPlFNw8X8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_model_pyg = GCN(dataset_karate_pyg.num_features, dataset_karate_pyg.num_classes)\n",
        "time_cpu, mem_cpu = profile_model(gcn_model_pyg, data_karate_pyg, device_cpu, format='coo')\n",
        "time_gpu, mem_gpu = profile_model(gcn_model_pyg, data_karate_pyg, device_gpu, format='coo')\n",
        "print(f'PyG Karate Club GCN on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "print(f'PyG Karate Club GCN on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n"
      ],
      "metadata": {
        "id": "OnZNIRzCxA-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test GCN on CPU and GPU for PyG Citeseer"
      ],
      "metadata": {
        "id": "SG8-Gyq1xD8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_model_pyg = GCN(dataset_citeseer_pyg.num_features, dataset_citeseer_pyg.num_classes)\n",
        "time_cpu, mem_cpu = profile_model(gcn_model_pyg, data_citeseer_pyg, device_cpu, format='csr')\n",
        "time_gpu, mem_gpu = profile_model(gcn_model_pyg, data_citeseer_pyg, device_gpu, format='csr')\n",
        "print(f'PyG Citeseer GCN on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "print(f'PyG Citeseer GCN on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n"
      ],
      "metadata": {
        "id": "uA1BpiguxLEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test GCN on CPU and GPU for DGL Karate Club"
      ],
      "metadata": {
        "id": "g8Ohm2YZxNCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`feat` error solver -v"
      ],
      "metadata": {
        "id": "_30haT4xyOnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Karate Club dataset\n",
        "dataset_karate_dgl = KarateClubDataset()\n",
        "graph_karate_dgl = dataset_karate_dgl[0]\n",
        "\n",
        "# Add dummy features (e.g., use one-hot encoding for simplicity)\n",
        "num_nodes = graph_karate_dgl.num_nodes()\n",
        "graph_karate_dgl.ndata['feat'] = torch.eye(num_nodes)\n",
        "\n",
        "# Add labels\n",
        "graph_karate_dgl.ndata['label'] = torch.tensor(graph_karate_dgl.ndata['label'])\n"
      ],
      "metadata": {
        "id": "AaOYF3EwyD6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_model_dgl = GCN_DGL(graph_karate_dgl.ndata['feat'].shape[1], graph_karate_dgl.ndata['label'].max().item() + 1)\n",
        "time_cpu, mem_cpu = profile_model(gcn_model_dgl, graph_karate_dgl, device_cpu, dgl=True, format='coo')\n",
        "time_gpu, mem_gpu = profile_model(gcn_model_dgl, graph_karate_dgl, device_gpu, dgl=True, format='coo')\n",
        "print(f'DGL Karate Club GCN on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "print(f'DGL Karate Club GCN on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n"
      ],
      "metadata": {
        "id": "UWygavUzxUk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test GCN on CPU and GPU for DGL Citeseer"
      ],
      "metadata": {
        "id": "j16XGpR7xZo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_model_dgl = GCN_DGL(graph_citeseer_dgl.ndata['feat'].shape[1], graph_citeseer_dgl.ndata['label'].max().item() + 1)\n",
        "time_cpu, mem_cpu = profile_model(gcn_model_dgl, graph_citeseer_dgl, device_cpu, dgl=True, format='csr')\n",
        "time_gpu, mem_gpu = profile_model(gcn_model_dgl, graph_citeseer_dgl, device_gpu, dgl=True, format='csr')\n",
        "print(f'DGL Citeseer GCN on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "print(f'DGL Citeseer GCN on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')"
      ],
      "metadata": {
        "id": "niT3DJBsyeUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "C6FNIdooz1mB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More coplex datasets"
      ],
      "metadata": {
        "id": "T9heMbv6yg_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Complex Datasets and Profiling\n",
        "Define Profiling Function"
      ],
      "metadata": {
        "id": "s8Wl1xB4z0up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def profile_model(model, data, device, dgl=False, format='coo'):\n",
        "    model = model.to(device)\n",
        "    data = data.to(device)\n",
        "\n",
        "    def run_model():\n",
        "        model.train()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "        for _ in range(1):  # Run for one epoch to measure time\n",
        "            optimizer.zero_grad()\n",
        "            if dgl:\n",
        "                if format == 'csr':\n",
        "                    logits = model(data, data.ndata['feat'])\n",
        "                else:\n",
        "                    logits = model(data, data.ndata['feat'])\n",
        "            else:\n",
        "                logits = model(data)\n",
        "            loss = F.cross_entropy(logits[data.y_index], data.y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Measure time\n",
        "    start_time = time.time()\n",
        "    run_model()\n",
        "    end_time = time.time()\n",
        "    time_taken = end_time - start_time\n",
        "\n",
        "    # Measure memory\n",
        "    mem_usage = memory_usage(run_model, max_usage=True, retval=False)\n",
        "    peak_memory = max(mem_usage)\n",
        "\n",
        "    return time_taken, peak_memory"
      ],
      "metadata": {
        "id": "tzO6MQiFz6tS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Complex Datasets"
      ],
      "metadata": {
        "id": "stnNJsyuPwdR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load PyG Datasets"
      ],
      "metadata": {
        "id": "xJgdsgUuQRe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import Reddit, Amazon"
      ],
      "metadata": {
        "id": "eOf49A9WP3Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_reddit_pyg = Reddit(root='/tmp/Reddit')\n",
        "data_reddit_pyg = dataset_reddit_pyg[0]\n",
        "\n",
        "dataset_amazon_pyg = Amazon(root='/tmp/Amazon', name='Computers')\n",
        "data_amazon_pyg = dataset_amazon_pyg[0]"
      ],
      "metadata": {
        "id": "m8j8CWSZP7Hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load DGL Datasets"
      ],
      "metadata": {
        "id": "P_Z60L5OQZlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dgl.data import RedditDataset, AmazonCoBuyComputerDataset"
      ],
      "metadata": {
        "id": "NhPU8h1rQcrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_reddit_dgl():\n",
        "    dataset = RedditDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "def load_amazon_dgl():\n",
        "    dataset = AmazonCoBuyComputerDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "graph_reddit_dgl = load_reddit_dgl()\n",
        "graph_amazon_dgl = load_amazon_dgl()"
      ],
      "metadata": {
        "id": "zRe38T83QeOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Models on Complex Datasets"
      ],
      "metadata": {
        "id": "tVi6OyLeQkER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define devices\n",
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "y4UKYg6_QmOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define and test models"
      ],
      "metadata": {
        "id": "TSXvUKvGQpi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'GCN': (GCN, GCN_DGL),\n",
        "    'GAT': (GAT, GATConvDGL),\n",
        "    'GraphSAGE': (GraphSAGE, SAGEConvDGL),\n",
        "    'PNA': (PNA, PNAConv)\n",
        "}\n",
        "\n",
        "datasets_pyg = {\n",
        "    'Reddit': data_reddit_pyg,\n",
        "    'Amazon': data_amazon_pyg\n",
        "}\n",
        "\n",
        "datasets_dgl = {\n",
        "    'Reddit': graph_reddit_dgl,\n",
        "    'Amazon': graph_amazon_dgl\n",
        "}"
      ],
      "metadata": {
        "id": "EyP3KR5UQsI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, (ModelPyG, ModelDGL) in models.items():\n",
        "    for dataset_name, data_pyg in datasets_pyg.items():\n",
        "        # PyG Models\n",
        "        model_pyg = ModelPyG(data_pyg.num_features, data_pyg.num_classes)\n",
        "        time_cpu, mem_cpu = profile_model(model_pyg, data_pyg, device_cpu, format='coo')\n",
        "        time_gpu, mem_gpu = profile_model(model_pyg, data_pyg, device_gpu, format='coo')\n",
        "        print(f'PyG {dataset_name} {model_name} on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "        print(f'PyG {dataset_name} {model_name} on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n",
        "\n",
        "    for dataset_name, graph_dgl in datasets_dgl.items():\n",
        "        # DGL Models\n",
        "        model_dgl = ModelDGL(graph_dgl.ndata['feat'].shape[1], graph_dgl.ndata['label'].max().item() + 1)\n",
        "        time_cpu, mem_cpu = profile_model(model_dgl, graph_dgl, device_cpu, dgl=True, format='coo')\n",
        "        time_gpu, mem_gpu = profile_model(model_dgl, graph_dgl, device_gpu, dgl=True, format='coo')\n",
        "        print(f'DGL {dataset_name} {model_name} on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "        print(f'DGL {dataset_name} {model_name} on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')"
      ],
      "metadata": {
        "id": "u0pnOONpQvPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ERROR : Your session crashed after using all available RAM"
      ],
      "metadata": {
        "id": "LMmkbIwST5PL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intermediate Complexity Datasets"
      ],
      "metadata": {
        "id": "0tMEurshUask"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Intermediate Complexity Datasets"
      ],
      "metadata": {
        "id": "KvMgph9BUiug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "from dgl.data import CoraGraphDataset, PubmedGraphDataset, CiteseerGraphDataset\n",
        "\n",
        "# Load PyG Datasets\n",
        "dataset_cora_pyg = Planetoid(root='/tmp/Cora', name='Cora')\n",
        "data_cora_pyg = dataset_cora_pyg[0]\n",
        "\n",
        "dataset_pubmed_pyg = Planetoid(root='/tmp/Pubmed', name='Pubmed')\n",
        "data_pubmed_pyg = dataset_pubmed_pyg[0]\n",
        "\n",
        "dataset_citeseer_pyg = Planetoid(root='/tmp/Citeseer', name='Citeseer')\n",
        "data_citeseer_pyg = dataset_citeseer_pyg[0]\n",
        "\n",
        "# Load DGL Datasets\n",
        "def load_cora_dgl():\n",
        "    dataset = CoraGraphDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "def load_pubmed_dgl():\n",
        "    dataset = PubmedGraphDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "def load_citeseer_dgl():\n",
        "    dataset = CiteseerGraphDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "graph_cora_dgl = load_cora_dgl()\n",
        "graph_pubmed_dgl = load_pubmed_dgl()\n",
        "graph_citeseer_dgl = load_citeseer_dgl()\n"
      ],
      "metadata": {
        "id": "pUwXlZpKUj5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Models on Intermediate Datasets"
      ],
      "metadata": {
        "id": "5AeZ-5-aVL0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define devices\n",
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define and test models\n",
        "models = {\n",
        "    'GCN': (GCN, GCN_DGL),\n",
        "    'GAT': (GAT, GATConvDGL),\n",
        "    'GraphSAGE': (GraphSAGE, SAGEConvDGL),\n",
        "    'PNA': (PNA, PNAConv)\n",
        "}\n",
        "\n",
        "datasets_pyg = {\n",
        "    'Cora': data_cora_pyg,\n",
        "    'PubMed': data_pubmed_pyg,\n",
        "    'CiteSeer': data_citeseer_pyg\n",
        "}\n",
        "\n",
        "datasets_dgl = {\n",
        "    'Cora': graph_cora_dgl,\n",
        "    'PubMed': graph_pubmed_dgl,\n",
        "    'CiteSeer': graph_citeseer_dgl\n",
        "}\n",
        "\n",
        "for model_name, (ModelPyG, ModelDGL) in models.items():\n",
        "    for dataset_name, data_pyg in datasets_pyg.items():\n",
        "        # PyG Models\n",
        "        model_pyg = ModelPyG(data_pyg.num_features, data_pyg.num_classes)\n",
        "        time_cpu, mem_cpu = profile_model(model_pyg, data_pyg, device_cpu, format='coo')\n",
        "        time_gpu, mem_gpu = profile_model(model_pyg, data_pyg, device_gpu, format='coo')\n",
        "        print(f'PyG {dataset_name} {model_name} on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "        print(f'PyG {dataset_name} {model_name} on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n",
        "\n",
        "    for dataset_name, graph_dgl in datasets_dgl.items():\n",
        "        # DGL Models\n",
        "        model_dgl = ModelDGL(graph_dgl.ndata['feat'].shape[1], graph_dgl.ndata['label'].max().item() + 1)\n",
        "        time_cpu, mem_cpu = profile_model(model_dgl, graph_dgl, device_cpu, dgl=True, format='coo')\n",
        "        time_gpu, mem_gpu = profile_model(model_dgl, graph_dgl, device_gpu, dgl=True, format='coo')\n",
        "        print(f'DGL {dataset_name} {model_name} on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "        print(f'DGL {dataset_name} {model_name} on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n"
      ],
      "metadata": {
        "id": "K0_fuc0RVNYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hb8LlkCjVRaZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}