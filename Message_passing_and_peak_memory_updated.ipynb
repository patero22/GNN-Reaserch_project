{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3c4+DURMp6SQmKhfQrPUv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ab32aa9397124dd2879f270ff8ea88b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d43f96ed68645cbb5c9c685efdb7075",
              "IPY_MODEL_3d2582e6ff774880a840697ad1b4bb22",
              "IPY_MODEL_92a97addbef54a0ea1e2fd01152194c4"
            ],
            "layout": "IPY_MODEL_739ef206c4874032bdb2dd79fea85cef"
          }
        },
        "7d43f96ed68645cbb5c9c685efdb7075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1350285f2d7f40dd97f9fe562350e3e6",
            "placeholder": "​",
            "style": "IPY_MODEL_56bc736aa31c4f38b0f7b3db093ec914",
            "value": "/root/.dgl/citeseer.zip: 100%"
          }
        },
        "3d2582e6ff774880a840697ad1b4bb22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a50c6cf55dfa48e882bf9c9a4ae8368d",
            "max": 238901,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_abff7252418e455bb5530e03779a6e7a",
            "value": 238901
          }
        },
        "92a97addbef54a0ea1e2fd01152194c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0abb211dbefa49f3b84f2d4c7da58bfc",
            "placeholder": "​",
            "style": "IPY_MODEL_db5c0e517d574752b2e2eeec1349a1d9",
            "value": " 239k/239k [00:00&lt;00:00, 9.24kB/s]"
          }
        },
        "739ef206c4874032bdb2dd79fea85cef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1350285f2d7f40dd97f9fe562350e3e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56bc736aa31c4f38b0f7b3db093ec914": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a50c6cf55dfa48e882bf9c9a4ae8368d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abff7252418e455bb5530e03779a6e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0abb211dbefa49f3b84f2d4c7da58bfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db5c0e517d574752b2e2eeec1349a1d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "418ba49fcb904d30a70bbd1bd167daeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16adc82424a04703b4fa1c2ab029fe5e",
              "IPY_MODEL_ec9562a27b0f46f390b0718dad569a35",
              "IPY_MODEL_4c65a7e516fd4fd78d92853fcc672cfd"
            ],
            "layout": "IPY_MODEL_a35bfd8280ab4f7cad3c30bafc890d9a"
          }
        },
        "16adc82424a04703b4fa1c2ab029fe5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_652735da4d1440cbadde919885ac478c",
            "placeholder": "​",
            "style": "IPY_MODEL_d4d9d314a1e4434da933edf95503b8bf",
            "value": "/root/.dgl/reddit.zip: 100%"
          }
        },
        "ec9562a27b0f46f390b0718dad569a35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b63e8e5c8754ce3a5ffaad7cc94b543",
            "max": 1397962821,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b84dac0bc83416cabe258f571022a78",
            "value": 1397962821
          }
        },
        "4c65a7e516fd4fd78d92853fcc672cfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6645c0e9946a4bc1a700ff93d6798c7f",
            "placeholder": "​",
            "style": "IPY_MODEL_2002b83573f8451c8ab48ff34357ee73",
            "value": " 1.40G/1.40G [01:02&lt;00:00, 11.9MB/s]"
          }
        },
        "a35bfd8280ab4f7cad3c30bafc890d9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "652735da4d1440cbadde919885ac478c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4d9d314a1e4434da933edf95503b8bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b63e8e5c8754ce3a5ffaad7cc94b543": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b84dac0bc83416cabe258f571022a78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6645c0e9946a4bc1a700ff93d6798c7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2002b83573f8451c8ab48ff34357ee73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patero22/GNN-Reaserch_project/blob/main/Message_passing_and_peak_memory_updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e57kSve1reG7",
        "outputId": "d0f878b5-7e00-4ab0-a2e5-e4907aae5d41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1) (12.5.82)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision\n",
            "  Using cached torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "  Using cached torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "  Using cached torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "  Using cached torchvision-0.17.1-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio\n",
            "  Using cached torchaudio-2.3.1-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "  Using cached torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "  Using cached torchaudio-2.2.2-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "  Using cached torchaudio-2.2.1-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1) (1.3.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: torchvision, torchaudio\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.18.0+cu121\n",
            "    Uninstalling torchvision-0.18.0+cu121:\n",
            "      Successfully uninstalled torchvision-0.18.0+cu121\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.3.0+cu121\n",
            "    Uninstalling torchaudio-2.3.0+cu121:\n",
            "      Successfully uninstalled torchaudio-2.3.0+cu121\n",
            "Successfully installed torchaudio-2.2.1 torchvision-0.17.1\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torch-geometric\n",
            "  Using cached torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.5.3\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting dgl==2.1.0\n",
            "  Downloading dgl-2.1.0-cp310-cp310-manylinux1_x86_64.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (3.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (4.66.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (5.9.5)\n",
            "Collecting torchdata>=0.5.0 (from dgl==2.1.0)\n",
            "  Downloading torchdata-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==2.1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==2.1.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==2.1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==2.1.0) (2024.7.4)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.5.0->dgl==2.1.0) (2.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (1.13.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl==2.1.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata>=0.5.0->dgl==2.1.0) (1.3.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: torchdata, dgl\n",
            "Successfully installed dgl-2.1.0 torchdata-0.7.1\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting memory-profiler\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory-profiler) (5.9.5)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: memory-profiler\n",
            "Successfully installed memory-profiler-0.61.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.2.1 torchvision torchaudio\n",
        "!pip install torch-geometric\n",
        "!pip install dgl==2.1.0\n",
        "!pip install memory-profiler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install  dgl -f https://data.dgl.ai/wheels/torch-2.3/cu121/repo.html"
      ],
      "metadata": {
        "id": "rcZ1dTupsjtN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# torch.utils.data.datapipes.utils.common.DILL_AVAILABLE = torch.utils._import_utils.dill_available()\n",
        "# import torchdata"
      ],
      "metadata": {
        "id": "Xg73b3xPtM-3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ImportError: cannot import name 'DILL_AVAILABLE' from 'torch.utils.data.datapipes.utils.common' (/usr/local/lib/python3.10/dist-packages/torch/utils/data/datapipes/utils/common.py)\n"
      ],
      "metadata": {
        "id": "m52bPfyisrMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, PNAConv\n",
        "from dgl.nn.pytorch import GraphConv, GATConv as GATConvDGL, SAGEConv as SAGEConvDGL"
      ],
      "metadata": {
        "id": "cLfDvwOUrkHn",
        "outputId": "d12d273c-44ec-47cc-bb3a-06eea2c3dc8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Models (GCN, GAT, GraphSAGE, PNA)"
      ],
      "metadata": {
        "id": "5O1LHCBfsKMy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyG Models"
      ],
      "metadata": {
        "id": "HfgeND5fuuqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 16)\n",
        "        self.conv2 = GCNConv(16, out_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GAT, self).__init__()\n",
        "        self.conv1 = GATConv(in_channels, 8, heads=8)\n",
        "        self.conv2 = GATConv(8*8, out_channels, heads=1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, 16)\n",
        "        self.conv2 = SAGEConv(16, out_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class PNA(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(PNA, self).__init__()\n",
        "        aggregators = ['mean', 'min', 'max', 'std']\n",
        "        scalers = ['identity', 'amplification', 'attenuation']\n",
        "        self.conv1 = PNAConv(in_channels, 16, aggregators, scalers)\n",
        "        self.conv2 = PNAConv(16, out_channels, aggregators, scalers)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "yf2ls6INuzF0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DGL Models"
      ],
      "metadata": {
        "id": "YS6graJVu3BX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_feats, out_feats):\n",
        "        super(GCN_DGL, self).__init__()\n",
        "        self.conv1 = GraphConv(in_feats, 16)\n",
        "        self.conv2 = GraphConv(16, out_feats)\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(g, x)\n",
        "        return x\n",
        "\n",
        "class GAT_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_feats, out_feats):\n",
        "        super(GAT_DGL, self).__init__()\n",
        "        self.conv1 = GATConvDGL(in_feats, 8, num_heads=8)\n",
        "        self.conv2 = GATConvDGL(8*8, out_feats, num_heads=1)\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(g, x)\n",
        "        return x\n",
        "\n",
        "class GraphSAGE_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_feats, out_feats):\n",
        "        super(GraphSAGE_DGL, self).__init__()\n",
        "        self.conv1 = SAGEConvDGL(in_feats, 16, 'mean')\n",
        "        self.conv2 = SAGEConvDGL(16, out_feats, 'mean')\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(g, x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "l6wgM7TLu5Ng"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Functions for COO and CSR Message Passing\n",
        "\n",
        "For COO and CSR message passing, we'll leverage scipy for conversion and torch-sparse for COO operations."
      ],
      "metadata": {
        "id": "hOhT94uOu8JM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import coo_matrix, csr_matrix\n",
        "\n",
        "# Conversion Functions\n",
        "def convert_to_coo(edge_index, num_nodes):\n",
        "    row, col = edge_index\n",
        "    data = torch.ones(row.size(0))\n",
        "    coo = coo_matrix((data.numpy(), (row.numpy(), col.numpy())), shape=(num_nodes, num_nodes))\n",
        "    return coo\n",
        "\n",
        "def convert_to_csr(edge_index, num_nodes):\n",
        "    row, col = edge_index\n",
        "    data = torch.ones(row.size(0))\n",
        "    csr = csr_matrix((data.numpy(), (row.numpy(), col.numpy())), shape=(num_nodes, num_nodes))\n",
        "    return csr"
      ],
      "metadata": {
        "id": "R-uGYhjyvD_J"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Profiling Function"
      ],
      "metadata": {
        "id": "sF_Qo1EawMNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Profiling Function\n",
        "from memory_profiler import memory_usage\n",
        "import time\n",
        "\n",
        "def profile_model(model, data, device, dgl=False, format='coo'):\n",
        "    data = data.to(device)\n",
        "    model = model.to(device)\n",
        "\n",
        "    def forward_pass():\n",
        "        if dgl:\n",
        "            model(data, data.ndata['feat'])\n",
        "        else:\n",
        "            model(data)\n",
        "\n",
        "    # Measure time\n",
        "    start_time = time.time()\n",
        "    for _ in range(100):\n",
        "        forward_pass()\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Measure peak memory usage\n",
        "    mem_usage = memory_usage(forward_pass, interval=0.1)\n",
        "\n",
        "    return (end_time - start_time) / 100, max(mem_usage)"
      ],
      "metadata": {
        "id": "Kcn-heVRwRzk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Datasets (Karate Club and Citeseer)"
      ],
      "metadata": {
        "id": "DLhmuWPiwZaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import KarateClub, Planetoid\n",
        "from dgl.data import KarateClubDataset, CiteseerGraphDataset"
      ],
      "metadata": {
        "id": "MwEVACsqwfNM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load PyG Datasets\n",
        "dataset_karate_pyg = KarateClub()\n",
        "data_karate_pyg = dataset_karate_pyg[0]\n",
        "\n",
        "dataset_citeseer_pyg = Planetoid(root='data/Citeseer', name='Citeseer')\n",
        "data_citeseer_pyg = dataset_citeseer_pyg[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfwxXSsswgZ2",
        "outputId": "c9fe72c1-330a-4a37-dd86-b0356ea8df16"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load DGL Datasets\n",
        "def load_karate_dgl():\n",
        "    dataset = KarateClubDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "def load_citeseer_dgl():\n",
        "    dataset = CiteseerGraphDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "graph_karate_dgl = load_karate_dgl()\n",
        "graph_citeseer_dgl = load_citeseer_dgl()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265,
          "referenced_widgets": [
            "ab32aa9397124dd2879f270ff8ea88b8",
            "7d43f96ed68645cbb5c9c685efdb7075",
            "3d2582e6ff774880a840697ad1b4bb22",
            "92a97addbef54a0ea1e2fd01152194c4",
            "739ef206c4874032bdb2dd79fea85cef",
            "1350285f2d7f40dd97f9fe562350e3e6",
            "56bc736aa31c4f38b0f7b3db093ec914",
            "a50c6cf55dfa48e882bf9c9a4ae8368d",
            "abff7252418e455bb5530e03779a6e7a",
            "0abb211dbefa49f3b84f2d4c7da58bfc",
            "db5c0e517d574752b2e2eeec1349a1d9"
          ]
        },
        "id": "uKAD2-mjwlur",
        "outputId": "abf2512a-bf2c-4c1d-a9a6-975fa024de02"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /root/.dgl/citeseer.zip from https://data.dgl.ai/dataset/citeseer.zip...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/root/.dgl/citeseer.zip:   0%|          | 0.00/239k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab32aa9397124dd2879f270ff8ea88b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting file to /root/.dgl/citeseer_d6836239\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done saving data into cached files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Models with COO and CSR on CPU and GPU"
      ],
      "metadata": {
        "id": "7CvDNY88woUM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define devices"
      ],
      "metadata": {
        "id": "Bl-4O69hw3PI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "TclZ_ZdZw6ZP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test GCN on CPU and GPU for PyG Karate ClubB"
      ],
      "metadata": {
        "id": "TKpJPlFNw8X8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_model_pyg = GCN(dataset_karate_pyg.num_features, dataset_karate_pyg.num_classes)\n",
        "time_cpu, mem_cpu = profile_model(gcn_model_pyg, data_karate_pyg, device_cpu, format='coo')\n",
        "time_gpu, mem_gpu = profile_model(gcn_model_pyg, data_karate_pyg, device_gpu, format='coo')\n",
        "print(f'PyG Karate Club GCN on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "print(f'PyG Karate Club GCN on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnZNIRzCxA-w",
        "outputId": "44a5f377-4782-4604-a380-33da0061cd22"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyG Karate Club GCN on CPU: 0.005358 seconds per iteration, 786.33 MB peak memory\n",
            "PyG Karate Club GCN on GPU: 0.001836 seconds per iteration, 786.33 MB peak memory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test GCN on CPU and GPU for PyG Citeseer"
      ],
      "metadata": {
        "id": "SG8-Gyq1xD8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_model_pyg = GCN(dataset_citeseer_pyg.num_features, dataset_citeseer_pyg.num_classes)\n",
        "time_cpu, mem_cpu = profile_model(gcn_model_pyg, data_citeseer_pyg, device_cpu, format='csr')\n",
        "time_gpu, mem_gpu = profile_model(gcn_model_pyg, data_citeseer_pyg, device_gpu, format='csr')\n",
        "print(f'PyG Citeseer GCN on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "print(f'PyG Citeseer GCN on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA1BpiguxLEH",
        "outputId": "715bd8a7-b3fb-4867-fdac-99557e23227e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyG Citeseer GCN on CPU: 0.021260 seconds per iteration, 786.83 MB peak memory\n",
            "PyG Citeseer GCN on GPU: 0.017199 seconds per iteration, 786.86 MB peak memory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test GCN on CPU and GPU for DGL Karate Club"
      ],
      "metadata": {
        "id": "g8Ohm2YZxNCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`feat` error solver -v"
      ],
      "metadata": {
        "id": "_30haT4xyOnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Karate Club dataset\n",
        "dataset_karate_dgl = KarateClubDataset()\n",
        "graph_karate_dgl = dataset_karate_dgl[0]\n",
        "\n",
        "# Add dummy features (e.g., use one-hot encoding for simplicity)\n",
        "num_nodes = graph_karate_dgl.num_nodes()\n",
        "graph_karate_dgl.ndata['feat'] = torch.eye(num_nodes)\n",
        "\n",
        "# Add labels\n",
        "graph_karate_dgl.ndata['label'] = torch.tensor(graph_karate_dgl.ndata['label'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaOYF3EwyD6Q",
        "outputId": "7a64c725-77f9-4e66-be06-ebdf4b6f081c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-5a57f9503770>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  graph_karate_dgl.ndata['label'] = torch.tensor(graph_karate_dgl.ndata['label'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_model_dgl = GCN_DGL(graph_karate_dgl.ndata['feat'].shape[1], graph_karate_dgl.ndata['label'].max().item() + 1)\n",
        "time_cpu, mem_cpu = profile_model(gcn_model_dgl, graph_karate_dgl, device_cpu, dgl=True, format='coo')\n",
        "time_gpu, mem_gpu = profile_model(gcn_model_dgl, graph_karate_dgl, device_gpu, dgl=True, format='coo')\n",
        "print(f'DGL Karate Club GCN on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "print(f'DGL Karate Club GCN on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWygavUzxUk1",
        "outputId": "1a35569f-30b2-443f-f3f7-6ff2e4a8a262"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DGL Karate Club GCN on CPU: 0.002505 seconds per iteration, 788.62 MB peak memory\n",
            "DGL Karate Club GCN on GPU: 0.002092 seconds per iteration, 788.62 MB peak memory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test GCN on CPU and GPU for DGL Citeseer"
      ],
      "metadata": {
        "id": "j16XGpR7xZo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_model_dgl = GCN_DGL(graph_citeseer_dgl.ndata['feat'].shape[1], graph_citeseer_dgl.ndata['label'].max().item() + 1)\n",
        "time_cpu, mem_cpu = profile_model(gcn_model_dgl, graph_citeseer_dgl, device_cpu, dgl=True, format='csr')\n",
        "time_gpu, mem_gpu = profile_model(gcn_model_dgl, graph_citeseer_dgl, device_gpu, dgl=True, format='csr')\n",
        "print(f'DGL Citeseer GCN on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "print(f'DGL Citeseer GCN on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niT3DJBsyeUV",
        "outputId": "c4d191ed-ac18-43bd-87ff-3e3164a92336"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DGL Citeseer GCN on CPU: 0.053042 seconds per iteration, 835.77 MB peak memory\n",
            "DGL Citeseer GCN on GPU: 0.058367 seconds per iteration, 835.78 MB peak memory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "C6FNIdooz1mB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More coplex datasets"
      ],
      "metadata": {
        "id": "T9heMbv6yg_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Complex Datasets and Profiling\n",
        "Define Profiling Function"
      ],
      "metadata": {
        "id": "s8Wl1xB4z0up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def profile_model(model, data, device, dgl=False, format='coo'):\n",
        "    model = model.to(device)\n",
        "    data = data.to(device)\n",
        "\n",
        "    def run_model():\n",
        "        model.train()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "        for _ in range(1):  # Run for one epoch to measure time\n",
        "            optimizer.zero_grad()\n",
        "            if dgl:\n",
        "                if format == 'csr':\n",
        "                    logits = model(data, data.ndata['feat'])\n",
        "                else:\n",
        "                    logits = model(data, data.ndata['feat'])\n",
        "            else:\n",
        "                logits = model(data)\n",
        "            loss = F.cross_entropy(logits[data.y_index], data.y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Measure time\n",
        "    start_time = time.time()\n",
        "    run_model()\n",
        "    end_time = time.time()\n",
        "    time_taken = end_time - start_time\n",
        "\n",
        "    # Measure memory\n",
        "    mem_usage = memory_usage(run_model, max_usage=True, retval=False)\n",
        "    peak_memory = max(mem_usage)\n",
        "\n",
        "    return time_taken, peak_memory"
      ],
      "metadata": {
        "id": "tzO6MQiFz6tS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Complex Datasets"
      ],
      "metadata": {
        "id": "stnNJsyuPwdR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load PyG Datasets"
      ],
      "metadata": {
        "id": "xJgdsgUuQRe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import Reddit, Amazon"
      ],
      "metadata": {
        "id": "eOf49A9WP3Vr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_reddit_pyg = Reddit(root='/tmp/Reddit')\n",
        "data_reddit_pyg = dataset_reddit_pyg[0]\n",
        "\n",
        "dataset_amazon_pyg = Amazon(root='/tmp/Amazon', name='Computers')\n",
        "data_amazon_pyg = dataset_amazon_pyg[0]"
      ],
      "metadata": {
        "id": "m8j8CWSZP7Hf",
        "outputId": "d59a42ad-a7e2-4477-c0b8-0a70c9e526f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://data.dgl.ai/dataset/reddit.zip\n",
            "Extracting /tmp/Reddit/raw/reddit.zip\n",
            "Processing...\n",
            "Done!\n",
            "Downloading https://github.com/shchur/gnn-benchmark/raw/master/data/npz/amazon_electronics_computers.npz\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load DGL Datasets"
      ],
      "metadata": {
        "id": "P_Z60L5OQZlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dgl.data import RedditDataset, AmazonCoBuyComputerDataset"
      ],
      "metadata": {
        "id": "NhPU8h1rQcrm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_reddit_dgl():\n",
        "    dataset = RedditDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "def load_amazon_dgl():\n",
        "    dataset = AmazonCoBuyComputerDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "graph_reddit_dgl = load_reddit_dgl()\n",
        "graph_amazon_dgl = load_amazon_dgl()"
      ],
      "metadata": {
        "id": "zRe38T83QeOn",
        "outputId": "f071d8e2-dfb6-40ef-cd8d-14699751f1ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "418ba49fcb904d30a70bbd1bd167daeb",
            "16adc82424a04703b4fa1c2ab029fe5e",
            "ec9562a27b0f46f390b0718dad569a35",
            "4c65a7e516fd4fd78d92853fcc672cfd",
            "a35bfd8280ab4f7cad3c30bafc890d9a",
            "652735da4d1440cbadde919885ac478c",
            "d4d9d314a1e4434da933edf95503b8bf",
            "2b63e8e5c8754ce3a5ffaad7cc94b543",
            "6b84dac0bc83416cabe258f571022a78",
            "6645c0e9946a4bc1a700ff93d6798c7f",
            "2002b83573f8451c8ab48ff34357ee73"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /root/.dgl/reddit.zip from https://data.dgl.ai/dataset/reddit.zip...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/root/.dgl/reddit.zip:   0%|          | 0.00/1.40G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "418ba49fcb904d30a70bbd1bd167daeb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting file to /root/.dgl/reddit_69f818f5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Models on Complex Datasets"
      ],
      "metadata": {
        "id": "tVi6OyLeQkER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define devices\n",
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "y4UKYg6_QmOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define and test models"
      ],
      "metadata": {
        "id": "TSXvUKvGQpi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'GCN': (GCN, GCN_DGL),\n",
        "    'GAT': (GAT, GATConvDGL),\n",
        "    'GraphSAGE': (GraphSAGE, SAGEConvDGL),\n",
        "    'PNA': (PNA, PNAConv)\n",
        "}\n",
        "\n",
        "datasets_pyg = {\n",
        "    'Reddit': data_reddit_pyg,\n",
        "    'Amazon': data_amazon_pyg\n",
        "}\n",
        "\n",
        "datasets_dgl = {\n",
        "    'Reddit': graph_reddit_dgl,\n",
        "    'Amazon': graph_amazon_dgl\n",
        "}"
      ],
      "metadata": {
        "id": "EyP3KR5UQsI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, (ModelPyG, ModelDGL) in models.items():\n",
        "    for dataset_name, data_pyg in datasets_pyg.items():\n",
        "        # PyG Models\n",
        "        model_pyg = ModelPyG(data_pyg.num_features, data_pyg.num_classes)\n",
        "        time_cpu, mem_cpu = profile_model(model_pyg, data_pyg, device_cpu, format='coo')\n",
        "        time_gpu, mem_gpu = profile_model(model_pyg, data_pyg, device_gpu, format='coo')\n",
        "        print(f'PyG {dataset_name} {model_name} on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "        print(f'PyG {dataset_name} {model_name} on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n",
        "\n",
        "    for dataset_name, graph_dgl in datasets_dgl.items():\n",
        "        # DGL Models\n",
        "        model_dgl = ModelDGL(graph_dgl.ndata['feat'].shape[1], graph_dgl.ndata['label'].max().item() + 1)\n",
        "        time_cpu, mem_cpu = profile_model(model_dgl, graph_dgl, device_cpu, dgl=True, format='coo')\n",
        "        time_gpu, mem_gpu = profile_model(model_dgl, graph_dgl, device_gpu, dgl=True, format='coo')\n",
        "        print(f'DGL {dataset_name} {model_name} on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "        print(f'DGL {dataset_name} {model_name} on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')"
      ],
      "metadata": {
        "id": "u0pnOONpQvPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ERROR : Your session crashed after using all available RAM"
      ],
      "metadata": {
        "id": "LMmkbIwST5PL"
      }
    }
  ]
}