{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVZcg95KlIhF47dNfHgPWj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patero22/GNN-Reaserch_project/blob/main/Message_passing_and_peak_memory_updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "e57kSve1reG7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc0c61b5-1e5a-4a2e-ee65-b1fb304fb5b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1) (12.5.82)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1) (1.3.0)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n",
            "Requirement already satisfied: dgl==2.1.0 in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (3.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (4.66.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (5.9.5)\n",
            "Requirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (0.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==2.1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==2.1.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==2.1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==2.1.0) (2024.7.4)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.5.0->dgl==2.1.0) (2.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (1.13.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl==2.1.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata>=0.5.0->dgl==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: memory-profiler in /usr/local/lib/python3.10/dist-packages (0.61.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory-profiler) (5.9.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.2.1 torchvision torchaudio\n",
        "!pip install torch-geometric\n",
        "!pip install dgl==2.1.0\n",
        "!pip install memory-profiler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install  dgl -f https://data.dgl.ai/wheels/torch-2.3/cu121/repo.html"
      ],
      "metadata": {
        "id": "rcZ1dTupsjtN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# torch.utils.data.datapipes.utils.common.DILL_AVAILABLE = torch.utils._import_utils.dill_available()\n",
        "# import torchdata"
      ],
      "metadata": {
        "id": "Xg73b3xPtM-3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ImportError: cannot import name 'DILL_AVAILABLE' from 'torch.utils.data.datapipes.utils.common' (/usr/local/lib/python3.10/dist-packages/torch/utils/data/datapipes/utils/common.py)\n"
      ],
      "metadata": {
        "id": "m52bPfyisrMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, PNAConv\n",
        "from dgl.nn.pytorch import GraphConv, GATConv as GATConvDGL, SAGEConv as SAGEConvDGL\n",
        "from dgl.nn import PNAConv"
      ],
      "metadata": {
        "id": "cLfDvwOUrkHn",
        "outputId": "77416207-29b2-4983-c1c5-39a04682ff4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-abd7eca32b32>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGCNConv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGATConv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAGEConv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPNAConv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphConv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGATConv\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mGATConvDGL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSAGEConv\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mSAGEConvDGL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPNAConv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_backend\u001b[0m  \u001b[0;31m# usort: skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m from . import (\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mcontainer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/dataloading/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preferred_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pytorch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mspot_target\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdist_dataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/dataloading/dataloader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbatch_graphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPUCache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistGraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyFeature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheterograph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDGLGraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/distributed/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdist_context\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexit_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdist_dataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdist_graph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistGraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDistGraphServer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdist_tensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgraph_partition_book\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphPartitionBook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPartitionPolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/distributed/dist_graph.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphbolt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheterograph_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mempty_shared_mem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mALL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDGLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mETYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/graphbolt/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ffi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibinfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mminibatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/graphbolt/minibatch.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCSCFormatBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype_str_to_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_indptr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minternal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msampled_subgraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSampledSubgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/graphbolt/internal/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"Utility functions for GraphBolt.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msample_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdatapipe_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mitem_sampler_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/graphbolt/internal/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_array_header_1_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_array_header_2_0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplotting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtseries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/testing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m from pandas._testing import (\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0massert_extension_array_equal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0massert_frame_equal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_testing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m \u001b[0mcython_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cython_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Models (GCN, GAT, GraphSAGE, PNA)"
      ],
      "metadata": {
        "id": "5O1LHCBfsKMy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyG Models"
      ],
      "metadata": {
        "id": "HfgeND5fuuqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 16)\n",
        "        self.conv2 = GCNConv(16, out_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GAT, self).__init__()\n",
        "        self.conv1 = GATConv(in_channels, 8, heads=8)\n",
        "        self.conv2 = GATConv(8*8, out_channels, heads=1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, 16)\n",
        "        self.conv2 = SAGEConv(16, out_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class PNA(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(PNA, self).__init__()\n",
        "        aggregators = ['mean', 'min', 'max', 'std']\n",
        "        scalers = ['identity', 'amplification', 'attenuation']\n",
        "        self.conv1 = PNAConv(in_channels, 16, aggregators, scalers)\n",
        "        self.conv2 = PNAConv(16, out_channels, aggregators, scalers)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "yf2ls6INuzF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DGL Models"
      ],
      "metadata": {
        "id": "YS6graJVu3BX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_feats, out_feats):\n",
        "        super(GCN_DGL, self).__init__()\n",
        "        self.conv1 = GraphConv(in_feats, 16)\n",
        "        self.conv2 = GraphConv(16, out_feats)\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(g, x)\n",
        "        return x\n",
        "\n",
        "class GAT_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_feats, out_feats):\n",
        "        super(GAT_DGL, self).__init__()\n",
        "        self.conv1 = GATConvDGL(in_feats, 8, num_heads=8)\n",
        "        self.conv2 = GATConvDGL(8*8, out_feats, num_heads=1)\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(g, x)\n",
        "        return x\n",
        "\n",
        "class GraphSAGE_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_feats, out_feats):\n",
        "        super(GraphSAGE_DGL, self).__init__()\n",
        "        self.conv1 = SAGEConvDGL(in_feats, 16, 'mean')\n",
        "        self.conv2 = SAGEConvDGL(16, out_feats, 'mean')\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(g, x)\n",
        "        return x\n",
        "\n",
        "class PNA_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(PNA_DGL, self).__init__()\n",
        "        aggregators = ['mean', 'min', 'max', 'std']\n",
        "        scalers = ['identity', 'amplification', 'attenuation']\n",
        "        self.conv1 = PNAConv(in_channels, 16, aggregators, scalers)\n",
        "        self.conv2 = PNAConv(16, out_channels, aggregators, scalers)\n",
        "\n",
        "    def forward(self, graph):\n",
        "        x = graph.ndata['feat']\n",
        "        x = self.conv1(graph, x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(graph, x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "l6wgM7TLu5Ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Functions for COO and CSR Message Passing\n",
        "\n",
        "For COO and CSR message passing, we'll leverage scipy for conversion and torch-sparse for COO operations."
      ],
      "metadata": {
        "id": "hOhT94uOu8JM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import coo_matrix, csr_matrix\n",
        "\n",
        "# Conversion Functions\n",
        "def convert_to_coo(edge_index, num_nodes):\n",
        "    row, col = edge_index\n",
        "    data = torch.ones(row.size(0))\n",
        "    coo = coo_matrix((data.numpy(), (row.numpy(), col.numpy())), shape=(num_nodes, num_nodes))\n",
        "    return coo\n",
        "\n",
        "def convert_to_csr(edge_index, num_nodes):\n",
        "    row, col = edge_index\n",
        "    data = torch.ones(row.size(0))\n",
        "    csr = csr_matrix((data.numpy(), (row.numpy(), col.numpy())), shape=(num_nodes, num_nodes))\n",
        "    return csr"
      ],
      "metadata": {
        "id": "R-uGYhjyvD_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Profiling Function"
      ],
      "metadata": {
        "id": "sF_Qo1EawMNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Profiling Function\n",
        "from memory_profiler import memory_usage\n",
        "import time\n",
        "\n",
        "def profile_model(model, data, device, dgl=False, format='coo'):\n",
        "    data = data.to(device)\n",
        "    model = model.to(device)\n",
        "\n",
        "    def forward_pass():\n",
        "        if dgl:\n",
        "            model(data, data.ndata['feat'])\n",
        "        else:\n",
        "            model(data)\n",
        "\n",
        "    # Measure time\n",
        "    start_time = time.time()\n",
        "    for _ in range(100):\n",
        "        forward_pass()\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Measure peak memory usage\n",
        "    mem_usage = memory_usage(forward_pass, interval=0.1)\n",
        "\n",
        "    return (end_time - start_time) / 100, max(mem_usage)"
      ],
      "metadata": {
        "id": "Kcn-heVRwRzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def profile_model(model, data, device, dgl=False, format='coo'):\n",
        "    model.to(device)\n",
        "    data.to(device)\n",
        "\n",
        "    # Ustaw model w tryb ewaluacji\n",
        "    model.eval()\n",
        "\n",
        "    # Profilowanie na CPU\n",
        "    if device == torch.device('cpu'):\n",
        "        start_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            for _ in range(10):  # zmniejsz liczbę iteracji, jeśli to konieczne\n",
        "                model(data)\n",
        "        end_time = time.time()\n",
        "\n",
        "        total_time = (end_time - start_time) / 10.0  # średni czas na iterację\n",
        "        memory_usage = torch.cuda.memory_allocated(device) / (1024 ** 2) if torch.cuda.is_available() else 0\n",
        "\n",
        "        return total_time, memory_usage\n",
        "\n",
        "    # Profilowanie na GPU\n",
        "    elif device == torch.device('cuda'):\n",
        "        torch.cuda.reset_peak_memory_stats(device)\n",
        "        start_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            for _ in range(10):  # zmniejsz liczbę iteracji, jeśli to konieczne\n",
        "                model(data)\n",
        "        end_time = time.time()\n",
        "\n",
        "        total_time = (end_time - start_time) / 10.0  # średni czas na iterację\n",
        "        memory_usage = torch.cuda.max_memory_allocated(device) / (1024 ** 2)\n",
        "\n",
        "        return total_time, memory_usage"
      ],
      "metadata": {
        "id": "hw9eYLKFxdJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Datasets (Karate Club and Citeseer)"
      ],
      "metadata": {
        "id": "DLhmuWPiwZaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import KarateClub, Planetoid\n",
        "from dgl.data import KarateClubDataset, CiteseerGraphDataset"
      ],
      "metadata": {
        "id": "MwEVACsqwfNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load PyG Datasets\n",
        "dataset_karate_pyg = KarateClub()\n",
        "data_karate_pyg = dataset_karate_pyg[0]\n",
        "\n",
        "dataset_citeseer_pyg = Planetoid(root='data/Citeseer', name='Citeseer')\n",
        "data_citeseer_pyg = dataset_citeseer_pyg[0]"
      ],
      "metadata": {
        "id": "xfwxXSsswgZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load DGL Datasets\n",
        "def load_karate_dgl():\n",
        "    dataset = KarateClubDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "def load_citeseer_dgl():\n",
        "    dataset = CiteseerGraphDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "graph_karate_dgl = load_karate_dgl()\n",
        "graph_citeseer_dgl = load_citeseer_dgl()"
      ],
      "metadata": {
        "id": "uKAD2-mjwlur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w9wXLUL5vFXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Great working loop for testing model GCN GAT GraphSAGE in coo and csr formats on cpu and gpu devices"
      ],
      "metadata": {
        "id": "KHs6gS4svGTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data\n",
        "import dgl\n",
        "from dgl.nn.pytorch import GATConv as GATConvDGL, GraphConv, SAGEConv as SAGEConvDGL, PNAConv as PNAConvDGL\n",
        "\n",
        "# Define GAT model for PyG\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GAT, self).__init__()\n",
        "        self.conv1 = torch_geometric.nn.GATConv(in_channels, 8, heads=8)\n",
        "        self.conv2 = torch_geometric.nn.GATConv(8 * 8, out_channels, heads=1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Define GAT model for DGL\n",
        "class GAT_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GAT_DGL, self).__init__()\n",
        "        self.conv1 = GATConvDGL(in_channels, 8, num_heads=8)\n",
        "        self.conv2 = GATConvDGL(8 * 8, out_channels, num_heads=1)\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features).flatten(1)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(g, x).mean(1)\n",
        "        return x\n",
        "\n",
        "# Define GraphSAGE model for PyG\n",
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = torch_geometric.nn.SAGEConv(in_channels, 16, aggr='mean')\n",
        "        self.conv2 = torch_geometric.nn.SAGEConv(16, out_channels, aggr='mean')\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Define GraphSAGE model for DGL\n",
        "class GraphSAGE_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GraphSAGE_DGL, self).__init__()\n",
        "        self.conv1 = SAGEConvDGL(in_channels, 16, aggregator_type='mean')\n",
        "        self.conv2 = SAGEConvDGL(16, out_channels, aggregator_type='mean')\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(g, x)\n",
        "        return x\n",
        "\n",
        "# Define PNA model for PyG\n",
        "class PNA(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, deg):\n",
        "        super(PNA, self).__init__()\n",
        "        self.conv1 = torch_geometric.nn.PNAConv(in_channels, 16, aggregators=['mean', 'max', 'min'], scalers=['identity'], deg=deg)\n",
        "        self.conv2 = torch_geometric.nn.PNAConv(16, out_channels, aggregators=['mean', 'max', 'min'], scalers=['identity'], deg=deg)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Define PNA model for DGL\n",
        "class PNA_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(PNA_DGL, self).__init__()\n",
        "        self.conv1 = PNAConvDGL(in_channels, 16)\n",
        "        self.conv2 = PNAConvDGL(16, out_channels)\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(g, x)\n",
        "        return x\n",
        "\n",
        "# Ensure features and labels are set for DGL graphs\n",
        "def ensure_dgl_features_and_labels(graph, pyg_data):\n",
        "    graph.ndata['feat'] = pyg_data.x.clone().detach()\n",
        "    graph.ndata['label'] = pyg_data.y.clone().detach()\n",
        "    return graph\n",
        "\n",
        "graph_karate_dgl = ensure_dgl_features_and_labels(graph_karate_dgl, data_karate_pyg)\n",
        "graph_citeseer_dgl = ensure_dgl_features_and_labels(graph_citeseer_dgl, data_citeseer_pyg)\n",
        "\n",
        "# Define devices\n",
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define and test models on COO and CSR formats\n",
        "formats = ['coo', 'csr']\n",
        "models = {\n",
        "    'GCN': (GCN, GCN_DGL),\n",
        "    'GAT': (GAT, GAT_DGL),\n",
        "    'GraphSAGE': (GraphSAGE, GraphSAGE_DGL),\n",
        "    #'PNA': (PNA, PNA_DGL)\n",
        "}\n",
        "\n",
        "datasets_pyg = {\n",
        "    'Karate Club': (dataset_karate_pyg, data_karate_pyg),\n",
        "    'Citeseer': (dataset_citeseer_pyg, data_citeseer_pyg)\n",
        "}\n",
        "\n",
        "datasets_dgl = {\n",
        "    'Karate Club': graph_karate_dgl,\n",
        "    'Citeseer': graph_citeseer_dgl\n",
        "}\n",
        "\n",
        "for model_name, (ModelPyG, ModelDGL) in models.items():\n",
        "    for dataset_name, (dataset_pyg, data_pyg) in datasets_pyg.items():\n",
        "        # Calculate degree tensor for PyG PNA model\n",
        "        if model_name == 'PNA':\n",
        "            deg = torch_geometric.utils.degree(data_pyg.edge_index[0], data_pyg.num_nodes).float()\n",
        "        for fmt in formats:\n",
        "            if model_name == 'PNA':\n",
        "                model_pyg = ModelPyG(dataset_pyg.num_features, dataset_pyg.num_classes, deg=deg)\n",
        "            else:\n",
        "                model_pyg = ModelPyG(dataset_pyg.num_features, dataset_pyg.num_classes)\n",
        "            time_cpu, mem_cpu = profile_model(model_pyg, data_pyg, device_cpu, format=fmt)\n",
        "            time_gpu, mem_gpu = profile_model(model_pyg, data_pyg, device_gpu, format=fmt)\n",
        "            print(f'PyG {dataset_name} {model_name} ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "            print(f'PyG {dataset_name} {model_name} ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n",
        "\n",
        "    for dataset_name, graph_dgl in datasets_dgl.items():\n",
        "        for fmt in formats:\n",
        "            input_dim = graph_dgl.ndata['feat'].shape[1]\n",
        "            output_dim = graph_dgl.ndata['label'].max().item() + 1\n",
        "            model_dgl = ModelDGL(input_dim, output_dim)\n",
        "            time_cpu, mem_cpu = profile_model(model_dgl, graph_dgl, device_cpu, dgl=True, format=fmt)\n",
        "            time_gpu, mem_gpu = profile_model(model_dgl, graph_dgl, device_gpu, dgl=True, format=fmt)\n",
        "            print(f'DGL {dataset_name} {model_name} ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "            print(f'DGL {dataset_name} {model_name} ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n"
      ],
      "metadata": {
        "id": "VYpLk2fou8GO",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mBt8YOXxrpRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PNA(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, deg):\n",
        "        super(PNA, self).__init__()\n",
        "        aggregators = ['mean', 'max', 'min', 'std']\n",
        "        scalers = ['identity', 'amplification', 'attenuation']\n",
        "        self.conv1 = torch_geometric.nn.PNAConv(in_channels, 16, aggregators=aggregators, scalers=scalers, deg=deg)\n",
        "        self.conv2 = torch_geometric.nn.PNAConv(16, out_channels, aggregators=aggregators, scalers=scalers, deg=deg)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        print(f\"Input features shape: {x.shape}\")\n",
        "        print(f\"Edge index shape: {edge_index.shape}\")\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        print(f\"Features after conv1: {x.shape}\")\n",
        "\n",
        "        x = F.elu(x)\n",
        "        print(f\"Features after activation: {x.shape}\")\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        print(f\"Features after conv2: {x.shape}\")\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "xNKDHMrDuo9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl.function as fn\n",
        "\n",
        "class PNAConvDGL(torch.nn.Module):\n",
        "    def __init__(self, in_feats, out_feats, aggregators=['mean', 'max', 'min'], scalers=['identity']):\n",
        "        super(PNAConvDGL, self).__init__()\n",
        "        self.in_feats = in_feats\n",
        "        self.out_feats = out_feats\n",
        "        self.aggregators = aggregators\n",
        "        self.scalers = scalers\n",
        "        self.linear = torch.nn.Linear(in_feats, out_feats)\n",
        "\n",
        "    def forward(self, g, feat):\n",
        "        with g.local_scope():\n",
        "            g.ndata['h'] = feat\n",
        "            g.update_all(fn.copy_u('h', 'm'), fn.mean('m', 'mean_h'))\n",
        "            g.update_all(fn.copy_u('h', 'm'), fn.max('m', 'max_h'))\n",
        "            g.update_all(fn.copy_u('h', 'm'), fn.min('m', 'min_h'))\n",
        "\n",
        "            h_mean = g.ndata['mean_h']\n",
        "            h_max = g.ndata['max_h']\n",
        "            h_min = g.ndata['min_h']\n",
        "\n",
        "            h = torch.cat([h_mean, h_max, h_min], dim=1)\n",
        "            h = self.linear(h)\n",
        "\n",
        "            return h\n",
        "\n",
        "class PNA_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(PNA_DGL, self).__init__()\n",
        "        self.conv1 = PNAConvDGL(in_channels, 16)\n",
        "        self.conv2 = PNAConvDGL(16, out_channels)\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(g, x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "eZ5BHpVXusml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure features and labels are set for DGL graphs\n",
        "def ensure_dgl_features_and_labels(graph, pyg_data):\n",
        "    graph.ndata['feat'] = pyg_data.x.clone().detach()\n",
        "    graph.ndata['label'] = pyg_data.y.clone().detach()\n",
        "    return graph\n",
        "\n",
        "# Define devices\n",
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define and test PNA models on COO and CSR formats\n",
        "formats = ['coo', 'csr']\n",
        "\n",
        "datasets_pyg = {\n",
        "    'Karate Club': (dataset_karate_pyg, data_karate_pyg),\n",
        "    'Citeseer': (dataset_citeseer_pyg, data_citeseer_pyg)\n",
        "}\n",
        "\n",
        "datasets_dgl = {\n",
        "    'Karate Club': graph_karate_dgl,\n",
        "    'Citeseer': graph_citeseer_dgl\n",
        "}\n",
        "\n",
        "for dataset_name, (dataset_pyg, data_pyg) in datasets_pyg.items():\n",
        "    # Calculate degree tensor for PyG PNA model\n",
        "    deg = torch_geometric.utils.degree(data_pyg.edge_index[0], data_pyg.num_nodes).float()\n",
        "    for fmt in formats:\n",
        "        model_pyg = PNA(dataset_pyg.num_features, dataset_pyg.num_classes, deg=deg)\n",
        "        time_cpu, mem_cpu = profile_model(model_pyg, data_pyg, device_cpu, format=fmt)\n",
        "        time_gpu, mem_gpu = profile_model(model_pyg, data_pyg, device_gpu, format=fmt)\n",
        "        print(f'PyG {dataset_name} PNA ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "        print(f'PyG {dataset_name} PNA ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n",
        "\n",
        "for dataset_name, graph_dgl in datasets_dgl.items():\n",
        "    for fmt in formats:\n",
        "        input_dim = graph_dgl.ndata['feat'].shape[1]\n",
        "        output_dim = graph_dgl.ndata['label'].max().item() + 1\n",
        "        model_dgl = PNA_DGL(input_dim, output_dim)\n",
        "        time_cpu, mem_cpu = profile_model(model_dgl, graph_dgl, device_cpu, dgl=True, format=fmt)\n",
        "        time_gpu, mem_gpu = profile_model(model_dgl, graph_dgl, device_gpu, dgl=True, format=fmt)\n",
        "        print(f'DGL {dataset_name} PNA ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "        print(f'DGL {dataset_name} PNA ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QvTBZjlbutST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kbCcSapvutXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data\n",
        "import dgl\n",
        "from dgl.nn.pytorch import PNAConv as PNAConvDGL\n",
        "\n",
        "# Define PNA model for PyG\n",
        "class PNA(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, deg):\n",
        "        super(PNA, self).__init__()\n",
        "        aggregators = ['mean', 'max', 'min', 'std']\n",
        "        scalers = ['identity', 'amplification', 'attenuation']\n",
        "        self.conv1 = torch_geometric.nn.PNAConv(in_channels, 16, aggregators=aggregators, scalers=scalers, deg=deg)\n",
        "        self.conv2 = torch_geometric.nn.PNAConv(16, out_channels, aggregators=aggregators, scalers=scalers, deg=deg)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Define PNA model for DGL\n",
        "import dgl.function as fn\n",
        "\n",
        "class PNAConvDGL(torch.nn.Module):\n",
        "    def __init__(self, in_feats, out_feats, aggregators=['mean', 'max', 'min'], scalers=['identity']):\n",
        "        super(PNAConvDGL, self).__init__()\n",
        "        self.in_feats = in_feats\n",
        "        self.out_feats = out_feats\n",
        "        self.aggregators = aggregators\n",
        "        self.scalers = scalers\n",
        "        self.linear = torch.nn.Linear(in_feats, out_feats)\n",
        "\n",
        "    def forward(self, g, feat):\n",
        "        with g.local_scope():\n",
        "            g.ndata['h'] = feat\n",
        "            g.update_all(fn.copy_u('h', 'm'), fn.mean('m', 'mean_h'))\n",
        "            g.update_all(fn.copy_u('h', 'm'), fn.max('m', 'max_h'))\n",
        "            g.update_all(fn.copy_u('h', 'm'), fn.min('m', 'min_h'))\n",
        "\n",
        "            h_mean = g.ndata['mean_h']\n",
        "            h_max = g.ndata['max_h']\n",
        "            h_min = g.ndata['min_h']\n",
        "\n",
        "            h = torch.cat([h_mean, h_max, h_min], dim=1)\n",
        "            h = self.linear(h)\n",
        "\n",
        "            return h\n",
        "\n",
        "class PNA_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(PNA_DGL, self).__init__()\n",
        "        self.conv1 = PNAConvDGL(in_channels, 16)\n",
        "        self.conv2 = PNAConvDGL(16, out_channels)\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(g, x)\n",
        "        return x\n",
        "\n",
        "# Ensure features and labels are set for DGL graphs\n",
        "def ensure_dgl_features_and_labels(graph, pyg_data):\n",
        "    graph.ndata['feat'] = pyg_data.x.clone().detach()\n",
        "    graph.ndata['label'] = pyg_data.y.clone().detach()\n",
        "    return graph\n",
        "\n",
        "graph_karate_dgl = ensure_dgl_features_and_labels(graph_karate_dgl, data_karate_pyg)\n",
        "graph_citeseer_dgl = ensure_dgl_features_and_labels(graph_citeseer_dgl, data_citeseer_pyg)\n",
        "\n",
        "# Define devices\n",
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define and test PNA models on COO and CSR formats\n",
        "formats = ['coo', 'csr']\n",
        "\n",
        "datasets_pyg = {\n",
        "    'Karate Club': (dataset_karate_pyg, data_karate_pyg),\n",
        "    'Citeseer': (dataset_citeseer_pyg, data_citeseer_pyg)\n",
        "}\n",
        "\n",
        "datasets_dgl = {\n",
        "    'Karate Club': graph_karate_dgl,\n",
        "    'Citeseer': graph_citeseer_dgl\n",
        "}\n",
        "\n",
        "for dataset_name, (dataset_pyg, data_pyg) in datasets_pyg.items():\n",
        "    # Calculate degree tensor for PyG PNA model\n",
        "    deg = torch_geometric.utils.degree(data_pyg.edge_index[0], data_pyg.num_nodes).float()\n",
        "    for fmt in formats:\n",
        "        model_pyg = PNA(dataset_pyg.num_features, dataset_pyg.num_classes, deg=deg)\n",
        "        time_cpu, mem_cpu = profile_model(model_pyg, data_pyg, device_cpu, format=fmt)\n",
        "        time_gpu, mem_gpu = profile_model(model_pyg, data_pyg, device_gpu, format=fmt)\n",
        "        print(f'PyG {dataset_name} PNA ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "        print(f'PyG {dataset_name} PNA ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n",
        "\n",
        "for dataset_name, graph_dgl in datasets_dgl.items():\n",
        "    for fmt in formats:\n",
        "        input_dim = graph_dgl.ndata['feat'].shape[1]\n",
        "        output_dim = graph_dgl.ndata['label'].max().item() + 1\n",
        "        model_dgl = PNA_DGL(input_dim, output_dim)\n",
        "        time_cpu, mem_cpu = profile_model(model_dgl, graph_dgl, device_cpu, dgl=True, format=fmt)\n",
        "        time_gpu, mem_gpu = profile_model(model_dgl, graph_dgl, device_gpu, dgl=True, format=fmt)\n",
        "        print(f'DGL {dataset_name} PNA ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "        print(f'DGL {dataset_name} PNA ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n"
      ],
      "metadata": {
        "id": "D6zXU89QropQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "weNQjepnuqhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5dSk_GMDvHbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### DEMO VERSION"
      ],
      "metadata": {
        "id": "55tHCyAXvID8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn.functional as F\n",
        "# from torch_geometric.data import Data\n",
        "# import torch_geometric\n",
        "# import dgl\n",
        "# from dgl.nn.pytorch import GATConv, GraphConv, SAGEConv, PNAConv\n",
        "\n",
        "# # Define GAT model for PyG\n",
        "# class GAT(torch.nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels):\n",
        "#         super(GAT, self).__init__()\n",
        "#         self.conv1 = torch_geometric.nn.GATConv(in_channels, 8, heads=8)\n",
        "#         self.conv2 = torch_geometric.nn.GATConv(8 * 8, out_channels, heads=1)\n",
        "\n",
        "#     def forward(self, data):\n",
        "#         x, edge_index = data.x, data.edge_index\n",
        "#         x = self.conv1(x, edge_index)\n",
        "#         x = F.elu(x)\n",
        "#         x = self.conv2(x, edge_index)\n",
        "#         return x\n",
        "\n",
        "# # Define GAT model for DGL\n",
        "# class GAT_DGL(torch.nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels):\n",
        "#         super(GAT_DGL, self).__init__()\n",
        "#         self.conv1 = GATConvDGL(in_channels, 8, num_heads=8)\n",
        "#         self.conv2 = GATConvDGL(8 * 8, out_channels, num_heads=1)\n",
        "\n",
        "#     def forward(self, g, features):\n",
        "#         x = self.conv1(g, features).flatten(1)\n",
        "#         x = F.elu(x)\n",
        "#         x = self.conv2(g, x).mean(1)\n",
        "#         return x\n",
        "\n",
        "\n",
        "# # Define PNA model for DGL\n",
        "# class PNA_DGL(torch.nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels):\n",
        "#         super(PNA_DGL, self).__init__()\n",
        "#         aggregators = ['mean', 'min', 'max', 'std']\n",
        "#         scalers = ['identity', 'amplification', 'attenuation']\n",
        "#         self.conv1 = PNAConv(in_channels, 16, aggregators, scalers)\n",
        "#         self.conv2 = PNAConv(16, out_channels, aggregators, scalers)\n",
        "\n",
        "#     def forward(self, g, features):\n",
        "#         x = self.conv1(g, features)\n",
        "#         x = F.relu(x)\n",
        "#         x = self.conv2(g, x)\n",
        "#         return x\n",
        "\n",
        "# # Ensure features and labels are set for DGL graphs\n",
        "# def ensure_dgl_features_and_labels(graph, pyg_data):\n",
        "#     graph.ndata['feat'] = pyg_data.x.clone().detach()\n",
        "#     graph.ndata['label'] = pyg_data.y.clone().detach()\n",
        "#     return graph\n",
        "\n",
        "# graph_karate_dgl = ensure_dgl_features_and_labels(graph_karate_dgl, data_karate_pyg)\n",
        "# graph_citeseer_dgl = ensure_dgl_features_and_labels(graph_citeseer_dgl, data_citeseer_pyg)\n",
        "\n",
        "# # Define devices\n",
        "# device_cpu = torch.device('cpu')\n",
        "# device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# # Define and test models on COO and CSR formats\n",
        "# formats = ['coo', 'csr']\n",
        "# models = {\n",
        "#     'GCN': (GCN, GCN_DGL),\n",
        "#     'GAT': (GAT, GAT_DGL),\n",
        "#     'GraphSAGE': (GraphSAGE, GraphSAGE_DGL),\n",
        "#     #'PNA': (PNA, PNA_DGL)\n",
        "# }\n",
        "\n",
        "# datasets_pyg = {\n",
        "#     'Karate Club': (dataset_karate_pyg, data_karate_pyg),\n",
        "#     'Citeseer': (dataset_citeseer_pyg, data_citeseer_pyg)\n",
        "# }\n",
        "\n",
        "# datasets_dgl = {\n",
        "#     'Karate Club': graph_karate_dgl,\n",
        "#     'Citeseer': graph_citeseer_dgl\n",
        "# }\n",
        "\n",
        "# for model_name, (ModelPyG, ModelDGL) in models.items():\n",
        "#     for dataset_name, (dataset_pyg, data_pyg) in datasets_pyg.items():\n",
        "#         for fmt in formats:\n",
        "#             model_pyg = ModelPyG(dataset_pyg.num_features, dataset_pyg.num_classes)\n",
        "#             time_cpu, mem_cpu = profile_model(model_pyg, data_pyg, device_cpu, format=fmt)\n",
        "#             time_gpu, mem_gpu = profile_model(model_pyg, data_pyg, device_gpu, format=fmt)\n",
        "#             print(f'PyG {dataset_name} {model_name} ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "#             print(f'PyG {dataset_name} {model_name} ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n",
        "\n",
        "#     for dataset_name, graph_dgl in datasets_dgl.items():\n",
        "#         for fmt in formats:\n",
        "#             input_dim = graph_dgl.ndata['feat'].shape[1]\n",
        "#             output_dim = graph_dgl.ndata['label'].max().item() + 1\n",
        "#             model_dgl = ModelDGL(input_dim, output_dim)\n",
        "#             time_cpu, mem_cpu = profile_model(model_dgl, graph_dgl, device_cpu, dgl=True, format=fmt)\n",
        "#             time_gpu, mem_gpu = profile_model(model_dgl, graph_dgl, device_gpu, dgl=True, format=fmt)\n",
        "#             print(f'DGL {dataset_name} {model_name} ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "#             print(f'DGL {dataset_name} {model_name} ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n"
      ],
      "metadata": {
        "id": "JdEmDhqJpEk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Models with COO and CSR on CPU and GPU"
      ],
      "metadata": {
        "id": "7CvDNY88woUM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define devices"
      ],
      "metadata": {
        "id": "Bl-4O69hw3PI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "TclZ_ZdZw6ZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test GCN on CPU and GPU for PyG Karate ClubB"
      ],
      "metadata": {
        "id": "TKpJPlFNw8X8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_model_pyg = GCN(dataset_karate_pyg.num_features, dataset_karate_pyg.num_classes)\n",
        "time_cpu, mem_cpu = profile_model(gcn_model_pyg, data_karate_pyg, device_cpu, format='coo')\n",
        "time_gpu, mem_gpu = profile_model(gcn_model_pyg, data_karate_pyg, device_gpu, format='coo')\n",
        "print(f'PyG Karate Club GCN on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "print(f'PyG Karate Club GCN on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n"
      ],
      "metadata": {
        "id": "OnZNIRzCxA-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test GCN on CPU and GPU for PyG Citeseer"
      ],
      "metadata": {
        "id": "SG8-Gyq1xD8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_model_pyg = GCN(dataset_citeseer_pyg.num_features, dataset_citeseer_pyg.num_classes)\n",
        "time_cpu, mem_cpu = profile_model(gcn_model_pyg, data_citeseer_pyg, device_cpu, format='csr')\n",
        "time_gpu, mem_gpu = profile_model(gcn_model_pyg, data_citeseer_pyg, device_gpu, format='csr')\n",
        "print(f'PyG Citeseer GCN on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "print(f'PyG Citeseer GCN on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n"
      ],
      "metadata": {
        "id": "uA1BpiguxLEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test GCN on CPU and GPU for DGL Karate Club"
      ],
      "metadata": {
        "id": "g8Ohm2YZxNCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`feat` error solver -v"
      ],
      "metadata": {
        "id": "_30haT4xyOnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Karate Club dataset\n",
        "dataset_karate_dgl = KarateClubDataset()\n",
        "graph_karate_dgl = dataset_karate_dgl[0]\n",
        "\n",
        "# Add dummy features (e.g., use one-hot encoding for simplicity)\n",
        "num_nodes = graph_karate_dgl.num_nodes()\n",
        "graph_karate_dgl.ndata['feat'] = torch.eye(num_nodes)\n",
        "\n",
        "# Add labels\n",
        "graph_karate_dgl.ndata['label'] = torch.tensor(graph_karate_dgl.ndata['label'])\n"
      ],
      "metadata": {
        "id": "AaOYF3EwyD6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_model_dgl = GCN_DGL(graph_karate_dgl.ndata['feat'].shape[1], graph_karate_dgl.ndata['label'].max().item() + 1)\n",
        "time_cpu, mem_cpu = profile_model(gcn_model_dgl, graph_karate_dgl, device_cpu, dgl=True, format='coo')\n",
        "time_gpu, mem_gpu = profile_model(gcn_model_dgl, graph_karate_dgl, device_gpu, dgl=True, format='coo')\n",
        "print(f'DGL Karate Club GCN on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "print(f'DGL Karate Club GCN on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n"
      ],
      "metadata": {
        "id": "UWygavUzxUk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test GCN on CPU and GPU for DGL Citeseer"
      ],
      "metadata": {
        "id": "j16XGpR7xZo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_model_dgl = GCN_DGL(graph_citeseer_dgl.ndata['feat'].shape[1], graph_citeseer_dgl.ndata['label'].max().item() + 1)\n",
        "time_cpu, mem_cpu = profile_model(gcn_model_dgl, graph_citeseer_dgl, device_cpu, dgl=True, format='csr')\n",
        "time_gpu, mem_gpu = profile_model(gcn_model_dgl, graph_citeseer_dgl, device_gpu, dgl=True, format='csr')\n",
        "print(f'DGL Citeseer GCN on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "print(f'DGL Citeseer GCN on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')"
      ],
      "metadata": {
        "id": "niT3DJBsyeUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "C6FNIdooz1mB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More coplex datasets"
      ],
      "metadata": {
        "id": "T9heMbv6yg_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Complex Datasets and Profiling\n",
        "Define Profiling Function"
      ],
      "metadata": {
        "id": "s8Wl1xB4z0up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def profile_model(model, data, device, dgl=False, format='coo'):\n",
        "    model = model.to(device)\n",
        "    data = data.to(device)\n",
        "\n",
        "    def run_model():\n",
        "        model.train()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "        for _ in range(1):  # Run for one epoch to measure time\n",
        "            optimizer.zero_grad()\n",
        "            if dgl:\n",
        "                if format == 'csr':\n",
        "                    logits = model(data, data.ndata['feat'])\n",
        "                else:\n",
        "                    logits = model(data, data.ndata['feat'])\n",
        "            else:\n",
        "                logits = model(data)\n",
        "            loss = F.cross_entropy(logits[data.y_index], data.y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Measure time\n",
        "    start_time = time.time()\n",
        "    run_model()\n",
        "    end_time = time.time()\n",
        "    time_taken = end_time - start_time\n",
        "\n",
        "    # Measure memory\n",
        "    mem_usage = memory_usage(run_model, max_usage=True, retval=False)\n",
        "    peak_memory = max(mem_usage)\n",
        "\n",
        "    return time_taken, peak_memory"
      ],
      "metadata": {
        "id": "tzO6MQiFz6tS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Complex Datasets"
      ],
      "metadata": {
        "id": "stnNJsyuPwdR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load PyG Datasets"
      ],
      "metadata": {
        "id": "xJgdsgUuQRe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import Reddit, Amazon"
      ],
      "metadata": {
        "id": "eOf49A9WP3Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_reddit_pyg = Reddit(root='/tmp/Reddit')\n",
        "data_reddit_pyg = dataset_reddit_pyg[0]\n",
        "\n",
        "dataset_amazon_pyg = Amazon(root='/tmp/Amazon', name='Computers')\n",
        "data_amazon_pyg = dataset_amazon_pyg[0]"
      ],
      "metadata": {
        "id": "m8j8CWSZP7Hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load DGL Datasets"
      ],
      "metadata": {
        "id": "P_Z60L5OQZlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dgl.data import RedditDataset, AmazonCoBuyComputerDataset"
      ],
      "metadata": {
        "id": "NhPU8h1rQcrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_reddit_dgl():\n",
        "    dataset = RedditDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "def load_amazon_dgl():\n",
        "    dataset = AmazonCoBuyComputerDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "graph_reddit_dgl = load_reddit_dgl()\n",
        "graph_amazon_dgl = load_amazon_dgl()"
      ],
      "metadata": {
        "id": "zRe38T83QeOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Models on Complex Datasets"
      ],
      "metadata": {
        "id": "tVi6OyLeQkER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define devices\n",
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "y4UKYg6_QmOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define and test models"
      ],
      "metadata": {
        "id": "TSXvUKvGQpi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'GCN': (GCN, GCN_DGL),\n",
        "    'GAT': (GAT, GATConvDGL),\n",
        "    'GraphSAGE': (GraphSAGE, SAGEConvDGL),\n",
        "    'PNA': (PNA, PNAConv)\n",
        "}\n",
        "\n",
        "datasets_pyg = {\n",
        "    'Reddit': data_reddit_pyg,\n",
        "    'Amazon': data_amazon_pyg\n",
        "}\n",
        "\n",
        "datasets_dgl = {\n",
        "    'Reddit': graph_reddit_dgl,\n",
        "    'Amazon': graph_amazon_dgl\n",
        "}"
      ],
      "metadata": {
        "id": "EyP3KR5UQsI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, (ModelPyG, ModelDGL) in models.items():\n",
        "    for dataset_name, data_pyg in datasets_pyg.items():\n",
        "        # PyG Models\n",
        "        model_pyg = ModelPyG(data_pyg.num_features, data_pyg.num_classes)\n",
        "        time_cpu, mem_cpu = profile_model(model_pyg, data_pyg, device_cpu, format='coo')\n",
        "        time_gpu, mem_gpu = profile_model(model_pyg, data_pyg, device_gpu, format='coo')\n",
        "        print(f'PyG {dataset_name} {model_name} on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "        print(f'PyG {dataset_name} {model_name} on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n",
        "\n",
        "    for dataset_name, graph_dgl in datasets_dgl.items():\n",
        "        # DGL Models\n",
        "        model_dgl = ModelDGL(graph_dgl.ndata['feat'].shape[1], graph_dgl.ndata['label'].max().item() + 1)\n",
        "        time_cpu, mem_cpu = profile_model(model_dgl, graph_dgl, device_cpu, dgl=True, format='coo')\n",
        "        time_gpu, mem_gpu = profile_model(model_dgl, graph_dgl, device_gpu, dgl=True, format='coo')\n",
        "        print(f'DGL {dataset_name} {model_name} on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "        print(f'DGL {dataset_name} {model_name} on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')"
      ],
      "metadata": {
        "id": "u0pnOONpQvPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ERROR : Your session crashed after using all available RAM"
      ],
      "metadata": {
        "id": "LMmkbIwST5PL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intermediate Complexity Datasets"
      ],
      "metadata": {
        "id": "0tMEurshUask"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Intermediate Complexity Datasets"
      ],
      "metadata": {
        "id": "KvMgph9BUiug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "from dgl.data import CoraGraphDataset, PubmedGraphDataset, CiteseerGraphDataset\n",
        "\n",
        "# Load PyG Datasets\n",
        "dataset_cora_pyg = Planetoid(root='/tmp/Cora', name='Cora')\n",
        "data_cora_pyg = dataset_cora_pyg[0]\n",
        "\n",
        "dataset_pubmed_pyg = Planetoid(root='/tmp/Pubmed', name='Pubmed')\n",
        "data_pubmed_pyg = dataset_pubmed_pyg[0]\n",
        "\n",
        "dataset_citeseer_pyg = Planetoid(root='/tmp/Citeseer', name='Citeseer')\n",
        "data_citeseer_pyg = dataset_citeseer_pyg[0]\n",
        "\n",
        "# Load DGL Datasets\n",
        "def load_cora_dgl():\n",
        "    dataset = CoraGraphDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "def load_pubmed_dgl():\n",
        "    dataset = PubmedGraphDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "def load_citeseer_dgl():\n",
        "    dataset = CiteseerGraphDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "graph_cora_dgl = load_cora_dgl()\n",
        "graph_pubmed_dgl = load_pubmed_dgl()\n",
        "graph_citeseer_dgl = load_citeseer_dgl()\n"
      ],
      "metadata": {
        "id": "pUwXlZpKUj5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Models on Intermediate Datasets"
      ],
      "metadata": {
        "id": "5AeZ-5-aVL0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define devices\n",
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define and test models\n",
        "models = {\n",
        "    'GCN': (GCN, GCN_DGL),\n",
        "    'GAT': (GAT, GATConvDGL),\n",
        "    'GraphSAGE': (GraphSAGE, SAGEConvDGL),\n",
        "    'PNA': (PNA, PNAConv)\n",
        "}\n",
        "\n",
        "datasets_pyg = {\n",
        "    'Cora': data_cora_pyg,\n",
        "    'PubMed': data_pubmed_pyg,\n",
        "    'CiteSeer': data_citeseer_pyg\n",
        "}\n",
        "\n",
        "datasets_dgl = {\n",
        "    'Cora': graph_cora_dgl,\n",
        "    'PubMed': graph_pubmed_dgl,\n",
        "    'CiteSeer': graph_citeseer_dgl\n",
        "}\n",
        "\n",
        "for model_name, (ModelPyG, ModelDGL) in models.items():\n",
        "    for dataset_name, data_pyg in datasets_pyg.items():\n",
        "        # PyG Models\n",
        "        model_pyg = ModelPyG(data_pyg.num_features, data_pyg.num_classes)\n",
        "        time_cpu, mem_cpu = profile_model(model_pyg, data_pyg, device_cpu, format='coo')\n",
        "        time_gpu, mem_gpu = profile_model(model_pyg, data_pyg, device_gpu, format='coo')\n",
        "        print(f'PyG {dataset_name} {model_name} on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "        print(f'PyG {dataset_name} {model_name} on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n",
        "\n",
        "    for dataset_name, graph_dgl in datasets_dgl.items():\n",
        "        # DGL Models\n",
        "        model_dgl = ModelDGL(graph_dgl.ndata['feat'].shape[1], graph_dgl.ndata['label'].max().item() + 1)\n",
        "        time_cpu, mem_cpu = profile_model(model_dgl, graph_dgl, device_cpu, dgl=True, format='coo')\n",
        "        time_gpu, mem_gpu = profile_model(model_dgl, graph_dgl, device_gpu, dgl=True, format='coo')\n",
        "        print(f'DGL {dataset_name} {model_name} on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "        print(f'DGL {dataset_name} {model_name} on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n"
      ],
      "metadata": {
        "id": "K0_fuc0RVNYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hb8LlkCjVRaZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}