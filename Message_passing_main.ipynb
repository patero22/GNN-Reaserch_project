{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patero22/GNN-Reaserch_project/blob/main/Message_passing_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementacja w PyTorch Geometric (PyG)\n"
      ],
      "metadata": {
        "id": "ejterDt3Jfx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvmxFQgGKABg",
        "outputId": "67341df4-712f-43ac-b02b-2ca3c1106ae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.6.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.5.0)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "\n",
        "# Pobieranie zbioru danych Planetoid o nazwie Cora z użyciem transformacji NormalizeFeatures\n",
        "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
        "\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('======================')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')\n",
        "\n",
        "data = dataset[0]  # Pobranie pierwszego obiektu grafu z zbioru danych.\n",
        "\n",
        "print(data)\n",
        "print('===========================================================================================================')\n",
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
        "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
        "print(f'Has self-loops: {data.has_self_loops()}')\n",
        "print(f'Is undirected: {data.is_undirected()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkJWVRotKdwT",
        "outputId": "30f607a4-5dc7-4dd7-a37a-522d557f7d6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: Cora():\n",
            "======================\n",
            "Number of graphs: 1\n",
            "Number of features: 1433\n",
            "Number of classes: 7\n",
            "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
            "===========================================================================================================\n",
            "Number of nodes: 2708\n",
            "Number of edges: 10556\n",
            "Average node degree: 3.90\n",
            "Number of training nodes: 140\n",
            "Training node label rate: 0.05\n",
            "Has isolated nodes: False\n",
            "Has self-loops: False\n",
            "Is undirected: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementacja Message Passing w PyTorch Geometric\n"
      ],
      "metadata": {
        "id": "2H5--0S6LA4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import add_self_loops\n",
        "\n",
        "class GNNConv(MessagePassing):\n",
        "    def __init__(self):\n",
        "        super(GNNConv, self).__init__(aggr='add')  # Agregacja przez sumowanie.\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # Dodawanie pętli własnych do macierzy sąsiedztwa.\n",
        "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "\n",
        "        # Liniowa transformacja macierzy cech węzłów.\n",
        "        x = F.linear(x, torch.ones(x.size(1), x.size(1)))  # Przykładowa transformacja liniowa.\n",
        "\n",
        "        # Obliczanie normalizacji.\n",
        "        row, col = edge_index\n",
        "        deg = torch.bincount(row, minlength=x.size(0)).float()\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "        # Propagacja wiadomości.\n",
        "        return self.propagate(edge_index, x=x, norm=norm)\n",
        "\n",
        "    def message(self, x_j, norm):\n",
        "        # Normalizacja cech węzłów.\n",
        "        return norm.view(-1, 1) * x_j\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        # Zwracanie nowych osadzeń węzłów.\n",
        "        return aggr_out\n",
        "\n",
        "# Tworzenie obiektu Data i modelu\n",
        "conv = GNNConv()\n",
        "output = conv(data.x, data.edge_index)\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFXHBK49KgTx",
        "outputId": "b57db604-68ca-41d8-8d54-fc8e28ff8b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9736, 0.9736, 0.9736,  ..., 0.9736, 0.9736, 0.9736],\n",
            "        [1.0964, 1.0964, 1.0964,  ..., 1.0964, 1.0964, 1.0964],\n",
            "        [1.0307, 1.0307, 1.0307,  ..., 1.0307, 1.0307, 1.0307],\n",
            "        ...,\n",
            "        [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
            "        [1.0582, 1.0582, 1.0582,  ..., 1.0582, 1.0582, 1.0582],\n",
            "        [0.8767, 0.8767, 0.8767,  ..., 0.8767, 0.8767, 0.8767]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementacja Message Passing w Deep Graph Library (DGL)\n"
      ],
      "metadata": {
        "id": "5PMke4fyLG5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL7ZcqjpLXEq",
        "outputId": "d27b45b0-8e06-4bfa-ffcf-35e7cbf0594a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dgl\n",
            "  Downloading dgl-2.1.0-cp310-cp310-manylinux1_x86_64.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Collecting torchdata>=0.5.0 (from dgl)\n",
            "  Downloading torchdata-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.6.2)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.5.0->dgl) (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (1.12.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata>=0.5.0->dgl) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchdata, dgl\n",
            "Successfully installed dgl-2.1.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 torchdata-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.0.1\n",
        "!pip install dgl==1.1.0 -f https://data.dgl.ai/wheels/repo.html\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sntRWYQMN6s",
        "outputId": "b0406408-962a-49c2-a5f5-2acc02d9094c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (18.1.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Looking in links: https://data.dgl.ai/wheels/repo.html\n",
            "Collecting dgl==1.1.0\n",
            "  Using cached dgl-1.1.0-cp310-cp310-manylinux1_x86_64.whl (5.9 MB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl==1.1.0) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl==1.1.0) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl==1.1.0) (3.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl==1.1.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl==1.1.0) (4.66.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl==1.1.0) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==1.1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==1.1.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==1.1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==1.1.0) (2024.6.2)\n",
            "Installing collected packages: dgl\n",
            "  Attempting uninstall: dgl\n",
            "    Found existing installation: dgl 2.1.0\n",
            "    Uninstalling dgl-2.1.0:\n",
            "      Successfully uninstalled dgl-2.1.0\n",
            "Successfully installed dgl-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "from torch_geometric.utils import add_self_loops\n",
        "import dgl\n",
        "import dgl.function as fn\n",
        "\n",
        "# Pobieranie zbioru danych Planetoid o nazwie Cora z użyciem transformacji NormalizeFeatures\n",
        "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
        "\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('======================')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')\n",
        "\n",
        "data = dataset[0]\n",
        "\n",
        "print()\n",
        "print(data)\n",
        "print('===========================================================================================================')\n",
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
        "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
        "print(f'Has self-loops: {data.has_self_loops()}')\n",
        "print(f'Is undirected: {data.is_undirected()}')\n",
        "\n",
        "# Implementacja Message Passing w PyTorch Geometric\n",
        "class GNNConv(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GNNConv, self).__init__()\n",
        "        self.aggr = 'add'  # Agregacja przez sumowanie.\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # Dodawanie pętli własnych do macierzy sąsiedztwa.\n",
        "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "\n",
        "        # Liniowa transformacja macierzy cech węzłów.\n",
        "        x = F.linear(x, torch.ones(x.size(1), x.size(1)))  # Przykładowa transformacja liniowa.\n",
        "\n",
        "        # Obliczanie normalizacji.\n",
        "        row, col = edge_index\n",
        "        deg = torch.bincount(row, minlength=x.size(0)).float()\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "        # Propagacja wiadomości.\n",
        "        return self.propagate(edge_index, x=x, norm=norm)\n",
        "\n",
        "    def propagate(self, edge_index, x, norm):\n",
        "        row, col = edge_index\n",
        "        out = torch.zeros_like(x)\n",
        "        for i in range(len(row)):\n",
        "            out[row[i]] += norm[i] * x[col[i]]\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j, norm):\n",
        "        # Normalizacja cech węzłów.\n",
        "        return norm.view(-1, 1) * x_j\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        # Zwracanie nowych osadzeń węzłów.\n",
        "        return aggr_out\n",
        "\n",
        "# Tworzenie obiektu Data i modelu\n",
        "conv = GNNConv()\n",
        "output = conv(data.x, data.edge_index)\n",
        "print(output)\n",
        "\n",
        "# Implementacja Message Passing w Deep Graph Library (DGL)\n",
        "# Tworzenie grafu DGL z danych PyTorch Geometric\n",
        "src, dst = data.edge_index\n",
        "g = dgl.graph((src, dst))\n",
        "g = dgl.add_self_loop(g)\n",
        "g.ndata['feat'] = data.x\n",
        "\n",
        "class GNNLayer(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GNNLayer, self).__init__()\n",
        "\n",
        "    def forward(self, g, feature):\n",
        "        # Liniowa transformacja cech węzłów.\n",
        "        feature = F.linear(feature, torch.ones(feature.size(1), feature.size(1)))  # Przykładowa transformacja liniowa.\n",
        "\n",
        "        # Normalizacja\n",
        "        degs = g.in_degrees().float().clamp(min=1)\n",
        "        norm = torch.pow(degs, -0.5).to(feature.device).unsqueeze(1)\n",
        "        g.ndata['h'] = feature * norm\n",
        "\n",
        "        # Propagacja wiadomości\n",
        "        g.update_all(fn.copy_u(u='h', out='m'), fn.sum(msg='m', out='h'))\n",
        "        g.ndata['h'] = g.ndata['h'] * norm\n",
        "\n",
        "        return g.ndata.pop('h')\n",
        "\n",
        "# Tworzenie modelu i przekazanie danych\n",
        "conv = GNNLayer()\n",
        "output = conv(g, g.ndata['feat'])\n",
        "print(output)\n",
        "\n",
        "# Porównanie wydajności\n",
        "import time\n",
        "\n",
        "# Pomiar czasu dla PyTorch Geometric\n",
        "conv = GNNConv()\n",
        "start_time = time.time()\n",
        "for _ in range(100):\n",
        "    output = conv(data.x, data.edge_index)\n",
        "print(f'PyTorch Geometric: {(time.time() - start_time) / 100:.6f} seconds per iteration')\n",
        "\n",
        "# Pomiar czasu dla DGL\n",
        "conv = GNNLayer()\n",
        "start_time = time.time()\n",
        "for _ in range(100):\n",
        "    output = conv(g, g.ndata['feat'])\n",
        "print(f'DGL: {(time.time() - start_time) / 100:.6f} seconds per iteration')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gbf_drj-LJoH",
        "outputId": "db1b7ea9-e677-44b4-e42e-ae2ab4afe872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: Cora():\n",
            "======================\n",
            "Number of graphs: 1\n",
            "Number of features: 1433\n",
            "Number of classes: 7\n",
            "\n",
            "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
            "===========================================================================================================\n",
            "Number of nodes: 2708\n",
            "Number of edges: 10556\n",
            "Average node degree: 3.90\n",
            "Number of training nodes: 140\n",
            "Training node label rate: 0.05\n",
            "Has isolated nodes: False\n",
            "Has self-loops: False\n",
            "Is undirected: True\n",
            "tensor([[0.9736, 0.9736, 0.9736,  ..., 0.9736, 0.9736, 0.9736],\n",
            "        [1.0964, 1.0964, 1.0964,  ..., 1.0964, 1.0964, 1.0964],\n",
            "        [1.0307, 1.0307, 1.0307,  ..., 1.0307, 1.0307, 1.0307],\n",
            "        ...,\n",
            "        [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
            "        [1.0582, 1.0582, 1.0582,  ..., 1.0582, 1.0582, 1.0582],\n",
            "        [0.8767, 0.8767, 0.8767,  ..., 0.8767, 0.8767, 0.8767]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/tensor.py:449: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  assert input.numel() == input.storage().size(), (\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9736, 0.9736, 0.9736,  ..., 0.9736, 0.9736, 0.9736],\n",
            "        [1.0964, 1.0964, 1.0964,  ..., 1.0964, 1.0964, 1.0964],\n",
            "        [1.0307, 1.0307, 1.0307,  ..., 1.0307, 1.0307, 1.0307],\n",
            "        ...,\n",
            "        [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
            "        [1.0582, 1.0582, 1.0582,  ..., 1.0582, 1.0582, 1.0582],\n",
            "        [0.8767, 0.8767, 0.8767,  ..., 0.8767, 0.8767, 0.8767]])\n",
            "PyTorch Geometric: 0.659531 seconds per iteration\n",
            "DGL: 0.214324 seconds per iteration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementacje Message Passing\n",
        "PyTorch Geometric\n"
      ],
      "metadata": {
        "id": "CDnSxLSFQyZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GNNConv(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GNNConv, self).__init__()\n",
        "        self.aggr = 'add'  # Agregacja przez sumowanie.\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # Dodawanie pętli własnych do macierzy sąsiedztwa.\n",
        "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "\n",
        "        # Liniowa transformacja macierzy cech węzłów.\n",
        "        x = F.linear(x, torch.ones(x.size(1), x.size(1)))  # Przykładowa transformacja liniowa.\n",
        "\n",
        "        # Obliczanie normalizacji.\n",
        "        row, col = edge_index\n",
        "        deg = torch.bincount(row, minlength=x.size(0)).float()\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "        # Propagacja wiadomości.\n",
        "        return self.propagate(edge_index, x=x, norm=norm)\n",
        "\n",
        "    def propagate(self, edge_index, x, norm):\n",
        "        row, col = edge_index\n",
        "        out = torch.zeros_like(x)\n",
        "        for i in range(len(row)):\n",
        "            out[row[i]] += norm[i] * x[col[i]]\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j, norm):\n",
        "        return norm.view(-1, 1) * x_j\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        return aggr_out\n"
      ],
      "metadata": {
        "id": "cuW26gIJQzWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep Graph Library (DGL)"
      ],
      "metadata": {
        "id": "7U5MP0MoQ46K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GNNLayer(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GNNLayer, self).__init__()\n",
        "\n",
        "    def forward(self, g, feature):\n",
        "        # Liniowa transformacja cech węzłów.\n",
        "        feature = F.linear(feature, torch.ones(feature.size(1), feature.size(1)))  # Przykładowa transformacja liniowa.\n",
        "\n",
        "        # Normalizacja\n",
        "        degs = g.in_degrees().float().clamp(min=1)\n",
        "        norm = torch.pow(degs, -0.5).to(feature.device).unsqueeze(1)\n",
        "        g.ndata['h'] = feature * norm\n",
        "\n",
        "        # Propagacja wiadomości\n",
        "        g.update_all(fn.copy_u(u='h', out='m'), fn.sum(msg='m', out='h'))\n",
        "        g.ndata['h'] = g.ndata['h'] * norm\n",
        "\n",
        "        return g.ndata.pop('h')\n"
      ],
      "metadata": {
        "id": "ZiU9f8AYQ4T1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Porównanie wydajności"
      ],
      "metadata": {
        "id": "ujyCliaiRC5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Pomiar czasu dla PyTorch Geometric\n",
        "conv = GNNConv()\n",
        "start_time = time.time()\n",
        "for _ in range(100):\n",
        "    output = conv(data.x, data.edge_index)\n",
        "print(f'PyTorch Geometric: {(time.time() - start_time) / 100:.6f} seconds per iteration')\n",
        "\n",
        "# Pomiar czasu dla DGL\n",
        "conv = GNNLayer()\n",
        "start_time = time.time()\n",
        "for _ in range(100):\n",
        "    output = conv(g, g.ndata['feat'])\n",
        "print(f'DGL: {(time.time() - start_time) / 100:.6f} seconds per iteration')\n"
      ],
      "metadata": {
        "id": "8zUI5h4vRAdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3977032c-0a2c-4f40-b959-6d3201b68ee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Geometric: 0.586509 seconds per iteration\n",
            "DGL: 0.229661 seconds per iteration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Format danych: COO vs. CSR\n",
        "\n",
        "    COO (Coordinate Format):\n",
        "        Reprezentuje graf za pomocą listy krawędzi, gdzie każda krawędź jest określona przez parę (źródło, cel).\n",
        "        Stosowany do dynamicznych grafów, gdzie krawędzie mogą być często dodawane lub usuwane.\n",
        "        PyTorch Geometric używa formatu COO do reprezentowania grafów (macierz edge_index).\n",
        "\n",
        "    CSR (Compressed Sparse Row):\n",
        "        Reprezentuje graf za pomocą dwóch tablic: jednej dla węzłów, a drugiej dla wartości.\n",
        "        Lepszy do operacji macierzowych, np. mnożenia macierzy.\n",
        "        DGL wspiera oba formaty, ale często używa CSR dla wydajności operacji macierzowych."
      ],
      "metadata": {
        "id": "s4dymGmvRVOO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch Geometric (PyG)\n",
        "\n",
        "PyTorch Geometric używa formatu COO do przechowywania grafów, co można zobaczyć w strukturze edge_index. Ten format jest bezpośrednio używany w procesie propagacji wiadomości:"
      ],
      "metadata": {
        "id": "ScJdlT40RWM_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "row, col = edge_index\n"
      ],
      "metadata": {
        "id": "5BCHYORURahl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep Graph Library (DGL)\n",
        "\n",
        "DGL domyślnie używa formatu CSR, ale wspiera także format COO. Format CSR jest bardziej wydajny przy wykonywaniu operacji algebraicznych na dużych grafach. W DGL, graf jest tworzony z danych w formacie COO, ale może być przechowywany i przetwarzany w formacie CSR dla lepszej wydajności:\n",
        "\n",
        "g = dgl.graph((torch.tensor(data.edge_index[0]), torch.tensor(data.edge_index[1])))\n",
        "g = dgl.add_self_loop(g)\n"
      ],
      "metadata": {
        "id": "lQYdqp7eRggY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wnioski\n",
        "\n",
        "    Wydajność:\n",
        "        PyTorch Geometric (COO): Jest bardziej elastyczny przy dynamicznych zmianach w strukturze grafu, ale może być mniej wydajny przy operacjach algebraicznych na dużych grafach.\n",
        "        DGL (CSR): Jest bardziej wydajny przy operacjach algebraicznych na dużych grafach, ale mniej elastyczny przy dynamicznych zmianach.\n",
        "\n",
        "    Użycie:\n",
        "        Wybór między PyTorch Geometric a DGL zależy od konkretnego zastosowania. Jeśli operacje na grafie są głównie statyczne i algebraiczne, DGL może być bardziej odpowiedni. Jeśli struktura grafu często się zmienia, PyTorch Geometric może być lepszym wyborem."
      ],
      "metadata": {
        "id": "-RSmfGZdRlRm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kilka popularnych dużych zbiorów danych dla grafów to:\n",
        "\n",
        "    Amazon Computers and Photo:\n",
        "        Graf zakupów na Amazonie, gdzie węzły reprezentują produkty, a krawędzie współzakupy.\n",
        "        Dane dostępne w torch_geometric.datasets.Amazon.\n",
        "\n",
        "    Reddit:\n",
        "        Graf interakcji użytkowników Reddita.\n",
        "        Dane dostępne w torch_geometric.datasets.Reddit.\n",
        "\n",
        "    OGB (Open Graph Benchmark):\n",
        "        Zbiory danych dla dużych grafów, takie jak ogbn-arxiv, ogbn-products, itd.\n",
        "        Dane dostępne w ogb.nodeproppred (dla klasyfikacji węzłów)."
      ],
      "metadata": {
        "id": "BqnWvurqUGdg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementacja na Zbiorze Danych Amazon Computers i Photo\n",
        "PyTorch Geometric"
      ],
      "metadata": {
        "id": "QJSCNSwgUPXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import Amazon\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "import time\n",
        "\n",
        "# Amazon Computers\n",
        "dataset_computers = Amazon(root='data/AmazonComputers', name='Computers', transform=NormalizeFeatures())\n",
        "data_computers = dataset_computers[0]\n",
        "\n",
        "# Amazon Photo\n",
        "dataset_photo = Amazon(root='data/AmazonPhoto', name='Photo', transform=NormalizeFeatures())\n",
        "data_photo = dataset_photo[0]\n",
        "\n",
        "# Definicja funkcji testującej\n",
        "def test_pyg(dataset):\n",
        "    conv_pyg = GNNConv()\n",
        "    start_time = time.time()\n",
        "    for _ in range(100):\n",
        "        output = conv_pyg(dataset.x, dataset.edge_index)\n",
        "    return (time.time() - start_time) / 100\n",
        "\n",
        "print(f'PyTorch Geometric Amazon Computers: {test_pyg(data_computers):.6f} seconds per iteration')\n",
        "print(f'PyTorch Geometric Amazon Photo: {test_pyg(data_photo):.6f} seconds per iteration')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "M57pfosMURgl",
        "outputId": "7990233f-6f15-40bb-b148-35a0c601a734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/shchur/gnn-benchmark/raw/master/data/npz/amazon_electronics_computers.npz\n",
            "Processing...\n",
            "Done!\n",
            "Downloading https://github.com/shchur/gnn-benchmark/raw/master/data/npz/amazon_electronics_photo.npz\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Geometric Amazon Computers: 14.390730 seconds per iteration\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a12287b22cb8>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'PyTorch Geometric Amazon Computers: {test_pyg(data_computers):.6f} seconds per iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'PyTorch Geometric Amazon Photo: {test_pyg(data_photo):.6f} seconds per iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-a12287b22cb8>\u001b[0m in \u001b[0;36mtest_pyg\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_pyg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-a5ea9b89aeb7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Liniowa transformacja macierzy cech węzłów.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Przykładowa transformacja liniowa.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Obliczanie normalizacji.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementacja na Zbiorze Danych Amazon Computers i Photo\n",
        "DGL - Deep Graph Library"
      ],
      "metadata": {
        "id": "B-lRURILUeOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dgl.data import AmazonCoBuyComputerDataset, AmazonCoBuyPhotoDataset\n",
        "\n",
        "# Amazon Computers\n",
        "dataset_computers_dgl = AmazonCoBuyComputerDataset()\n",
        "g_computers_dgl = dataset_computers_dgl[0]\n",
        "\n",
        "# Amazon Photo\n",
        "dataset_photo_dgl = AmazonCoBuyPhotoDataset()\n",
        "g_photo_dgl = dataset_photo_dgl[0]\n",
        "\n",
        "# Dodanie samopętli\n",
        "g_computers_dgl = dgl.add_self_loop(g_computers_dgl)\n",
        "g_photo_dgl = dgl.add_self_loop(g_photo_dgl)\n",
        "\n",
        "# Definicja funkcji testującej\n",
        "def test_dgl(graph):\n",
        "    conv_dgl = GNNLayer()\n",
        "    start_time = time.time()\n",
        "    for _ in range(100):\n",
        "        output = conv_dgl(graph, graph.ndata['feat'])\n",
        "    return (time.time() - start_time) / 100\n",
        "\n",
        "print(f'DGL Amazon Computers: {test_dgl(g_computers_dgl):.6f} seconds per iteration')\n",
        "print(f'DGL Amazon Photo: {test_dgl(g_photo_dgl):.6f} seconds per iteration')\n"
      ],
      "metadata": {
        "id": "AerRhdW1UbxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementacja na Zbiorze Danych Reddit\n",
        "PyTorch Geometric"
      ],
      "metadata": {
        "id": "nJ5talA9Uqfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import Reddit\n",
        "\n",
        "# Reddit\n",
        "dataset_reddit = Reddit(root='data/Reddit')\n",
        "data_reddit = dataset_reddit[0]\n",
        "\n",
        "print(f'Number of nodes: {data_reddit.num_nodes}')\n",
        "print(f'Number of edges: {data_reddit.num_edges}')\n",
        "\n",
        "print(f'PyTorch Geometric Reddit: {test_pyg(data_reddit):.6f} seconds per iteration')\n"
      ],
      "metadata": {
        "id": "0jm0IfMEUrEw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "f71c0459-0490-41d7-ab5e-9bbbc48b2aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://data.dgl.ai/dataset/reddit.zip\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-514ac8b321b9>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Reddit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdataset_reddit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReddit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'data/Reddit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdata_reddit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_reddit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/datasets/reddit.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform, force_reload)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mforce_reload\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     ) -> None:\n\u001b[0;32m---> 61\u001b[0;31m         super().__init__(root, transform, pre_transform,\n\u001b[0m\u001b[1;32m     62\u001b[0m                          force_reload=force_reload)\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/in_memory_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log, force_reload)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mforce_reload\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     ) -> None:\n\u001b[0;32m---> 81\u001b[0;31m         super().__init__(root, transform, pre_transform, pre_filter, log,\n\u001b[0m\u001b[1;32m     82\u001b[0m                          force_reload)\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log, force_reload)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_download\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_process\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m_download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/datasets/reddit.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mextract_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/data/download.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, folder, log, filename)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# workaround for https://bugs.python.org/issue42853\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    464\u001b[0m                 \u001b[0;31m# clip the read to the \"end of response\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0mamt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                 \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DGL"
      ],
      "metadata": {
        "id": "Gk3YQCNDUvwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dgl.data import RedditDataset\n",
        "\n",
        "# Reddit\n",
        "dataset_reddit_dgl = RedditDataset()\n",
        "g_reddit_dgl = dataset_reddit_dgl[0]\n",
        "\n",
        "# Dodanie samopętli\n",
        "g_reddit_dgl = dgl.add_self_loop(g_reddit_dgl)\n",
        "\n",
        "print(f'DGL Reddit: {test_dgl(g_reddit_dgl):.6f} seconds per iteration')\n"
      ],
      "metadata": {
        "id": "rFJ3XINuUwab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PODZIAL NA GPU I CPU"
      ],
      "metadata": {
        "id": "23BppKRteFf9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementacja na Zbiorze Danych Karate Club i Citeseer\n",
        "PyTorch Geometric"
      ],
      "metadata": {
        "id": "j5R7Nm3dbirb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch Geometric z Obsługą CPU i GPU"
      ],
      "metadata": {
        "id": "cyq62BELeVsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.datasets import KarateClub, Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "import time\n",
        "\n",
        "# Karate Club\n",
        "dataset_karate = KarateClub()\n",
        "data_karate = dataset_karate[0]\n",
        "\n",
        "# Citeseer\n",
        "dataset_citeseer = Planetoid(root='data/Planetoid', name='Citeseer', transform=NormalizeFeatures())\n",
        "data_citeseer = dataset_citeseer[0]\n",
        "\n",
        "# Funkcja testująca z obsługą CPU i GPU\n",
        "def test_pyg(dataset, device):\n",
        "    conv_pyg = GNNConv().to(device)\n",
        "    dataset = dataset.to(device)\n",
        "    start_time = time.time()\n",
        "    for _ in range(100):\n",
        "        output = conv_pyg(dataset.x, dataset.edge_index)\n",
        "    return (time.time() - start_time) / 100\n",
        "\n",
        "# Wybór urządzenia\n",
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(f'PyTorch Geometric Karate Club on CPU: {test_pyg(data_karate, device_cpu):.6f} seconds per iteration')\n",
        "print(f'PyTorch Geometric Karate Club on GPU: {test_pyg(data_karate, device_gpu):.6f} seconds per iteration')\n",
        "print(f'PyTorch Geometric Citeseer on CPU: {test_pyg(data_citeseer, device_cpu):.6f} seconds per iteration')\n",
        "print(f'PyTorch Geometric Citeseer on GPU: {test_pyg(data_citeseer, device_gpu):.6f} seconds per iteration')\n"
      ],
      "metadata": {
        "id": "_BT4k7nReLm2",
        "outputId": "c72075f2-9343-40ac-93fe-c3b209025477",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Geometric Karate Club on CPU: 0.004782 seconds per iteration\n",
            "PyTorch Geometric Karate Club on GPU: 0.004629 seconds per iteration\n",
            "PyTorch Geometric Citeseer on CPU: 2.034567 seconds per iteration\n",
            "PyTorch Geometric Citeseer on GPU: 2.055309 seconds per iteration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DGL z Obsługą CPU i GPU"
      ],
      "metadata": {
        "id": "BusuzWhBeYfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "import torch\n",
        "import time\n",
        "from dgl.data import KarateClubDataset, CiteseerGraphDataset\n",
        "from dgl.nn import GraphConv\n",
        "\n",
        "# Karate Club Dataset\n",
        "dataset_karate_dgl = KarateClubDataset()\n",
        "g_karate_dgl = dataset_karate_dgl[0]\n",
        "g_karate_dgl = dgl.add_self_loop(g_karate_dgl)\n",
        "# Losowe cechy węzłów o wymiarze 1433 (zgodne z modelem)\n",
        "g_karate_dgl.ndata['feat'] = torch.randn(g_karate_dgl.num_nodes(), 1433)\n",
        "\n",
        "# Citeseer Dataset\n",
        "dataset_citeseer_dgl = CiteseerGraphDataset()\n",
        "g_citeseer_dgl = dataset_citeseer_dgl[0]\n",
        "g_citeseer_dgl = dgl.add_self_loop(g_citeseer_dgl)\n",
        "\n",
        "class GNNLayerKarate(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GNNLayerKarate, self).__init__()\n",
        "        self.conv1 = GraphConv(1433, 16)\n",
        "        self.conv2 = GraphConv(16, 7)\n",
        "\n",
        "    def forward(self, g, feature):\n",
        "        h = self.conv1(g, feature)\n",
        "        h = torch.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h\n",
        "\n",
        "class GNNLayerCiteseer(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GNNLayerCiteseer, self).__init__()\n",
        "        self.conv1 = GraphConv(3703, 16)\n",
        "        self.conv2 = GraphConv(16, 6)\n",
        "\n",
        "    def forward(self, g, feature):\n",
        "        h = self.conv1(g, feature)\n",
        "        h = torch.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h\n",
        "\n",
        "def test_dgl(graph, model, device):\n",
        "    model = model.to(device)\n",
        "    graph = graph.to(device)\n",
        "    feature = graph.ndata['feat'].to(device)\n",
        "    start_time = time.time()\n",
        "    for _ in range(100):\n",
        "        output = model(graph, feature)\n",
        "    return (time.time() - start_time) / 100\n",
        "\n",
        "# Wybór urządzenia\n",
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Testy\n",
        "print(f'DGL Karate Club on CPU: {test_dgl(g_karate_dgl, GNNLayerKarate(), device_cpu):.6f} seconds per iteration')\n",
        "print(f'DGL Karate Club on GPU: {test_dgl(g_karate_dgl, GNNLayerKarate(), device_gpu):.6f} seconds per iteration')\n",
        "print(f'DGL Citeseer on CPU: {test_dgl(g_citeseer_dgl, GNNLayerCiteseer(), device_cpu):.6f} seconds per iteration')\n",
        "print(f'DGL Citeseer on GPU: {test_dgl(g_citeseer_dgl, GNNLayerCiteseer(), device_gpu):.6f} seconds per iteration')\n"
      ],
      "metadata": {
        "id": "2PJ5tz-Mea97",
        "outputId": "6aa33896-a332-4446-9215-b1249f242be9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /root/.dgl/citeseer.zip from https://data.dgl.ai/dataset/citeseer.zip...\n",
            "Extracting file to /root/.dgl/citeseer_d6836239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dgl/data/citation_graph.py:314: RuntimeWarning: divide by zero encountered in power\n",
            "  r_inv = np.power(rowsum, -1).flatten()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done saving data into cached files.\n",
            "DGL Karate Club on CPU: 0.009004 seconds per iteration\n",
            "DGL Karate Club on GPU: 0.002409 seconds per iteration\n",
            "DGL Citeseer on CPU: 0.059976 seconds per iteration\n",
            "DGL Citeseer on GPU: 0.067811 seconds per iteration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch Geometric - Amazon Dataset"
      ],
      "metadata": {
        "id": "rGf6yRNoj6eE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import Amazon\n",
        "from torch_geometric.nn import GCNConv\n",
        "import time\n",
        "\n",
        "# Load Amazon Computers dataset\n",
        "dataset_amazon = Amazon(root='data/Amazon', name='Computers')\n",
        "data_amazon = dataset_amazon[0]\n",
        "\n",
        "# Define a simple GCN model\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(dataset_amazon.num_features, 16)\n",
        "        self.conv2 = GCNConv(16, dataset_amazon.num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "model = GCN()\n",
        "\n",
        "# Test function for PyG\n",
        "def test_pyg(data, device):\n",
        "    data = data.to(device)\n",
        "    model.to(device)\n",
        "    start_time = time.time()\n",
        "    for _ in range(100):\n",
        "        out = model(data)\n",
        "    return (time.time() - start_time) / 100\n",
        "\n",
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(f'PyG Amazon Computers on CPU: {test_pyg(data_amazon, device_cpu):.6f} seconds per iteration')\n",
        "print(f'PyG Amazon Computers on GPU: {test_pyg(data_amazon, device_gpu):.6f} seconds per iteration')\n"
      ],
      "metadata": {
        "id": "UlW5ULMpj8JW",
        "outputId": "c0d3bb5f-d660-4676-daa7-d78e6e6f2f01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/shchur/gnn-benchmark/raw/master/data/npz/amazon_electronics_computers.npz\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyG Amazon Computers on CPU: 0.164049 seconds per iteration\n",
            "PyG Amazon Computers on GPU: 0.167240 seconds per iteration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DGL - Amazon Dataset"
      ],
      "metadata": {
        "id": "C6j4Wufaj_IZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "from dgl.data import AmazonCoBuyComputerDataset\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load Amazon Computers dataset\n",
        "dataset_amazon_dgl = AmazonCoBuyComputerDataset()\n",
        "g_amazon_dgl = dataset_amazon_dgl[0]\n",
        "g_amazon_dgl = dgl.add_self_loop(g_amazon_dgl)\n",
        "g_amazon_dgl.ndata['feat'] = torch.randn(g_amazon_dgl.num_nodes(), dataset_amazon.num_features)\n",
        "\n",
        "# Define a simple GCN model for DGL\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GraphConv(dataset_amazon.num_features, 16)\n",
        "        self.conv2 = GraphConv(16, dataset_amazon.num_classes)\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(g, x)\n",
        "        return x\n",
        "\n",
        "model = GCN()\n",
        "\n",
        "# Test function for DGL\n",
        "def test_dgl(g, device):\n",
        "    g = g.to(device)\n",
        "    model.to(device)\n",
        "    features = g.ndata['feat'].to(device)\n",
        "    start_time = time.time()\n",
        "    for _ in range(100):\n",
        "        out = model(g, features)\n",
        "    return (time.time() - start_time) / 100\n",
        "\n",
        "print(f'DGL Amazon Computers on CPU: {test_dgl(g_amazon_dgl, device_cpu):.6f} seconds per iteration')\n",
        "print(f'DGL Amazon Computers on GPU: {test_dgl(g_amazon_dgl, device_gpu):.6f} seconds per iteration')\n"
      ],
      "metadata": {
        "id": "NBTQQdgZkBhp",
        "outputId": "d10a9cc8-ff48-419f-b0e0-8157603c25cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /root/.dgl/amazon_co_buy_computer.zip from https://data.dgl.ai/dataset/amazon_co_buy_computer.zip...\n",
            "Extracting file to /root/.dgl/amazon_co_buy_computer_b5999b2e\n",
            "DGL Amazon Computers on CPU: 0.066257 seconds per iteration\n",
            "DGL Amazon Computers on GPU: 0.053029 seconds per iteration\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# REDDIT DATASET"
      ],
      "metadata": {
        "id": "FQs-3bsDkIz-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch Geometric - Reddit Dataset"
      ],
      "metadata": {
        "id": "FFCq5sStkNev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torch-geometric dgl\n"
      ],
      "metadata": {
        "id": "wd08S9Val9YT",
        "outputId": "9e22da07-b3f6-4de4-bfc8-b579ae484274",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.5.3)\n",
            "Requirement already satisfied: dgl in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (18.1.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.6.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import Reddit\n",
        "\n",
        "# Load Reddit dataset\n",
        "dataset_reddit = Reddit(root='data/Reddit')\n",
        "data_reddit = dataset_reddit[0]\n",
        "\n",
        "# Define a simple GCN model\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(dataset_reddit.num_features, 16)\n",
        "        self.conv2 = GCNConv(16, dataset_reddit.num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "model = GCN()\n",
        "\n",
        "print(f'PyG Reddit on CPU: {test_pyg(data_reddit, device_cpu):.6f} seconds per iteration')\n",
        "print(f'PyG Reddit on GPU: {test_pyg(data_reddit, device_gpu):.6f} seconds per iteration')\n"
      ],
      "metadata": {
        "id": "qdBhF7dekMBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DGL - Reddit Dataset"
      ],
      "metadata": {
        "id": "iwXIzSRpkQNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dgl.data import RedditDataset\n",
        "\n",
        "# Load Reddit dataset\n",
        "dataset_reddit_dgl = RedditDataset()\n",
        "g_reddit_dgl = dataset_reddit_dgl[0]\n",
        "g_reddit_dgl = dgl.add_self_loop(g_reddit_dgl)\n",
        "g_reddit_dgl.ndata['feat'] = torch.randn(g_reddit_dgl.num_nodes(), dataset_reddit.num_features)\n",
        "\n",
        "print(f'DGL Reddit on CPU: {test_dgl(g_reddit_dgl, device_cpu):.6f} seconds per iteration')\n",
        "print(f'DGL Reddit on GPU: {test_dgl(g_reddit_dgl, device_gpu):.6f} seconds per iteration')\n"
      ],
      "metadata": {
        "id": "XRiG2uNtkRtk",
        "outputId": "48cf0766-c6f0-427d-fac4-b2a7e65d7733",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /root/.dgl/reddit.zip from https://data.dgl.ai/dataset/reddit.zip...\n",
            "Extracting file to /root/.dgl/reddit_69f818f5\n"
          ]
        }
      ]
    }
  ]
}