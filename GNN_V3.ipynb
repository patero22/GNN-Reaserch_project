{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3lOdJFhQK0m7NJVRg6swy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "70ea8302e6db40439638a3b2aa3c8604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1800bfdcd9c54f0bbc7b35a909b31d4b",
              "IPY_MODEL_d6990a26ed324c4aa08896bc88931754",
              "IPY_MODEL_5dc88f229b28482db76ed98ef2d5a162"
            ],
            "layout": "IPY_MODEL_afb3145e92a940a7ab5aea68a5e6b191"
          }
        },
        "1800bfdcd9c54f0bbc7b35a909b31d4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9929fa2bdd824c3997b5872bcaf24ef9",
            "placeholder": "​",
            "style": "IPY_MODEL_fc144b60fb1b41d9af01a7fdd10fe8b4",
            "value": "/root/.dgl/citeseer.zip: 100%"
          }
        },
        "d6990a26ed324c4aa08896bc88931754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4390c55980c347dcb6fbb1863fd85a44",
            "max": 238901,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3d7ce67aec44e91a7219d9958261e56",
            "value": 238901
          }
        },
        "5dc88f229b28482db76ed98ef2d5a162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_058279adf66b42de8cff5b31a0670c46",
            "placeholder": "​",
            "style": "IPY_MODEL_8e87e1f476af483c8cf1b06ad4d7d402",
            "value": " 239k/239k [00:00&lt;00:00, 5.57MB/s]"
          }
        },
        "afb3145e92a940a7ab5aea68a5e6b191": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9929fa2bdd824c3997b5872bcaf24ef9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc144b60fb1b41d9af01a7fdd10fe8b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4390c55980c347dcb6fbb1863fd85a44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3d7ce67aec44e91a7219d9958261e56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "058279adf66b42de8cff5b31a0670c46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e87e1f476af483c8cf1b06ad4d7d402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patero22/GNN-Reaserch_project/blob/main/GNN_V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr6s2PHkKS_O",
        "outputId": "505e03ab-a76b-4e5f-a298-72ff049e2da2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.2.1\n",
            "  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m973.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.1)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.1)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.1)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.1)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.1)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.1)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.1)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.1)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.1)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.1)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.1)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting triton==2.2.0 (from torch==2.2.1)\n",
            "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchvision-0.17.1-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-2.3.1-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchaudio-2.2.2-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchaudio-2.2.1-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.1\n",
            "    Uninstalling triton-2.3.1:\n",
            "      Successfully uninstalled triton-2.3.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.1+cu121\n",
            "    Uninstalling torch-2.3.1+cu121:\n",
            "      Successfully uninstalled torch-2.3.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.18.1+cu121\n",
            "    Uninstalling torchvision-0.18.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.18.1+cu121\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.3.1+cu121\n",
            "    Uninstalling torchaudio-2.3.1+cu121:\n",
            "      Successfully uninstalled torchaudio-2.3.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 torch-2.2.1 torchaudio-2.2.1 torchvision-0.17.1 triton-2.2.0\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.5.3\n",
            "Collecting dgl==2.1.0\n",
            "  Downloading dgl-2.1.0-cp310-cp310-manylinux1_x86_64.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (3.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (4.66.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl==2.1.0) (5.9.5)\n",
            "Collecting torchdata>=0.5.0 (from dgl==2.1.0)\n",
            "  Downloading torchdata-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==2.1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==2.1.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==2.1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl==2.1.0) (2024.7.4)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.5.0->dgl==2.1.0) (2.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (1.13.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata>=0.5.0->dgl==2.1.0) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata>=0.5.0->dgl==2.1.0) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl==2.1.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata>=0.5.0->dgl==2.1.0) (1.3.0)\n",
            "Installing collected packages: torchdata, dgl\n",
            "Successfully installed dgl-2.1.0 torchdata-0.7.1\n",
            "Collecting memory-profiler\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory-profiler) (5.9.5)\n",
            "Installing collected packages: memory-profiler\n",
            "Successfully installed memory-profiler-0.61.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.2.1 torchvision torchaudio\n",
        "!pip install torch-geometric\n",
        "!pip install dgl==2.1.0\n",
        "!pip install memory-profiler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, PNAConv\n",
        "from dgl.nn.pytorch import GraphConv, GATConv as GATConvDGL, SAGEConv as SAGEConvDGL\n",
        "from dgl.nn import PNAConv"
      ],
      "metadata": {
        "id": "vtzraN2eKURJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "265ae03d-cc59-4f94-ebe9-49f14e6e9c62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import coo_matrix, csr_matrix\n",
        "\n",
        "# Conversion Functions\n",
        "def convert_to_coo(edge_index, num_nodes):\n",
        "    row, col = edge_index\n",
        "    data = torch.ones(row.size(0))\n",
        "    coo = coo_matrix((data.numpy(), (row.numpy(), col.numpy())), shape=(num_nodes, num_nodes))\n",
        "    return coo\n",
        "\n",
        "def convert_to_csr(edge_index, num_nodes):\n",
        "    row, col = edge_index\n",
        "    data = torch.ones(row.size(0))\n",
        "    csr = csr_matrix((data.numpy(), (row.numpy(), col.numpy())), shape=(num_nodes, num_nodes))\n",
        "    return csr"
      ],
      "metadata": {
        "id": "Z4-5Pce_KWL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Profiling Function\n",
        "from memory_profiler import memory_usage\n",
        "import time\n",
        "\n",
        "def profile_model(model, data, device, dgl=False, format='coo'):\n",
        "    data = data.to(device)\n",
        "    model = model.to(device)\n",
        "\n",
        "    def forward_pass():\n",
        "        if dgl:\n",
        "            model(data, data.ndata['feat'])\n",
        "        else:\n",
        "            model(data)\n",
        "\n",
        "    # Measure time\n",
        "    start_time = time.time()\n",
        "    for _ in range(100):\n",
        "        forward_pass()\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Measure peak memory usage\n",
        "    mem_usage = memory_usage(forward_pass, interval=0.1)\n",
        "\n",
        "    return (end_time - start_time) / 100, max(mem_usage)"
      ],
      "metadata": {
        "id": "o1hxdm2sLA2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import KarateClub, Planetoid\n",
        "from dgl.data import KarateClubDataset, CiteseerGraphDataset"
      ],
      "metadata": {
        "id": "MzLmFyc8LEzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load PyG Datasets\n",
        "dataset_karate_pyg = KarateClub()\n",
        "data_karate_pyg = dataset_karate_pyg[0]\n",
        "\n",
        "dataset_citeseer_pyg = Planetoid(root='data/Citeseer', name='Citeseer')\n",
        "data_citeseer_pyg = dataset_citeseer_pyg[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDdy_bKmLFcS",
        "outputId": "ec72755b-3b98-4d04-8f8a-a92067f2c44d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load DGL Datasets\n",
        "def load_karate_dgl():\n",
        "    dataset = KarateClubDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "def load_citeseer_dgl():\n",
        "    dataset = CiteseerGraphDataset()\n",
        "    graph = dataset[0]\n",
        "    return graph\n",
        "\n",
        "graph_karate_dgl = load_karate_dgl()\n",
        "graph_citeseer_dgl = load_citeseer_dgl()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "70ea8302e6db40439638a3b2aa3c8604",
            "1800bfdcd9c54f0bbc7b35a909b31d4b",
            "d6990a26ed324c4aa08896bc88931754",
            "5dc88f229b28482db76ed98ef2d5a162",
            "afb3145e92a940a7ab5aea68a5e6b191",
            "9929fa2bdd824c3997b5872bcaf24ef9",
            "fc144b60fb1b41d9af01a7fdd10fe8b4",
            "4390c55980c347dcb6fbb1863fd85a44",
            "b3d7ce67aec44e91a7219d9958261e56",
            "058279adf66b42de8cff5b31a0670c46",
            "8e87e1f476af483c8cf1b06ad4d7d402"
          ]
        },
        "id": "7sQ7n3nRLHLC",
        "outputId": "adcd1e0e-d822-4ff5-9f6d-90203411344c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading /root/.dgl/citeseer.zip from https://data.dgl.ai/dataset/citeseer.zip...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/root/.dgl/citeseer.zip:   0%|          | 0.00/239k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70ea8302e6db40439638a3b2aa3c8604"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting file to /root/.dgl/citeseer_d6836239\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 3327\n",
            "  NumEdges: 9228\n",
            "  NumFeats: 3703\n",
            "  NumClasses: 6\n",
            "  NumTrainingSamples: 120\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done saving data into cached files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data\n",
        "import dgl\n",
        "from dgl.nn.pytorch import GATConv as GATConvDGL, GraphConv, SAGEConv as SAGEConvDGL, PNAConv as PNAConvDGL\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 16)\n",
        "        self.conv2 = GCNConv(16, out_channels)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "class GCN_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_feats, out_feats):\n",
        "        super(GCN_DGL, self).__init__()\n",
        "        self.conv1 = GraphConv(in_feats, 16)\n",
        "        self.conv2 = GraphConv(16, out_feats)\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(g, x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Define GAT model for PyG\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GAT, self).__init__()\n",
        "        self.conv1 = torch_geometric.nn.GATConv(in_channels, 8, heads=8)\n",
        "        self.conv2 = torch_geometric.nn.GATConv(8 * 8, out_channels, heads=1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Define GAT model for DGL\n",
        "class GAT_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GAT_DGL, self).__init__()\n",
        "        self.conv1 = GATConvDGL(in_channels, 8, num_heads=8)\n",
        "        self.conv2 = GATConvDGL(8 * 8, out_channels, num_heads=1)\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features).flatten(1)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(g, x).mean(1)\n",
        "        return x\n",
        "\n",
        "# Define GraphSAGE model for PyG\n",
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = torch_geometric.nn.SAGEConv(in_channels, 16, aggr='mean')\n",
        "        self.conv2 = torch_geometric.nn.SAGEConv(16, out_channels, aggr='mean')\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# Define GraphSAGE model for DGL\n",
        "class GraphSAGE_DGL(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GraphSAGE_DGL, self).__init__()\n",
        "        self.conv1 = SAGEConvDGL(in_channels, 16, aggregator_type='mean')\n",
        "        self.conv2 = SAGEConvDGL(16, out_channels, aggregator_type='mean')\n",
        "\n",
        "    def forward(self, g, features):\n",
        "        x = self.conv1(g, features)\n",
        "        x = F.elu(x)\n",
        "        x = self.conv2(g, x)\n",
        "        return x\n",
        "\n",
        "# Define PNA model for PyG\n",
        "# class PNA(torch.nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels, deg):\n",
        "#         super(PNA, self).__init__()\n",
        "#         self.conv1 = torch_geometric.nn.PNAConv(in_channels, 16, aggregators=['mean', 'max', 'min'], scalers=['identity'], deg=deg)\n",
        "#         self.conv2 = torch_geometric.nn.PNAConv(16, out_channels, aggregators=['mean', 'max', 'min'], scalers=['identity'], deg=deg)\n",
        "\n",
        "#     def forward(self, data):\n",
        "#         x, edge_index = data.x, data.edge_index\n",
        "#         x = self.conv1(x, edge_index)\n",
        "#         x = F.elu(x)\n",
        "#         x = self.conv2(x, edge_index)\n",
        "#         return x\n",
        "\n",
        "# Define PNA model for DGL\n",
        "# class PNA_DGL(torch.nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels):\n",
        "#         super(PNA_DGL, self).__init__()\n",
        "#         self.conv1 = PNAConvDGL(in_channels, 16)\n",
        "#         self.conv2 = PNAConvDGL(16, out_channels)\n",
        "\n",
        "#     def forward(self, g, features):\n",
        "#         x = self.conv1(g, features)\n",
        "#         x = F.elu(x)\n",
        "#         x = self.conv2(g, x)\n",
        "#         return x\n"
      ],
      "metadata": {
        "id": "owvHfvQvZ2RU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Ensure features and labels are set for DGL graphs\n",
        "def ensure_dgl_features_and_labels(graph, pyg_data):\n",
        "    graph.ndata['feat'] = pyg_data.x.clone().detach()\n",
        "    graph.ndata['label'] = pyg_data.y.clone().detach()\n",
        "    return graph\n",
        "\n",
        "graph_karate_dgl = ensure_dgl_features_and_labels(graph_karate_dgl, data_karate_pyg)\n",
        "graph_citeseer_dgl = ensure_dgl_features_and_labels(graph_citeseer_dgl, data_citeseer_pyg)\n",
        "\n",
        "# Define devices\n",
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define and test models on COO and CSR formats\n",
        "formats = ['coo', 'csr']\n",
        "models = {\n",
        "    'GCN': (GCN, GCN_DGL),\n",
        "    'GAT': (GAT, GAT_DGL),\n",
        "    'GraphSAGE': (GraphSAGE, GraphSAGE_DGL),\n",
        "    #'PNA': (PNA, PNA_DGL)\n",
        "}\n",
        "\n",
        "datasets_pyg = {\n",
        "    'Karate Club': (dataset_karate_pyg, data_karate_pyg),\n",
        "    'Citeseer': (dataset_citeseer_pyg, data_citeseer_pyg)\n",
        "}\n",
        "\n",
        "datasets_dgl = {\n",
        "    'Karate Club': graph_karate_dgl,\n",
        "    'Citeseer': graph_citeseer_dgl\n",
        "}\n",
        "\n",
        "for model_name, (ModelPyG, ModelDGL) in models.items():\n",
        "    for dataset_name, (dataset_pyg, data_pyg) in datasets_pyg.items():\n",
        "        # Calculate degree tensor for PyG PNA model\n",
        "        if model_name == 'PNA':\n",
        "            deg = torch_geometric.utils.degree(data_pyg.edge_index[0], data_pyg.num_nodes).float()\n",
        "        for fmt in formats:\n",
        "            if model_name == 'PNA':\n",
        "                model_pyg = ModelPyG(dataset_pyg.num_features, dataset_pyg.num_classes, deg=deg)\n",
        "            else:\n",
        "                model_pyg = ModelPyG(dataset_pyg.num_features, dataset_pyg.num_classes)\n",
        "            time_cpu, mem_cpu = profile_model(model_pyg, data_pyg, device_cpu, format=fmt)\n",
        "            time_gpu, mem_gpu = profile_model(model_pyg, data_pyg, device_gpu, format=fmt)\n",
        "            print(f'PyG {dataset_name} {model_name} ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "            print(f'PyG {dataset_name} {model_name} ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n",
        "\n",
        "    for dataset_name, graph_dgl in datasets_dgl.items():\n",
        "        for fmt in formats:\n",
        "            input_dim = graph_dgl.ndata['feat'].shape[1]\n",
        "            output_dim = graph_dgl.ndata['label'].max().item() + 1\n",
        "            model_dgl = ModelDGL(input_dim, output_dim)\n",
        "            time_cpu, mem_cpu = profile_model(model_dgl, graph_dgl, device_cpu, dgl=True, format=fmt)\n",
        "            time_gpu, mem_gpu = profile_model(model_dgl, graph_dgl, device_gpu, dgl=True, format=fmt)\n",
        "            print(f'DGL {dataset_name} {model_name} ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "            print(f'DGL {dataset_name} {model_name} ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIjvrcWzLMcy",
        "outputId": "967e5e1e-4cd9-4151-f4fa-b9ebe036fb6f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyG Karate Club GCN (COO) on CPU: 0.001191 seconds per iteration, 7164.95 MB peak memory\n",
            "PyG Karate Club GCN (COO) on GPU: 0.002448 seconds per iteration, 7164.95 MB peak memory\n",
            "PyG Karate Club GCN (CSR) on CPU: 0.004803 seconds per iteration, 7164.95 MB peak memory\n",
            "PyG Karate Club GCN (CSR) on GPU: 0.001869 seconds per iteration, 7164.95 MB peak memory\n",
            "PyG Citeseer GCN (COO) on CPU: 0.020012 seconds per iteration, 7164.96 MB peak memory\n",
            "PyG Citeseer GCN (COO) on GPU: 0.019383 seconds per iteration, 7164.96 MB peak memory\n",
            "PyG Citeseer GCN (CSR) on CPU: 0.019447 seconds per iteration, 7164.96 MB peak memory\n",
            "PyG Citeseer GCN (CSR) on GPU: 0.022810 seconds per iteration, 7164.96 MB peak memory\n",
            "DGL Karate Club GCN (COO) on CPU: 0.005057 seconds per iteration, 7165.03 MB peak memory\n",
            "DGL Karate Club GCN (COO) on GPU: 0.003122 seconds per iteration, 7165.03 MB peak memory\n",
            "DGL Karate Club GCN (CSR) on CPU: 0.003300 seconds per iteration, 7165.03 MB peak memory\n",
            "DGL Karate Club GCN (CSR) on GPU: 0.003232 seconds per iteration, 7165.03 MB peak memory\n",
            "DGL Citeseer GCN (COO) on CPU: 0.058956 seconds per iteration, 7212.04 MB peak memory\n",
            "DGL Citeseer GCN (COO) on GPU: 0.066677 seconds per iteration, 7212.04 MB peak memory\n",
            "DGL Citeseer GCN (CSR) on CPU: 0.059217 seconds per iteration, 7212.04 MB peak memory\n",
            "DGL Citeseer GCN (CSR) on GPU: 0.066199 seconds per iteration, 7212.04 MB peak memory\n",
            "PyG Karate Club GAT (COO) on CPU: 0.002823 seconds per iteration, 7166.41 MB peak memory\n",
            "PyG Karate Club GAT (COO) on GPU: 0.002452 seconds per iteration, 7166.41 MB peak memory\n",
            "PyG Karate Club GAT (CSR) on CPU: 0.002591 seconds per iteration, 7166.41 MB peak memory\n",
            "PyG Karate Club GAT (CSR) on GPU: 0.002732 seconds per iteration, 7166.41 MB peak memory\n",
            "PyG Citeseer GAT (COO) on CPU: 0.065815 seconds per iteration, 7166.47 MB peak memory\n",
            "PyG Citeseer GAT (COO) on GPU: 0.053776 seconds per iteration, 7166.47 MB peak memory\n",
            "PyG Citeseer GAT (CSR) on CPU: 0.063960 seconds per iteration, 7166.47 MB peak memory\n",
            "PyG Citeseer GAT (CSR) on GPU: 0.054054 seconds per iteration, 7166.47 MB peak memory\n",
            "DGL Karate Club GAT (COO) on CPU: 0.003617 seconds per iteration, 7167.07 MB peak memory\n",
            "DGL Karate Club GAT (COO) on GPU: 0.003984 seconds per iteration, 7167.07 MB peak memory\n",
            "DGL Karate Club GAT (CSR) on CPU: 0.006965 seconds per iteration, 7167.07 MB peak memory\n",
            "DGL Karate Club GAT (CSR) on GPU: 0.007120 seconds per iteration, 7167.07 MB peak memory\n",
            "DGL Citeseer GAT (COO) on CPU: 0.053516 seconds per iteration, 7167.07 MB peak memory\n",
            "DGL Citeseer GAT (COO) on GPU: 0.062475 seconds per iteration, 7167.07 MB peak memory\n",
            "DGL Citeseer GAT (CSR) on CPU: 0.053449 seconds per iteration, 7167.07 MB peak memory\n",
            "DGL Citeseer GAT (CSR) on GPU: 0.060871 seconds per iteration, 7167.07 MB peak memory\n",
            "PyG Karate Club GraphSAGE (COO) on CPU: 0.001237 seconds per iteration, 7167.18 MB peak memory\n",
            "PyG Karate Club GraphSAGE (COO) on GPU: 0.000844 seconds per iteration, 7167.18 MB peak memory\n",
            "PyG Karate Club GraphSAGE (CSR) on CPU: 0.000939 seconds per iteration, 7167.18 MB peak memory\n",
            "PyG Karate Club GraphSAGE (CSR) on GPU: 0.001017 seconds per iteration, 7167.18 MB peak memory\n",
            "PyG Citeseer GraphSAGE (COO) on CPU: 0.244922 seconds per iteration, 7298.11 MB peak memory\n",
            "PyG Citeseer GraphSAGE (COO) on GPU: 0.245435 seconds per iteration, 7292.65 MB peak memory\n",
            "PyG Citeseer GraphSAGE (CSR) on CPU: 0.241539 seconds per iteration, 7362.44 MB peak memory\n",
            "PyG Citeseer GraphSAGE (CSR) on GPU: 0.239787 seconds per iteration, 7356.65 MB peak memory\n",
            "DGL Karate Club GraphSAGE (COO) on CPU: 0.002315 seconds per iteration, 7167.19 MB peak memory\n",
            "DGL Karate Club GraphSAGE (COO) on GPU: 0.004820 seconds per iteration, 7167.19 MB peak memory\n",
            "DGL Karate Club GraphSAGE (CSR) on CPU: 0.002290 seconds per iteration, 7167.19 MB peak memory\n",
            "DGL Karate Club GraphSAGE (CSR) on GPU: 0.002457 seconds per iteration, 7167.19 MB peak memory\n",
            "DGL Citeseer GraphSAGE (COO) on CPU: 0.032928 seconds per iteration, 7167.19 MB peak memory\n",
            "DGL Citeseer GraphSAGE (COO) on GPU: 0.031860 seconds per iteration, 7167.19 MB peak memory\n",
            "DGL Citeseer GraphSAGE (CSR) on CPU: 0.040951 seconds per iteration, 7167.19 MB peak memory\n",
            "DGL Citeseer GraphSAGE (CSR) on GPU: 0.030474 seconds per iteration, 7167.19 MB peak memory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ezC8ChI3M_zJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.datasets import Planetoid, KarateClub\n",
        "import dgl\n",
        "from dgl.data import CoraGraphDataset, CiteseerGraphDataset, PubmedGraphDataset\n",
        "from dgl.nn.pytorch import GATConv as GATConvDGL, SAGEConv as SAGEConvDGL"
      ],
      "metadata": {
        "id": "KNfSjgDEOdvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i-RpCUEsaXQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_cora_pyg = Planetoid(root='/tmp/Cora', name='Cora')\n",
        "data_cora_pyg = dataset_cora_pyg[0]\n",
        "\n",
        "dataset_pubmed_pyg = Planetoid(root='/tmp/Pubmed', name='Pubmed')\n",
        "data_pubmed_pyg = dataset_pubmed_pyg[0]\n",
        "\n",
        "# Load datasets for DGL\n",
        "\n",
        "graph_cora_dgl = CoraGraphDataset()[0]\n",
        "graph_cora_dgl = ensure_dgl_features_and_labels(graph_cora_dgl, data_cora_pyg)\n",
        "\n",
        "graph_pubmed_dgl = PubmedGraphDataset()[0]\n",
        "graph_pubmed_dgl = ensure_dgl_features_and_labels(graph_pubmed_dgl, data_pubmed_pyg)\n",
        "\n",
        "# Define devices\n",
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define and test models on COO and CSR formats\n",
        "formats = ['coo', 'csr']\n",
        "models = {\n",
        "    'GCN': (GCN, GCN_DGL),\n",
        "    'GAT': (GAT, GAT_DGL),\n",
        "    'GraphSAGE': (GraphSAGE, GraphSAGE_DGL),\n",
        "    #'PNA': (PNA, PNA_DGL)\n",
        "}\n",
        "\n",
        "datasets_pyg = {\n",
        "    'Karate Club': (dataset_karate_pyg, data_karate_pyg),\n",
        "    'Citeseer': (dataset_citeseer_pyg, data_citeseer_pyg),\n",
        "    'Cora': (dataset_cora_pyg, data_cora_pyg),\n",
        "    'Pubmed': (dataset_pubmed_pyg, data_pubmed_pyg)\n",
        "}\n",
        "\n",
        "datasets_dgl = {\n",
        "    'Karate Club': graph_karate_dgl,\n",
        "    'Citeseer': graph_citeseer_dgl,\n",
        "    'Cora': graph_cora_dgl,\n",
        "    'Pubmed': graph_pubmed_dgl\n",
        "}\n",
        "\n",
        "for model_name, (ModelPyG, ModelDGL) in models.items():\n",
        "    for dataset_name, (dataset_pyg, data_pyg) in datasets_pyg.items():\n",
        "        # Calculate degree tensor for PyG PNA model\n",
        "        if model_name == 'PNA':\n",
        "            deg = torch_geometric.utils.degree(data_pyg.edge_index[0], data_pyg.num_nodes).float()\n",
        "        for fmt in formats:\n",
        "            if model_name == 'PNA':\n",
        "                model_pyg = ModelPyG(dataset_pyg.num_features, dataset_pyg.num_classes, deg=deg)\n",
        "            else:\n",
        "                model_pyg = ModelPyG(dataset_pyg.num_features, dataset_pyg.num_classes)\n",
        "            time_cpu, mem_cpu = profile_model(model_pyg, data_pyg, device_cpu, format=fmt)\n",
        "            time_gpu, mem_gpu = profile_model(model_pyg, data_pyg, device_gpu, format=fmt)\n",
        "            print(f'PyG {dataset_name} {model_name} ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "            print(f'PyG {dataset_name} {model_name} ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n",
        "\n",
        "    for dataset_name, graph_dgl in datasets_dgl.items():\n",
        "        for fmt in formats:\n",
        "            input_dim = graph_dgl.ndata['feat'].shape[1]\n",
        "            output_dim = graph_dgl.ndata['label'].max().item() + 1\n",
        "            model_dgl = ModelDGL(input_dim, output_dim)\n",
        "            time_cpu, mem_cpu = profile_model(model_dgl, graph_dgl, device_cpu, dgl=True, format=fmt)\n",
        "            time_gpu, mem_gpu = profile_model(model_dgl, graph_dgl, device_gpu, dgl=True, format=fmt)\n",
        "            print(f'DGL {dataset_name} {model_name} ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "            print(f'DGL {dataset_name} {model_name} ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCgmnA_NOd83",
        "outputId": "9ff87c70-d664-40e6-d15d-681a743e1dd3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n",
            "  NumNodes: 19717\n",
            "  NumEdges: 88651\n",
            "  NumFeats: 500\n",
            "  NumClasses: 3\n",
            "  NumTrainingSamples: 60\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n",
            "PyG Karate Club GCN (COO) on CPU: 0.002038 seconds per iteration, 7158.20 MB peak memory\n",
            "PyG Karate Club GCN (COO) on GPU: 0.001737 seconds per iteration, 7158.20 MB peak memory\n",
            "PyG Karate Club GCN (CSR) on CPU: 0.001650 seconds per iteration, 7158.20 MB peak memory\n",
            "PyG Karate Club GCN (CSR) on GPU: 0.001771 seconds per iteration, 7158.20 MB peak memory\n",
            "PyG Citeseer GCN (COO) on CPU: 0.019733 seconds per iteration, 7158.20 MB peak memory\n",
            "PyG Citeseer GCN (COO) on GPU: 0.019869 seconds per iteration, 7158.20 MB peak memory\n",
            "PyG Citeseer GCN (CSR) on CPU: 0.021990 seconds per iteration, 7158.20 MB peak memory\n",
            "PyG Citeseer GCN (CSR) on GPU: 0.024525 seconds per iteration, 7158.20 MB peak memory\n",
            "PyG Cora GCN (COO) on CPU: 0.010372 seconds per iteration, 7158.20 MB peak memory\n",
            "PyG Cora GCN (COO) on GPU: 0.011713 seconds per iteration, 7158.20 MB peak memory\n",
            "PyG Cora GCN (CSR) on CPU: 0.010559 seconds per iteration, 7158.20 MB peak memory\n",
            "PyG Cora GCN (CSR) on GPU: 0.010201 seconds per iteration, 7158.20 MB peak memory\n",
            "PyG Pubmed GCN (COO) on CPU: 0.039550 seconds per iteration, 7158.21 MB peak memory\n",
            "PyG Pubmed GCN (COO) on GPU: 0.035097 seconds per iteration, 7158.21 MB peak memory\n",
            "PyG Pubmed GCN (CSR) on CPU: 0.034207 seconds per iteration, 7158.21 MB peak memory\n",
            "PyG Pubmed GCN (CSR) on GPU: 0.038586 seconds per iteration, 7158.21 MB peak memory\n",
            "DGL Karate Club GCN (COO) on CPU: 0.005758 seconds per iteration, 7158.21 MB peak memory\n",
            "DGL Karate Club GCN (COO) on GPU: 0.003115 seconds per iteration, 7158.21 MB peak memory\n",
            "DGL Karate Club GCN (CSR) on CPU: 0.002987 seconds per iteration, 7158.21 MB peak memory\n",
            "DGL Karate Club GCN (CSR) on GPU: 0.003089 seconds per iteration, 7158.21 MB peak memory\n",
            "DGL Citeseer GCN (COO) on CPU: 0.059231 seconds per iteration, 7205.21 MB peak memory\n",
            "DGL Citeseer GCN (COO) on GPU: 0.065994 seconds per iteration, 7205.21 MB peak memory\n",
            "DGL Citeseer GCN (CSR) on CPU: 0.062956 seconds per iteration, 7205.21 MB peak memory\n",
            "DGL Citeseer GCN (CSR) on GPU: 0.063358 seconds per iteration, 7205.21 MB peak memory\n",
            "DGL Cora GCN (COO) on CPU: 0.012990 seconds per iteration, 7158.21 MB peak memory\n",
            "DGL Cora GCN (COO) on GPU: 0.013344 seconds per iteration, 7158.21 MB peak memory\n",
            "DGL Cora GCN (CSR) on CPU: 0.014665 seconds per iteration, 7158.21 MB peak memory\n",
            "DGL Cora GCN (CSR) on GPU: 0.017221 seconds per iteration, 7158.21 MB peak memory\n",
            "DGL Pubmed GCN (COO) on CPU: 0.050256 seconds per iteration, 7195.83 MB peak memory\n",
            "DGL Pubmed GCN (COO) on GPU: 0.052944 seconds per iteration, 7195.83 MB peak memory\n",
            "DGL Pubmed GCN (CSR) on CPU: 0.053393 seconds per iteration, 7195.83 MB peak memory\n",
            "DGL Pubmed GCN (CSR) on GPU: 0.049630 seconds per iteration, 7195.83 MB peak memory\n",
            "PyG Karate Club GAT (COO) on CPU: 0.004102 seconds per iteration, 7158.22 MB peak memory\n",
            "PyG Karate Club GAT (COO) on GPU: 0.005954 seconds per iteration, 7158.22 MB peak memory\n",
            "PyG Karate Club GAT (CSR) on CPU: 0.002683 seconds per iteration, 7158.22 MB peak memory\n",
            "PyG Karate Club GAT (CSR) on GPU: 0.003141 seconds per iteration, 7158.22 MB peak memory\n",
            "PyG Citeseer GAT (COO) on CPU: 0.056074 seconds per iteration, 7158.22 MB peak memory\n",
            "PyG Citeseer GAT (COO) on GPU: 0.068102 seconds per iteration, 7158.22 MB peak memory\n",
            "PyG Citeseer GAT (CSR) on CPU: 0.055383 seconds per iteration, 7158.22 MB peak memory\n",
            "PyG Citeseer GAT (CSR) on GPU: 0.066326 seconds per iteration, 7158.22 MB peak memory\n",
            "PyG Cora GAT (COO) on CPU: 0.027285 seconds per iteration, 7158.22 MB peak memory\n",
            "PyG Cora GAT (COO) on GPU: 0.026689 seconds per iteration, 7158.22 MB peak memory\n",
            "PyG Cora GAT (CSR) on CPU: 0.037842 seconds per iteration, 7158.22 MB peak memory\n",
            "PyG Cora GAT (CSR) on GPU: 0.026359 seconds per iteration, 7158.22 MB peak memory\n",
            "PyG Pubmed GAT (COO) on CPU: 0.117086 seconds per iteration, 7211.14 MB peak memory\n",
            "PyG Pubmed GAT (COO) on GPU: 0.113401 seconds per iteration, 7211.14 MB peak memory\n",
            "PyG Pubmed GAT (CSR) on CPU: 0.113720 seconds per iteration, 7211.14 MB peak memory\n",
            "PyG Pubmed GAT (CSR) on GPU: 0.104131 seconds per iteration, 7211.14 MB peak memory\n",
            "DGL Karate Club GAT (COO) on CPU: 0.004795 seconds per iteration, 7211.14 MB peak memory\n",
            "DGL Karate Club GAT (COO) on GPU: 0.003969 seconds per iteration, 7211.14 MB peak memory\n",
            "DGL Karate Club GAT (CSR) on CPU: 0.003750 seconds per iteration, 7211.14 MB peak memory\n",
            "DGL Karate Club GAT (CSR) on GPU: 0.003732 seconds per iteration, 7211.14 MB peak memory\n",
            "DGL Citeseer GAT (COO) on CPU: 0.053725 seconds per iteration, 7211.14 MB peak memory\n",
            "DGL Citeseer GAT (COO) on GPU: 0.065547 seconds per iteration, 7211.14 MB peak memory\n",
            "DGL Citeseer GAT (CSR) on CPU: 0.052689 seconds per iteration, 7211.14 MB peak memory\n",
            "DGL Citeseer GAT (CSR) on GPU: 0.064589 seconds per iteration, 7211.14 MB peak memory\n",
            "DGL Cora GAT (COO) on CPU: 0.024479 seconds per iteration, 7211.14 MB peak memory\n",
            "DGL Cora GAT (COO) on GPU: 0.024381 seconds per iteration, 7211.14 MB peak memory\n",
            "DGL Cora GAT (CSR) on CPU: 0.028326 seconds per iteration, 7211.14 MB peak memory\n",
            "DGL Cora GAT (CSR) on GPU: 0.029606 seconds per iteration, 7211.14 MB peak memory\n",
            "DGL Pubmed GAT (COO) on CPU: 0.102472 seconds per iteration, 7211.14 MB peak memory\n",
            "DGL Pubmed GAT (COO) on GPU: 0.097652 seconds per iteration, 7211.14 MB peak memory\n",
            "DGL Pubmed GAT (CSR) on CPU: 0.105977 seconds per iteration, 7211.14 MB peak memory\n",
            "DGL Pubmed GAT (CSR) on GPU: 0.106977 seconds per iteration, 7211.14 MB peak memory\n",
            "PyG Karate Club GraphSAGE (COO) on CPU: 0.000855 seconds per iteration, 7211.14 MB peak memory\n",
            "PyG Karate Club GraphSAGE (COO) on GPU: 0.000900 seconds per iteration, 7211.14 MB peak memory\n",
            "PyG Karate Club GraphSAGE (CSR) on CPU: 0.000853 seconds per iteration, 7211.14 MB peak memory\n",
            "PyG Karate Club GraphSAGE (CSR) on GPU: 0.000818 seconds per iteration, 7211.14 MB peak memory\n",
            "PyG Citeseer GraphSAGE (COO) on CPU: 0.213633 seconds per iteration, 7364.28 MB peak memory\n",
            "PyG Citeseer GraphSAGE (COO) on GPU: 0.216986 seconds per iteration, 7385.91 MB peak memory\n",
            "PyG Citeseer GraphSAGE (CSR) on CPU: 0.210067 seconds per iteration, 7339.74 MB peak memory\n",
            "PyG Citeseer GraphSAGE (CSR) on GPU: 0.214302 seconds per iteration, 7351.91 MB peak memory\n",
            "PyG Cora GraphSAGE (COO) on CPU: 0.081153 seconds per iteration, 7268.84 MB peak memory\n",
            "PyG Cora GraphSAGE (COO) on GPU: 0.075657 seconds per iteration, 7268.84 MB peak memory\n",
            "PyG Cora GraphSAGE (CSR) on CPU: 0.080864 seconds per iteration, 7268.84 MB peak memory\n",
            "PyG Cora GraphSAGE (CSR) on GPU: 0.082040 seconds per iteration, 7268.84 MB peak memory\n",
            "PyG Pubmed GraphSAGE (COO) on CPU: 0.257230 seconds per iteration, 7380.22 MB peak memory\n",
            "PyG Pubmed GraphSAGE (COO) on GPU: 0.257094 seconds per iteration, 7380.79 MB peak memory\n",
            "PyG Pubmed GraphSAGE (CSR) on CPU: 0.257862 seconds per iteration, 7380.79 MB peak memory\n",
            "PyG Pubmed GraphSAGE (CSR) on GPU: 0.260518 seconds per iteration, 7380.79 MB peak memory\n",
            "DGL Karate Club GraphSAGE (COO) on CPU: 0.001713 seconds per iteration, 7211.70 MB peak memory\n",
            "DGL Karate Club GraphSAGE (COO) on GPU: 0.002346 seconds per iteration, 7211.70 MB peak memory\n",
            "DGL Karate Club GraphSAGE (CSR) on CPU: 0.002195 seconds per iteration, 7211.70 MB peak memory\n",
            "DGL Karate Club GraphSAGE (CSR) on GPU: 0.002515 seconds per iteration, 7211.70 MB peak memory\n",
            "DGL Citeseer GraphSAGE (COO) on CPU: 0.035039 seconds per iteration, 7211.70 MB peak memory\n",
            "DGL Citeseer GraphSAGE (COO) on GPU: 0.036540 seconds per iteration, 7211.70 MB peak memory\n",
            "DGL Citeseer GraphSAGE (CSR) on CPU: 0.031021 seconds per iteration, 7211.70 MB peak memory\n",
            "DGL Citeseer GraphSAGE (CSR) on GPU: 0.032784 seconds per iteration, 7211.70 MB peak memory\n",
            "DGL Cora GraphSAGE (COO) on CPU: 0.016314 seconds per iteration, 7211.70 MB peak memory\n",
            "DGL Cora GraphSAGE (COO) on GPU: 0.015724 seconds per iteration, 7211.70 MB peak memory\n",
            "DGL Cora GraphSAGE (CSR) on CPU: 0.012033 seconds per iteration, 7211.70 MB peak memory\n",
            "DGL Cora GraphSAGE (CSR) on GPU: 0.011969 seconds per iteration, 7211.70 MB peak memory\n",
            "DGL Pubmed GraphSAGE (COO) on CPU: 0.026331 seconds per iteration, 7211.70 MB peak memory\n",
            "DGL Pubmed GraphSAGE (COO) on GPU: 0.028971 seconds per iteration, 7211.70 MB peak memory\n",
            "DGL Pubmed GraphSAGE (CSR) on CPU: 0.030704 seconds per iteration, 7211.70 MB peak memory\n",
            "DGL Pubmed GraphSAGE (CSR) on GPU: 0.026006 seconds per iteration, 7211.70 MB peak memory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IgCNVJl32TzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_geometric\n",
        "from torch_geometric.datasets import Amazon, Coauthor, PPI, Flickr\n",
        "import dgl\n",
        "from dgl.data import PPIDataset, FlickrDataset"
      ],
      "metadata": {
        "id": "CJPpqB8n2Tb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IyqFEHdJW7-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AmazonComputers Dataset\n",
        "correct\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vDr-VIDf2eaq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y-WXuGeBJQWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5vEnhTUfJNoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.datasets import Planetoid, KarateClub, Amazon, Coauthor, PPI, Reddit, Flickr\n",
        "import dgl\n",
        "from dgl.data import CiteseerGraphDataset, CoraGraphDataset, PubmedGraphDataset, PPIDataset, RedditDataset, FlickrDataset\n",
        "from dgl.nn.pytorch import GATConv as GATConvDGL, SAGEConv as SAGEConvDGL\n",
        "\n",
        "# Load datasets for PyG\n",
        "dataset_amazon_computers_pyg = Amazon(root='/tmp/AmazonComputers', name='Computers')\n",
        "data_amazon_computers_pyg = dataset_amazon_computers_pyg[0]\n",
        "# Load datasets for DGL\n",
        "graph_amazon_computers_dgl = dgl.graph((data_amazon_computers_pyg.edge_index[0], data_amazon_computers_pyg.edge_index[1]))\n",
        "\n",
        "# Ensure features and labels are set for DGL graphs\n",
        "def ensure_dgl_features_and_labels(graph, pyg_data):\n",
        "    graph.ndata['feat'] = pyg_data.x.clone().detach()\n",
        "    graph.ndata['label'] = pyg_data.y.clone().detach()\n",
        "    return graph\n",
        "\n",
        "graph_amazon_computers_dgl = ensure_dgl_features_and_labels(graph_amazon_computers_dgl, data_amazon_computers_pyg)\n",
        "\n",
        "# Add self-loops to the DGL graphs to handle 0-in-degree nodes\n",
        "graphs_dgl = {\n",
        "    'Amazon Computers': graph_amazon_computers_dgl\n",
        "}\n",
        "\n",
        "for name, graph in graphs_dgl.items():\n",
        "    graphs_dgl[name] = dgl.add_self_loop(graph)\n",
        "\n",
        "datasets_pyg_amazon_computers = {\n",
        "    'Amazon Computers': (dataset_amazon_computers_pyg, data_amazon_computers_pyg)\n",
        "}\n",
        "\n",
        "datasets_dgl_amazon_computers = {\n",
        "    'Amazon Computers': graphs_dgl['Amazon Computers']\n",
        "}"
      ],
      "metadata": {
        "id": "HptTAFaNXkgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define devices\n",
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define and test models on COO and CSR formats\n",
        "formats = ['coo', 'csr']\n",
        "models = {\n",
        "    'GCN': (GCN, GCN_DGL),\n",
        "    'GAT': (GAT, GAT_DGL),\n",
        "    'GraphSAGE': (GraphSAGE, GraphSAGE_DGL),\n",
        "    #'PNA': (PNA, PNA_DGL)\n",
        "}\n",
        "\n",
        "for model_name, (ModelPyG, ModelDGL) in models.items():\n",
        "    for dataset_name, (dataset_pyg, data_pyg) in datasets_pyg_amazon_computers.items():\n",
        "        # Calculate degree tensor for PyG PNA model\n",
        "        if model_name == 'PNA':\n",
        "            deg = torch_geometric.utils.degree(data_pyg.edge_index[0], data_pyg.num_nodes).float()\n",
        "        for fmt in formats:\n",
        "            if model_name == 'PNA':\n",
        "                model_pyg = ModelPyG(dataset_pyg.num_features, dataset_pyg.num_classes, deg=deg)\n",
        "            else:\n",
        "                model_pyg = ModelPyG(dataset_pyg.num_features, dataset_pyg.num_classes)\n",
        "            time_cpu, mem_cpu = profile_model(model_pyg, data_pyg, device_cpu, format=fmt)\n",
        "            time_gpu, mem_gpu = profile_model(model_pyg, data_pyg, device_gpu, format=fmt)\n",
        "            print(f'PyG {dataset_name} {model_name} ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "            print(f'PyG {dataset_name} {model_name} ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n",
        "\n",
        "    for dataset_name, graph_dgl in datasets_dgl_amazon_computers.items():\n",
        "        for fmt in formats:\n",
        "            input_dim = graph_dgl.ndata['feat'].shape[1]\n",
        "            output_dim = graph_dgl.ndata['label'].max().item() + 1\n",
        "            model_dgl = ModelDGL(input_dim, output_dim)\n",
        "            time_cpu, mem_cpu = profile_model(model_dgl, graph_dgl, device_cpu, dgl=True, format=fmt)\n",
        "            time_gpu, mem_gpu = profile_model(model_dgl, graph_dgl, device_gpu, dgl=True, format=fmt)\n",
        "            print(f'DGL {dataset_name} {model_name} ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "            print(f'DGL {dataset_name} {model_name} ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgpsdS122i9g",
        "outputId": "19c8ba49-070f-45de-e4b2-acb93e9ee5c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyG Amazon Computers GCN (COO) on CPU: 0.211311 seconds per iteration, 5548.11 MB peak memory\n",
            "PyG Amazon Computers GCN (COO) on GPU: 0.148071 seconds per iteration, 5548.14 MB peak memory\n",
            "PyG Amazon Computers GCN (CSR) on CPU: 0.153019 seconds per iteration, 5548.14 MB peak memory\n",
            "PyG Amazon Computers GCN (CSR) on GPU: 0.149438 seconds per iteration, 5548.14 MB peak memory\n",
            "DGL Amazon Computers GCN (COO) on CPU: 0.032600 seconds per iteration, 5510.53 MB peak memory\n",
            "DGL Amazon Computers GCN (COO) on GPU: 0.032824 seconds per iteration, 5510.53 MB peak memory\n",
            "DGL Amazon Computers GCN (CSR) on CPU: 0.036971 seconds per iteration, 5510.53 MB peak memory\n",
            "DGL Amazon Computers GCN (CSR) on GPU: 0.033462 seconds per iteration, 5510.53 MB peak memory\n",
            "PyG Amazon Computers GAT (COO) on CPU: 0.550445 seconds per iteration, 5757.47 MB peak memory\n",
            "PyG Amazon Computers GAT (COO) on GPU: 0.559175 seconds per iteration, 5757.47 MB peak memory\n",
            "PyG Amazon Computers GAT (CSR) on CPU: 0.559044 seconds per iteration, 5776.75 MB peak memory\n",
            "PyG Amazon Computers GAT (CSR) on GPU: 0.560271 seconds per iteration, 5776.75 MB peak memory\n",
            "DGL Amazon Computers GAT (COO) on CPU: 0.328077 seconds per iteration, 5529.97 MB peak memory\n",
            "DGL Amazon Computers GAT (COO) on GPU: 0.316365 seconds per iteration, 5529.97 MB peak memory\n",
            "DGL Amazon Computers GAT (CSR) on CPU: 0.315708 seconds per iteration, 5529.98 MB peak memory\n",
            "DGL Amazon Computers GAT (CSR) on GPU: 0.326112 seconds per iteration, 5529.98 MB peak memory\n",
            "PyG Amazon Computers GraphSAGE (COO) on CPU: 1.539357 seconds per iteration, 6968.70 MB peak memory\n",
            "PyG Amazon Computers GraphSAGE (COO) on GPU: 1.620018 seconds per iteration, 6844.79 MB peak memory\n",
            "PyG Amazon Computers GraphSAGE (CSR) on CPU: 1.551173 seconds per iteration, 6844.82 MB peak memory\n",
            "PyG Amazon Computers GraphSAGE (CSR) on GPU: 1.594249 seconds per iteration, 6844.82 MB peak memory\n",
            "DGL Amazon Computers GraphSAGE (COO) on CPU: 0.030360 seconds per iteration, 5406.20 MB peak memory\n",
            "DGL Amazon Computers GraphSAGE (COO) on GPU: 0.030039 seconds per iteration, 5406.20 MB peak memory\n",
            "DGL Amazon Computers GraphSAGE (CSR) on CPU: 0.039278 seconds per iteration, 5406.20 MB peak memory\n",
            "DGL Amazon Computers GraphSAGE (CSR) on GPU: 0.029797 seconds per iteration, 5406.20 MB peak memory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CIcY3AHThOgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GB97f-WxECll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Amazon Photo Dataset\n",
        "\n",
        "> *correct*\n",
        "\n"
      ],
      "metadata": {
        "id": "e9ZW3LGGEC1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.datasets import Planetoid, KarateClub, Amazon, Coauthor, PPI, Reddit, Flickr\n",
        "import dgl\n",
        "from dgl.data import CiteseerGraphDataset, CoraGraphDataset, PubmedGraphDataset, PPIDataset, RedditDataset, FlickrDataset\n",
        "from dgl.nn.pytorch import GATConv as GATConvDGL, SAGEConv as SAGEConvDGL\n",
        "\n",
        "# Load datasets for PyG\n",
        "dataset_amazon_photo_pyg = Amazon(root='/tmp/AmazonPhoto', name='Photo')\n",
        "data_amazon_photo_pyg = dataset_amazon_photo_pyg[0]\n",
        "# Load datasets for DGL\n",
        "graph_amazon_photo_dgl = dgl.graph((data_amazon_photo_pyg.edge_index[0], data_amazon_photo_pyg.edge_index[1]))\n",
        "\n",
        "# Ensure features and labels are set for DGL graphs\n",
        "def ensure_dgl_features_and_labels(graph, pyg_data):\n",
        "    graph.ndata['feat'] = pyg_data.x.clone().detach()\n",
        "    graph.ndata['label'] = pyg_data.y.clone().detach()\n",
        "    return graph\n",
        "\n",
        "graph_amazon_photo_dgl = ensure_dgl_features_and_labels(graph_amazon_photo_dgl, data_amazon_photo_pyg)\n",
        "\n",
        "\n",
        "# Add self-loops to the DGL graphs to handle 0-in-degree nodes\n",
        "graphs_dgl = {\n",
        "    'Amazon Photo': graph_amazon_photo_dgl\n",
        "}\n",
        "\n",
        "for name, graph in graphs_dgl.items():\n",
        "    graphs_dgl[name] = dgl.add_self_loop(graph)\n",
        "\n",
        "datasets_pyg_amazon_photo = {\n",
        "    'Amazon Photo': (dataset_amazon_photo_pyg, data_amazon_photo_pyg),\n",
        "}\n",
        "\n",
        "datasets_dgl_amazon_photo = {\n",
        "    'Amazon Photo': graphs_dgl['Amazon Photo'],\n",
        "}"
      ],
      "metadata": {
        "id": "PXiJtFMaELM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define devices\n",
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define and test models on COO and CSR formats\n",
        "formats = ['coo', 'csr']\n",
        "models = {\n",
        "    'GCN': (GCN, GCN_DGL),\n",
        "    'GAT': (GAT, GAT_DGL),\n",
        "    'GraphSAGE': (GraphSAGE, GraphSAGE_DGL),\n",
        "    #'PNA': (PNA, PNA_DGL)\n",
        "}\n",
        "\n",
        "for model_name, (ModelPyG, ModelDGL) in models.items():\n",
        "    for dataset_name, (dataset_pyg, data_pyg) in datasets_pyg_amazon_photo.items():\n",
        "        # Calculate degree tensor for PyG PNA model\n",
        "        if model_name == 'PNA':\n",
        "            deg = torch_geometric.utils.degree(data_pyg.edge_index[0], data_pyg.num_nodes).float()\n",
        "        for fmt in formats:\n",
        "            if model_name == 'PNA':\n",
        "                model_pyg = ModelPyG(dataset_pyg.num_features, dataset_pyg.num_classes, deg=deg)\n",
        "            else:\n",
        "                model_pyg = ModelPyG(dataset_pyg.num_features, dataset_pyg.num_classes)\n",
        "            time_cpu, mem_cpu = profile_model(model_pyg, data_pyg, device_cpu, format=fmt)\n",
        "            time_gpu, mem_gpu = profile_model(model_pyg, data_pyg, device_gpu, format=fmt)\n",
        "            print(f'PyG {dataset_name} {model_name} ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "            print(f'PyG {dataset_name} {model_name} ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n",
        "\n",
        "    for dataset_name, graph_dgl in datasets_dgl_amazon_photo.items():\n",
        "        for fmt in formats:\n",
        "            input_dim = graph_dgl.ndata['feat'].shape[1]\n",
        "            output_dim = graph_dgl.ndata['label'].max().item() + 1\n",
        "            model_dgl = ModelDGL(input_dim, output_dim)\n",
        "            time_cpu, mem_cpu = profile_model(model_dgl, graph_dgl, device_cpu, dgl=True, format=fmt)\n",
        "            time_gpu, mem_gpu = profile_model(model_dgl, graph_dgl, device_gpu, dgl=True, format=fmt)\n",
        "            print(f'DGL {dataset_name} {model_name} ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "            print(f'DGL {dataset_name} {model_name} ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRTyKxJzEgcy",
        "outputId": "0bcfe272-ee10-4a56-9c5a-25e816198ce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyG Amazon Photo GCN (COO) on CPU: 0.078241 seconds per iteration, 5218.05 MB peak memory\n",
            "PyG Amazon Photo GCN (COO) on GPU: 0.064290 seconds per iteration, 5218.07 MB peak memory\n",
            "PyG Amazon Photo GCN (CSR) on CPU: 0.075476 seconds per iteration, 5218.07 MB peak memory\n",
            "PyG Amazon Photo GCN (CSR) on GPU: 0.082685 seconds per iteration, 5218.07 MB peak memory\n",
            "DGL Amazon Photo GCN (COO) on CPU: 0.023630 seconds per iteration, 5218.10 MB peak memory\n",
            "DGL Amazon Photo GCN (COO) on GPU: 0.018715 seconds per iteration, 5218.10 MB peak memory\n",
            "DGL Amazon Photo GCN (CSR) on CPU: 0.018804 seconds per iteration, 5218.10 MB peak memory\n",
            "DGL Amazon Photo GCN (CSR) on GPU: 0.019447 seconds per iteration, 5218.10 MB peak memory\n",
            "PyG Amazon Photo GAT (COO) on CPU: 0.230910 seconds per iteration, 5278.18 MB peak memory\n",
            "PyG Amazon Photo GAT (COO) on GPU: 0.281870 seconds per iteration, 5277.42 MB peak memory\n",
            "PyG Amazon Photo GAT (CSR) on CPU: 0.239136 seconds per iteration, 5275.73 MB peak memory\n",
            "PyG Amazon Photo GAT (CSR) on GPU: 0.236617 seconds per iteration, 5277.42 MB peak memory\n",
            "DGL Amazon Photo GAT (COO) on CPU: 0.152253 seconds per iteration, 5217.41 MB peak memory\n",
            "DGL Amazon Photo GAT (COO) on GPU: 0.209468 seconds per iteration, 5217.41 MB peak memory\n",
            "DGL Amazon Photo GAT (CSR) on CPU: 0.145413 seconds per iteration, 5217.41 MB peak memory\n",
            "DGL Amazon Photo GAT (CSR) on GPU: 0.153055 seconds per iteration, 5217.41 MB peak memory\n",
            "PyG Amazon Photo GraphSAGE (COO) on CPU: 0.748609 seconds per iteration, 5894.27 MB peak memory\n",
            "PyG Amazon Photo GraphSAGE (COO) on GPU: 0.747205 seconds per iteration, 5894.27 MB peak memory\n",
            "PyG Amazon Photo GraphSAGE (CSR) on CPU: 0.732269 seconds per iteration, 5894.27 MB peak memory\n",
            "PyG Amazon Photo GraphSAGE (CSR) on GPU: 0.743745 seconds per iteration, 5894.27 MB peak memory\n",
            "DGL Amazon Photo GraphSAGE (COO) on CPU: 0.015656 seconds per iteration, 5217.42 MB peak memory\n",
            "DGL Amazon Photo GraphSAGE (COO) on GPU: 0.018640 seconds per iteration, 5217.42 MB peak memory\n",
            "DGL Amazon Photo GraphSAGE (CSR) on CPU: 0.020731 seconds per iteration, 5217.43 MB peak memory\n",
            "DGL Amazon Photo GraphSAGE (CSR) on GPU: 0.016238 seconds per iteration, 5217.43 MB peak memory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OaJaoXZmEDE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bIMy6nKyIJuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CoauthorCS Dataset"
      ],
      "metadata": {
        "id": "Qo1X6074IJ-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.datasets import Planetoid, KarateClub, Amazon, Coauthor, PPI, Reddit, Flickr\n",
        "import dgl\n",
        "from dgl.data import CiteseerGraphDataset, CoraGraphDataset, PubmedGraphDataset, PPIDataset, RedditDataset, FlickrDataset\n",
        "from dgl.nn.pytorch import GATConv as GATConvDGL, SAGEConv as SAGEConvDGL\n",
        "\n",
        "# Load datasets for PyG\n",
        "dataset_coauthor_cs_pyg = Coauthor(root='/tmp/CoauthorCS', name='CS')\n",
        "data_coauthor_cs_pyg = dataset_coauthor_cs_pyg[0]\n",
        "# Load datasets for DGL\n",
        "graph_coauthor_cs_dgl = dgl.graph((data_coauthor_cs_pyg.edge_index[0], data_coauthor_cs_pyg.edge_index[1]))\n",
        "\n",
        "# Ensure features and labels are set for DGL graphs\n",
        "def ensure_dgl_features_and_labels(graph, pyg_data):\n",
        "    graph.ndata['feat'] = pyg_data.x.clone().detach()\n",
        "    graph.ndata['label'] = pyg_data.y.clone().detach()\n",
        "    return graph\n",
        "\n",
        "graph_coauthor_cs_dgl = ensure_dgl_features_and_labels(graph_coauthor_cs_dgl, data_coauthor_cs_pyg)\n",
        "\n",
        "# Add self-loops to the DGL graphs to handle 0-in-degree nodes\n",
        "graphs_dgl = {\n",
        "    'Coauthor CS': graph_coauthor_cs_dgl\n",
        "}\n",
        "\n",
        "for name, graph in graphs_dgl.items():\n",
        "    graphs_dgl[name] = dgl.add_self_loop(graph)\n",
        "\n",
        "datasets_pyg_CoauthorCS = {\n",
        "    'Coauthor CS': (dataset_coauthor_cs_pyg, data_coauthor_cs_pyg)\n",
        "}\n",
        "\n",
        "datasets_dgl_CoauthorCS = {\n",
        "    'Coauthor CS': graphs_dgl['Coauthor CS']\n",
        "}"
      ],
      "metadata": {
        "id": "RkUvIo-bIKMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define devices\n",
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define and test models on COO and CSR formats\n",
        "formats = ['coo', 'csr']\n",
        "models = {\n",
        "    'GCN': (GCN, GCN_DGL),\n",
        "    'GAT': (GAT, GAT_DGL),\n",
        "    'GraphSAGE': (GraphSAGE, GraphSAGE_DGL),\n",
        "    #'PNA': (PNA, PNA_DGL)\n",
        "}\n",
        "\n",
        "for model_name, (ModelPyG, ModelDGL) in models.items():\n",
        "    for dataset_name, (dataset_pyg, data_pyg) in datasets_pyg_CoauthorCS.items():\n",
        "        # Calculate degree tensor for PyG PNA model\n",
        "        if model_name == 'PNA':\n",
        "            deg = torch_geometric.utils.degree(data_pyg.edge_index[0], data_pyg.num_nodes).float()\n",
        "        for fmt in formats:\n",
        "            if model_name == 'PNA':\n",
        "                model_pyg = ModelPyG(dataset_pyg.num_features, dataset_pyg.num_classes, deg=deg)\n",
        "            else:\n",
        "                model_pyg = ModelPyG(dataset_pyg.num_features, dataset_pyg.num_classes)\n",
        "            time_cpu, mem_cpu = profile_model(model_pyg, data_pyg, device_cpu, format=fmt)\n",
        "            time_gpu, mem_gpu = profile_model(model_pyg, data_pyg, device_gpu, format=fmt)\n",
        "            print(f'PyG {dataset_name} {model_name} ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "            print(f'PyG {dataset_name} {model_name} ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n",
        "\n",
        "    for dataset_name, graph_dgl in datasets_dgl_CoauthorCS.items():\n",
        "        for fmt in formats:\n",
        "            input_dim = graph_dgl.ndata['feat'].shape[1]\n",
        "            output_dim = graph_dgl.ndata['label'].max().item() + 1\n",
        "            model_dgl = ModelDGL(input_dim, output_dim)\n",
        "            time_cpu, mem_cpu = profile_model(model_dgl, graph_dgl, device_cpu, dgl=True, format=fmt)\n",
        "            time_gpu, mem_gpu = profile_model(model_dgl, graph_dgl, device_gpu, dgl=True, format=fmt)\n",
        "            print(f'DGL {dataset_name} {model_name} ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "            print(f'DGL {dataset_name} {model_name} ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-MuMW06KHzV",
        "outputId": "cbcc3e9f-2f5e-43d7-b079-1f189ddbfc5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyG Coauthor CS GCN (COO) on CPU: 0.249697 seconds per iteration, 6169.25 MB peak memory\n",
            "PyG Coauthor CS GCN (COO) on GPU: 0.257429 seconds per iteration, 6169.25 MB peak memory\n",
            "PyG Coauthor CS GCN (CSR) on CPU: 0.258276 seconds per iteration, 6169.25 MB peak memory\n",
            "PyG Coauthor CS GCN (CSR) on GPU: 0.256737 seconds per iteration, 6169.25 MB peak memory\n",
            "DGL Coauthor CS GCN (COO) on CPU: 0.613521 seconds per iteration, 6645.16 MB peak memory\n",
            "DGL Coauthor CS GCN (COO) on GPU: 0.599712 seconds per iteration, 6645.16 MB peak memory\n",
            "DGL Coauthor CS GCN (CSR) on CPU: 0.601166 seconds per iteration, 6645.16 MB peak memory\n",
            "DGL Coauthor CS GCN (CSR) on GPU: 0.597603 seconds per iteration, 6645.16 MB peak memory\n",
            "PyG Coauthor CS GAT (COO) on CPU: 0.673392 seconds per iteration, 6169.25 MB peak memory\n",
            "PyG Coauthor CS GAT (COO) on GPU: 0.689402 seconds per iteration, 6213.71 MB peak memory\n",
            "PyG Coauthor CS GAT (CSR) on CPU: 0.664841 seconds per iteration, 6201.96 MB peak memory\n",
            "PyG Coauthor CS GAT (CSR) on GPU: 0.664953 seconds per iteration, 6213.71 MB peak memory\n",
            "DGL Coauthor CS GAT (COO) on CPU: 0.601586 seconds per iteration, 6169.30 MB peak memory\n",
            "DGL Coauthor CS GAT (COO) on GPU: 0.578313 seconds per iteration, 6169.30 MB peak memory\n",
            "DGL Coauthor CS GAT (CSR) on CPU: 0.597363 seconds per iteration, 6169.30 MB peak memory\n",
            "DGL Coauthor CS GAT (CSR) on GPU: 0.583889 seconds per iteration, 6169.30 MB peak memory\n",
            "PyG Coauthor CS GraphSAGE (COO) on CPU: 5.390388 seconds per iteration, 11251.83 MB peak memory\n",
            "PyG Coauthor CS GraphSAGE (COO) on GPU: 5.317198 seconds per iteration, 11347.91 MB peak memory\n",
            "PyG Coauthor CS GraphSAGE (CSR) on CPU: 5.283137 seconds per iteration, 11337.32 MB peak memory\n",
            "PyG Coauthor CS GraphSAGE (CSR) on GPU: 5.313482 seconds per iteration, 11338.09 MB peak memory\n",
            "DGL Coauthor CS GraphSAGE (COO) on CPU: 0.342809 seconds per iteration, 6166.22 MB peak memory\n",
            "DGL Coauthor CS GraphSAGE (COO) on GPU: 0.353922 seconds per iteration, 6166.22 MB peak memory\n",
            "DGL Coauthor CS GraphSAGE (CSR) on CPU: 0.357821 seconds per iteration, 6166.22 MB peak memory\n",
            "DGL Coauthor CS GraphSAGE (CSR) on GPU: 0.341464 seconds per iteration, 6166.31 MB peak memory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qtZjDhohKHdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R0PEJn8GIKZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_knWYPzwEDpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_geometric\n",
        "from torch_geometric.datasets import Amazon, Coauthor, PPI, Flickr\n",
        "import dgl\n",
        "from dgl.data import PPIDataset, FlickrDataset\n",
        "\n",
        "# Load datasets for PyG\n",
        "dataset_amazon_computers_pyg = Amazon(root='/tmp/AmazonComputers', name='Computers')\n",
        "data_amazon_computers_pyg = dataset_amazon_computers_pyg[0]\n",
        "\n",
        "dataset_amazon_photo_pyg = Amazon(root='/tmp/AmazonPhoto', name='Photo')\n",
        "data_amazon_photo_pyg = dataset_amazon_photo_pyg[0]\n",
        "\n",
        "dataset_coauthor_cs_pyg = Coauthor(root='/tmp/CoauthorCS', name='CS')\n",
        "data_coauthor_cs_pyg = dataset_coauthor_cs_pyg[0]\n",
        "\n",
        "dataset_coauthor_physics_pyg = Coauthor(root='/tmp/CoauthorPhysics', name='Physics')\n",
        "data_coauthor_physics_pyg = dataset_coauthor_physics_pyg[0]\n",
        "\n",
        "dataset_ppi_pyg = PPI(root='/tmp/PPI')\n",
        "data_ppi_pyg = dataset_ppi_pyg[0]\n",
        "\n",
        "dataset_flickr_pyg = Flickr(root='/tmp/Flickr')\n",
        "data_flickr_pyg = dataset_flickr_pyg[0]\n",
        "\n",
        "# Load datasets for DGL\n",
        "graph_amazon_computers_dgl = dgl.graph((data_amazon_computers_pyg.edge_index[0], data_amazon_computers_pyg.edge_index[1]))\n",
        "graph_amazon_photo_dgl = dgl.graph((data_amazon_photo_pyg.edge_index[0], data_amazon_photo_pyg.edge_index[1]))\n",
        "graph_coauthor_cs_dgl = dgl.graph((data_coauthor_cs_pyg.edge_index[0], data_coauthor_cs_pyg.edge_index[1]))\n",
        "graph_coauthor_physics_dgl = dgl.graph((data_coauthor_physics_pyg.edge_index[0], data_coauthor_physics_pyg.edge_index[1]))\n",
        "graph_ppi_dgl = PPIDataset()[0]\n",
        "graph_flickr_dgl = FlickrDataset()[0]\n",
        "\n",
        "# Ensure features and labels are set for DGL graphs\n",
        "def ensure_dgl_features_and_labels(graph, pyg_data):\n",
        "    graph.ndata['feat'] = pyg_data.x.clone().detach()\n",
        "    graph.ndata['label'] = pyg_data.y.clone().detach()\n",
        "    return graph\n",
        "\n",
        "graph_amazon_computers_dgl = ensure_dgl_features_and_labels(graph_amazon_computers_dgl, data_amazon_computers_pyg)\n",
        "graph_amazon_photo_dgl = ensure_dgl_features_and_labels(graph_amazon_photo_dgl, data_amazon_photo_pyg)\n",
        "graph_coauthor_cs_dgl = ensure_dgl_features_and_labels(graph_coauthor_cs_dgl, data_coauthor_cs_pyg)\n",
        "graph_coauthor_physics_dgl = ensure_dgl_features_and_labels(graph_coauthor_physics_dgl, data_coauthor_physics_pyg)\n",
        "graph_ppi_dgl = ensure_dgl_features_and_labels(graph_ppi_dgl, data_ppi_pyg)\n",
        "graph_flickr_dgl = ensure_dgl_features_and_labels(graph_flickr_dgl, data_flickr_pyg)\n",
        "\n",
        "# Add self-loops to the DGL graphs to handle 0-in-degree nodes\n",
        "graphs_dgl = {\n",
        "    'Amazon Computers': graph_amazon_computers_dgl,\n",
        "    'Amazon Photo': graph_amazon_photo_dgl,\n",
        "    'Coauthor CS': graph_coauthor_cs_dgl,\n",
        "    'Coauthor Physics': graph_coauthor_physics_dgl,\n",
        "    'PPI': graph_ppi_dgl,\n",
        "    'Flickr': graph_flickr_dgl\n",
        "}\n",
        "\n",
        "for name, graph in graphs_dgl.items():\n",
        "    graphs_dgl[name] = dgl.add_self_loop(graph)\n",
        "\n",
        "# Print dataset information\n",
        "def print_pyg_dataset_info(name, dataset, data):\n",
        "    print(f\"PyG {name} Dataset:\")\n",
        "    print(f\"  Number of nodes: {data.num_nodes}\")\n",
        "    print(f\"  Number of edges: {data.num_edges // 2}\")  # edges are doubled\n",
        "    print(f\"  Number of features: {dataset.num_features}\")\n",
        "    print(f\"  Number of classes: {dataset.num_classes}\")\n",
        "    print(f\"  Edge index shape: {data.edge_index.shape}\")\n",
        "    print(f\"  Features shape: {data.x.shape}\")\n",
        "    print(f\"  Labels shape: {data.y.shape}\\n\")\n",
        "\n",
        "def print_dgl_dataset_info(name, graph):\n",
        "    print(f\"DGL {name} Dataset:\")\n",
        "    print(f\"  Number of nodes: {graph.num_nodes()}\")\n",
        "    print(f\"  Number of edges: {graph.num_edges() // 2}\")  # edges are doubled\n",
        "    print(f\"  Number of features: {graph.ndata['feat'].shape[1]}\")\n",
        "    print(f\"  Number of classes: {len(torch.unique(graph.ndata['label']))}\")\n",
        "    print(f\"  Edge index shape: {graph.edges(form='all')[0].shape}\")\n",
        "    print(f\"  Features shape: {graph.ndata['feat'].shape}\")\n",
        "    print(f\"  Labels shape: {graph.ndata['label'].shape}\\n\")\n",
        "\n",
        "# Print information for PyG datasets\n",
        "datasets_pyg = {\n",
        "    'Amazon Computers': (dataset_amazon_computers_pyg, data_amazon_computers_pyg),\n",
        "    'Amazon Photo': (dataset_amazon_photo_pyg, data_amazon_photo_pyg),\n",
        "    'Coauthor CS': (dataset_coauthor_cs_pyg, data_coauthor_cs_pyg),\n",
        "    'Coauthor Physics': (dataset_coauthor_physics_pyg, data_coauthor_physics_pyg),\n",
        "    'PPI': (dataset_ppi_pyg, data_ppi_pyg),\n",
        "    'Flickr': (dataset_flickr_pyg, data_flickr_pyg)\n",
        "}\n",
        "\n",
        "for name, (dataset, data) in datasets_pyg.items():\n",
        "    print_pyg_dataset_info(name, dataset, data)\n",
        "\n",
        "# Print information for DGL datasets\n",
        "datasets_dgl = {\n",
        "    'Amazon Computers': graphs_dgl['Amazon Computers'],\n",
        "    'Amazon Photo': graphs_dgl['Amazon Photo'],\n",
        "    'Coauthor CS': graphs_dgl['Coauthor CS'],\n",
        "    'Coauthor Physics': graphs_dgl['Coauthor Physics'],\n",
        "    'PPI': graphs_dgl['PPI'],\n",
        "    'Flickr': graphs_dgl['Flickr']\n",
        "}\n",
        "\n",
        "for name, graph in datasets_dgl.items():\n",
        "    print_dgl_dataset_info(name, graph)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qOuiHqIhOIi",
        "outputId": "b44cef0b-37ad-4d32-add1-53b7833f4cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyG Amazon Computers Dataset:\n",
            "  Number of nodes: 13752\n",
            "  Number of edges: 245861\n",
            "  Number of features: 767\n",
            "  Number of classes: 10\n",
            "  Edge index shape: torch.Size([2, 491722])\n",
            "  Features shape: torch.Size([13752, 767])\n",
            "  Labels shape: torch.Size([13752])\n",
            "\n",
            "PyG Amazon Photo Dataset:\n",
            "  Number of nodes: 7650\n",
            "  Number of edges: 119081\n",
            "  Number of features: 745\n",
            "  Number of classes: 8\n",
            "  Edge index shape: torch.Size([2, 238162])\n",
            "  Features shape: torch.Size([7650, 745])\n",
            "  Labels shape: torch.Size([7650])\n",
            "\n",
            "PyG Coauthor CS Dataset:\n",
            "  Number of nodes: 18333\n",
            "  Number of edges: 81894\n",
            "  Number of features: 6805\n",
            "  Number of classes: 15\n",
            "  Edge index shape: torch.Size([2, 163788])\n",
            "  Features shape: torch.Size([18333, 6805])\n",
            "  Labels shape: torch.Size([18333])\n",
            "\n",
            "PyG Coauthor Physics Dataset:\n",
            "  Number of nodes: 34493\n",
            "  Number of edges: 247962\n",
            "  Number of features: 8415\n",
            "  Number of classes: 5\n",
            "  Edge index shape: torch.Size([2, 495924])\n",
            "  Features shape: torch.Size([34493, 8415])\n",
            "  Labels shape: torch.Size([34493])\n",
            "\n",
            "PyG PPI Dataset:\n",
            "  Number of nodes: 1767\n",
            "  Number of edges: 16159\n",
            "  Number of features: 50\n",
            "  Number of classes: 121\n",
            "  Edge index shape: torch.Size([2, 32318])\n",
            "  Features shape: torch.Size([1767, 50])\n",
            "  Labels shape: torch.Size([1767, 121])\n",
            "\n",
            "PyG Flickr Dataset:\n",
            "  Number of nodes: 89250\n",
            "  Number of edges: 449878\n",
            "  Number of features: 500\n",
            "  Number of classes: 7\n",
            "  Edge index shape: torch.Size([2, 899756])\n",
            "  Features shape: torch.Size([89250, 500])\n",
            "  Labels shape: torch.Size([89250])\n",
            "\n",
            "DGL Amazon Computers Dataset:\n",
            "  Number of nodes: 13752\n",
            "  Number of edges: 252737\n",
            "  Number of features: 767\n",
            "  Number of classes: 10\n",
            "  Edge index shape: torch.Size([505474])\n",
            "  Features shape: torch.Size([13752, 767])\n",
            "  Labels shape: torch.Size([13752])\n",
            "\n",
            "DGL Amazon Photo Dataset:\n",
            "  Number of nodes: 7650\n",
            "  Number of edges: 122906\n",
            "  Number of features: 745\n",
            "  Number of classes: 8\n",
            "  Edge index shape: torch.Size([245812])\n",
            "  Features shape: torch.Size([7650, 745])\n",
            "  Labels shape: torch.Size([7650])\n",
            "\n",
            "DGL Coauthor CS Dataset:\n",
            "  Number of nodes: 18333\n",
            "  Number of edges: 91060\n",
            "  Number of features: 6805\n",
            "  Number of classes: 15\n",
            "  Edge index shape: torch.Size([182121])\n",
            "  Features shape: torch.Size([18333, 6805])\n",
            "  Labels shape: torch.Size([18333])\n",
            "\n",
            "DGL Coauthor Physics Dataset:\n",
            "  Number of nodes: 34493\n",
            "  Number of edges: 265208\n",
            "  Number of features: 8415\n",
            "  Number of classes: 5\n",
            "  Edge index shape: torch.Size([530417])\n",
            "  Features shape: torch.Size([34493, 8415])\n",
            "  Labels shape: torch.Size([34493])\n",
            "\n",
            "DGL PPI Dataset:\n",
            "  Number of nodes: 1767\n",
            "  Number of edges: 17926\n",
            "  Number of features: 50\n",
            "  Number of classes: 2\n",
            "  Edge index shape: torch.Size([35852])\n",
            "  Features shape: torch.Size([1767, 50])\n",
            "  Labels shape: torch.Size([1767, 121])\n",
            "\n",
            "DGL Flickr Dataset:\n",
            "  Number of nodes: 89250\n",
            "  Number of edges: 494503\n",
            "  Number of features: 500\n",
            "  Number of classes: 7\n",
            "  Edge index shape: torch.Size([989006])\n",
            "  Features shape: torch.Size([89250, 500])\n",
            "  Labels shape: torch.Size([89250])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u4JljwXehYfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define devices\n",
        "device_cpu = torch.device('cpu')\n",
        "device_gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "ec7eFS-ZI8ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define and test models on COO and CSR formats\n",
        "formats = ['coo', 'csr']\n",
        "models = {\n",
        "    'GCN': (GCN, GCN_DGL),\n",
        "    'GAT': (GAT, GAT_DGL),\n",
        "    'GraphSAGE': (GraphSAGE, GraphSAGE_DGL),\n",
        "    #'PNA': (PNA, PNA_DGL)\n",
        "}\n",
        "\n",
        "for model_name, (ModelPyG, ModelDGL) in models.items():\n",
        "    for dataset_name, (dataset_pyg, data_pyg) in datasets_pyg.items():\n",
        "        # Calculate degree tensor for PyG PNA model\n",
        "        if model_name == 'PNA':\n",
        "            deg = torch_geometric.utils.degree(data_pyg.edge_index[0], data_pyg.num_nodes).float()\n",
        "        for fmt in formats:\n",
        "            if model_name == 'PNA':\n",
        "                model_pyg = ModelPyG(dataset_pyg.num_features, dataset_pyg.num_classes, deg=deg)\n",
        "            else:\n",
        "                model_pyg = ModelPyG(dataset_pyg.num_features, dataset_pyg.num_classes)\n",
        "            time_cpu, mem_cpu = profile_model(model_pyg, data_pyg, device_cpu, format=fmt)\n",
        "            time_gpu, mem_gpu = profile_model(model_pyg, data_pyg, device_gpu, format=fmt)\n",
        "            print(f'PyG {dataset_name} {model_name} ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "            print(f'PyG {dataset_name} {model_name} ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n",
        "\n",
        "    for dataset_name, graph_dgl in datasets_dgl.items():\n",
        "        for fmt in formats:\n",
        "            input_dim = graph_dgl.ndata['feat'].shape[1]\n",
        "            output_dim = graph_dgl.ndata['label'].max().item() + 1\n",
        "            model_dgl = ModelDGL(input_dim, output_dim)\n",
        "            time_cpu, mem_cpu = profile_model(model_dgl, graph_dgl, device_cpu, dgl=True, format=fmt)\n",
        "            time_gpu, mem_gpu = profile_model(model_dgl, graph_dgl, device_gpu, dgl=True, format=fmt)\n",
        "            print(f'DGL {dataset_name} {model_name} ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "            print(f'DGL {dataset_name} {model_name} ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9BwY0Fg3hYIx",
        "outputId": "b89f3430-60f8-4ec8-8389-eb9ad3db4141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyG Amazon Computers GCN (COO) on CPU: 0.211223 seconds per iteration, 5105.08 MB peak memory\n",
            "PyG Amazon Computers GCN (COO) on GPU: 0.187418 seconds per iteration, 5105.54 MB peak memory\n",
            "PyG Amazon Computers GCN (CSR) on CPU: 0.170395 seconds per iteration, 5124.83 MB peak memory\n",
            "PyG Amazon Computers GCN (CSR) on GPU: 0.184569 seconds per iteration, 5105.34 MB peak memory\n",
            "PyG Amazon Photo GCN (COO) on CPU: 0.067607 seconds per iteration, 5105.49 MB peak memory\n",
            "PyG Amazon Photo GCN (COO) on GPU: 0.069725 seconds per iteration, 5105.53 MB peak memory\n",
            "PyG Amazon Photo GCN (CSR) on CPU: 0.061381 seconds per iteration, 5039.46 MB peak memory\n",
            "PyG Amazon Photo GCN (CSR) on GPU: 0.071416 seconds per iteration, 5039.46 MB peak memory\n",
            "PyG Coauthor CS GCN (COO) on CPU: 0.231826 seconds per iteration, 5052.44 MB peak memory\n",
            "PyG Coauthor CS GCN (COO) on GPU: 0.229854 seconds per iteration, 5052.44 MB peak memory\n",
            "PyG Coauthor CS GCN (CSR) on CPU: 0.226484 seconds per iteration, 5073.97 MB peak memory\n",
            "PyG Coauthor CS GCN (CSR) on GPU: 0.225109 seconds per iteration, 5085.09 MB peak memory\n",
            "PyG Coauthor Physics GCN (COO) on CPU: 0.567206 seconds per iteration, 5117.47 MB peak memory\n",
            "PyG Coauthor Physics GCN (COO) on GPU: 0.549823 seconds per iteration, 5149.93 MB peak memory\n",
            "PyG Coauthor Physics GCN (CSR) on CPU: 0.602562 seconds per iteration, 5107.05 MB peak memory\n",
            "PyG Coauthor Physics GCN (CSR) on GPU: 0.559344 seconds per iteration, 5110.10 MB peak memory\n",
            "PyG PPI GCN (COO) on CPU: 0.049462 seconds per iteration, 5041.11 MB peak memory\n",
            "PyG PPI GCN (COO) on GPU: 0.038900 seconds per iteration, 5041.11 MB peak memory\n",
            "PyG PPI GCN (CSR) on CPU: 0.021819 seconds per iteration, 5072.57 MB peak memory\n",
            "PyG PPI GCN (CSR) on GPU: 0.021637 seconds per iteration, 5072.57 MB peak memory\n",
            "PyG Flickr GCN (COO) on CPU: 0.395191 seconds per iteration, 5213.75 MB peak memory\n",
            "PyG Flickr GCN (COO) on GPU: 0.383823 seconds per iteration, 5287.48 MB peak memory\n",
            "PyG Flickr GCN (CSR) on CPU: 0.379677 seconds per iteration, 5240.84 MB peak memory\n",
            "PyG Flickr GCN (CSR) on GPU: 0.414225 seconds per iteration, 5298.13 MB peak memory\n",
            "DGL Amazon Computers GCN (COO) on CPU: 0.035895 seconds per iteration, 5178.81 MB peak memory\n",
            "DGL Amazon Computers GCN (COO) on GPU: 0.031453 seconds per iteration, 5178.81 MB peak memory\n",
            "DGL Amazon Computers GCN (CSR) on CPU: 0.031641 seconds per iteration, 5178.81 MB peak memory\n",
            "DGL Amazon Computers GCN (CSR) on GPU: 0.037452 seconds per iteration, 5178.81 MB peak memory\n",
            "DGL Amazon Photo GCN (COO) on CPU: 0.018623 seconds per iteration, 5178.82 MB peak memory\n",
            "DGL Amazon Photo GCN (COO) on GPU: 0.018062 seconds per iteration, 5178.82 MB peak memory\n",
            "DGL Amazon Photo GCN (CSR) on CPU: 0.017824 seconds per iteration, 5178.82 MB peak memory\n",
            "DGL Amazon Photo GCN (CSR) on GPU: 0.017962 seconds per iteration, 5178.82 MB peak memory\n",
            "DGL Coauthor CS GCN (COO) on CPU: 0.665749 seconds per iteration, 5654.88 MB peak memory\n",
            "DGL Coauthor CS GCN (COO) on GPU: 0.639171 seconds per iteration, 5654.88 MB peak memory\n",
            "DGL Coauthor CS GCN (CSR) on CPU: 0.612666 seconds per iteration, 5654.88 MB peak memory\n",
            "DGL Coauthor CS GCN (CSR) on GPU: 0.604594 seconds per iteration, 5654.88 MB peak memory\n",
            "DGL Coauthor Physics GCN (COO) on CPU: 1.391449 seconds per iteration, 6286.24 MB peak memory\n",
            "DGL Coauthor Physics GCN (COO) on GPU: 1.391339 seconds per iteration, 6286.24 MB peak memory\n",
            "DGL Coauthor Physics GCN (CSR) on CPU: 1.459763 seconds per iteration, 6228.02 MB peak memory\n",
            "DGL Coauthor Physics GCN (CSR) on GPU: 1.447222 seconds per iteration, 6228.30 MB peak memory\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "new(): argument 'size' failed to unpack the object at pos 2 with error \"type must be tuple of ints,but got float\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-11483713a7f8>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_dgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0moutput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_dgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mmodel_dgl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelDGL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mtime_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprofile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dgl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_dgl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mtime_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprofile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dgl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_dgl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-b959cedb35f5>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_feats, out_feats)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGCN_DGL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_feats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/nn/pytorch/conv/graphconv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_feats, out_feats, norm, weight, bias, activation, allow_zero_in_degree)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_feats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: new(): argument 'size' failed to unpack the object at pos 2 with error \"type must be tuple of ints,but got float\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aHiqZvxzhKOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_amazon_computers_pyg = Amazon(root='/tmp/AmazonComputers', name='Computers')\n",
        "data_amazon_computers_pyg = dataset_amazon_computers_pyg[0]\n",
        "\n",
        "dataset_amazon_photo_pyg = Amazon(root='/tmp/AmazonPhoto', name='Photo')\n",
        "data_amazon_photo_pyg = dataset_amazon_photo_pyg[0]\n",
        "\n",
        "dataset_coauthor_cs_pyg = Coauthor(root='/tmp/CoauthorCS', name='CS')\n",
        "data_coauthor_cs_pyg = dataset_coauthor_cs_pyg[0]\n",
        "\n",
        "dataset_coauthor_physics_pyg = Coauthor(root='/tmp/CoauthorPhysics', name='Physics')\n",
        "data_coauthor_physics_pyg = dataset_coauthor_physics_pyg[0]\n",
        "\n",
        "dataset_ppi_pyg = PPI(root='/tmp/PPI')\n",
        "data_ppi_pyg = dataset_ppi_pyg[0]\n",
        "\n",
        "# dataset_reddit_pyg = Reddit(root='/tmp/Reddit')\n",
        "# data_reddit_pyg = dataset_reddit_pyg[0]\n",
        "\n",
        "dataset_flickr_pyg = Flickr(root='/tmp/Flickr')\n",
        "data_flickr_pyg = dataset_flickr_pyg[0]\n",
        "\n",
        "# Load datasets for DGL\n",
        "graph_amazon_computers_dgl = dgl.graph((data_amazon_computers_pyg.edge_index[0], data_amazon_computers_pyg.edge_index[1]))\n",
        "graph_amazon_computers_dgl = ensure_dgl_features_and_labels(graph_amazon_computers_dgl, data_amazon_computers_pyg)\n",
        "\n",
        "graph_amazon_photo_dgl = dgl.graph((data_amazon_photo_pyg.edge_index[0], data_amazon_photo_pyg.edge_index[1]))\n",
        "graph_amazon_photo_dgl = ensure_dgl_features_and_labels(graph_amazon_photo_dgl, data_amazon_photo_pyg)\n",
        "\n",
        "graph_coauthor_cs_dgl = dgl.graph((data_coauthor_cs_pyg.edge_index[0], data_coauthor_cs_pyg.edge_index[1]))\n",
        "graph_coauthor_cs_dgl = ensure_dgl_features_and_labels(graph_coauthor_cs_dgl, data_coauthor_cs_pyg)\n",
        "\n",
        "graph_coauthor_physics_dgl = dgl.graph((data_coauthor_physics_pyg.edge_index[0], data_coauthor_physics_pyg.edge_index[1]))\n",
        "graph_coauthor_physics_dgl = ensure_dgl_features_and_labels(graph_coauthor_physics_dgl, data_coauthor_physics_pyg)\n",
        "\n",
        "graph_ppi_dgl = PPIDataset()[0]\n",
        "graph_ppi_dgl = ensure_dgl_features_and_labels(graph_ppi_dgl, data_ppi_pyg)\n",
        "\n",
        "# graph_reddit_dgl = RedditDataset()[0]\n",
        "# graph_reddit_dgl = ensure_dgl_features_and_labels(graph_reddit_dgl, data_reddit_pyg)\n",
        "\n",
        "graph_flickr_dgl = FlickrDataset()[0]\n",
        "graph_flickr_dgl = ensure_dgl_features_and_labels(graph_flickr_dgl, data_flickr_pyg)"
      ],
      "metadata": {
        "id": "2Ldjx8S5W8UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets_pyg = {\n",
        "    #'Karate Club': (dataset_karate_pyg, data_karate_pyg),\n",
        "    #'Citeseer': (dataset_citeseer_pyg, data_citeseer_pyg),\n",
        "    #'Cora': (dataset_cora_pyg, data_cora_pyg),\n",
        "    #'Pubmed': (dataset_pubmed_pyg, data_pubmed_pyg),\n",
        "    'Amazon Computers': (dataset_amazon_computers_pyg, data_amazon_computers_pyg),\n",
        "    'Amazon Photo': (dataset_amazon_photo_pyg, data_amazon_photo_pyg),\n",
        "    'Coauthor CS': (dataset_coauthor_cs_pyg, data_coauthor_cs_pyg),\n",
        "    'Coauthor Physics': (dataset_coauthor_physics_pyg, data_coauthor_physics_pyg),\n",
        "    'PPI': (dataset_ppi_pyg, data_ppi_pyg),\n",
        "    #'Reddit': (dataset_reddit_pyg, data_reddit_pyg),\n",
        "    'Flickr': (dataset_flickr_pyg, data_flickr_pyg)\n",
        "}"
      ],
      "metadata": {
        "id": "_J-lV3jKXGqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets_dgl = {\n",
        "    #'Karate Club': graph_karate_dgl,\n",
        "    #'Citeseer': graph_citeseer_dgl,\n",
        "    #'Cora': graph_cora_dgl,\n",
        "    #'Pubmed': graph_pubmed_dgl,\n",
        "    'Amazon Computers': graph_amazon_computers_dgl,\n",
        "    'Amazon Photo': graph_amazon_photo_dgl,\n",
        "    'Coauthor CS': graph_coauthor_cs_dgl,\n",
        "    'Coauthor Physics': graph_coauthor_physics_dgl,\n",
        "    'PPI': graph_ppi_dgl,\n",
        "    #'Reddit': graph_reddit_dgl,\n",
        "    'Flickr': graph_flickr_dgl\n",
        "}"
      ],
      "metadata": {
        "id": "IRytKPMjW8mG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, (ModelPyG, ModelDGL) in models.items():\n",
        "    for dataset_name, (dataset_pyg, data_pyg) in datasets_pyg.items():\n",
        "        # Calculate degree tensor for PyG PNA model\n",
        "        if model_name == 'PNA':\n",
        "            deg = torch_geometric.utils.degree(data_pyg.edge_index[0], data_pyg.num_nodes).float()\n",
        "        for fmt in formats:\n",
        "            if model_name == 'PNA':\n",
        "                model_pyg = ModelPyG(dataset_pyg.num_features, dataset_pyg.num_classes, deg=deg)\n",
        "            else:\n",
        "                model_pyg = ModelPyG(dataset_pyg.num_features, dataset_pyg.num_classes)\n",
        "            time_cpu, mem_cpu = profile_model(model_pyg, data_pyg, device_cpu, format=fmt)\n",
        "            time_gpu, mem_gpu = profile_model(model_pyg, data_pyg, device_gpu, format=fmt)\n",
        "            print(f'PyG {dataset_name} {model_name} ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "            print(f'PyG {dataset_name} {model_name} ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')\n",
        "\n",
        "    for dataset_name, graph_dgl in datasets_dgl.items():\n",
        "        for fmt in formats:\n",
        "            input_dim = graph_dgl.ndata['feat'].shape[1]\n",
        "            output_dim = graph_dgl.ndata['label'].max().item() + 1\n",
        "            model_dgl = ModelDGL(input_dim, output_dim)\n",
        "            time_cpu, mem_cpu = profile_model(model_dgl, graph_dgl, device_cpu, dgl=True, format=fmt)\n",
        "            time_gpu, mem_gpu = profile_model(model_dgl, graph_dgl, device_gpu, dgl=True, format=fmt)\n",
        "            print(f'DGL {dataset_name} {model_name} ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory')\n",
        "            print(f'DGL {dataset_name} {model_name} ({fmt.upper()}) on GPU: {time_gpu:.6f} seconds per iteration, {mem_gpu:.2f} MB peak memory')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e8X7Za4MXNnZ",
        "outputId": "b5c44d73-3499-4083-9584-51623d8a7a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyG Amazon Computers GCN (COO) on CPU: 0.173519 seconds per iteration, 7115.42 MB peak memory\n",
            "PyG Amazon Computers GCN (COO) on GPU: 0.144428 seconds per iteration, 7103.64 MB peak memory\n",
            "PyG Amazon Computers GCN (CSR) on CPU: 0.146450 seconds per iteration, 7103.64 MB peak memory\n",
            "PyG Amazon Computers GCN (CSR) on GPU: 0.147744 seconds per iteration, 7103.64 MB peak memory\n",
            "PyG Amazon Photo GCN (COO) on CPU: 0.064113 seconds per iteration, 7103.64 MB peak memory\n",
            "PyG Amazon Photo GCN (COO) on GPU: 0.074729 seconds per iteration, 7103.64 MB peak memory\n",
            "PyG Amazon Photo GCN (CSR) on CPU: 0.064957 seconds per iteration, 7103.64 MB peak memory\n",
            "PyG Amazon Photo GCN (CSR) on GPU: 0.074434 seconds per iteration, 7103.64 MB peak memory\n",
            "PyG Coauthor CS GCN (COO) on CPU: 0.240318 seconds per iteration, 7103.65 MB peak memory\n",
            "PyG Coauthor CS GCN (COO) on GPU: 0.238295 seconds per iteration, 7103.65 MB peak memory\n",
            "PyG Coauthor CS GCN (CSR) on CPU: 0.231548 seconds per iteration, 7103.65 MB peak memory\n",
            "PyG Coauthor CS GCN (CSR) on GPU: 0.234615 seconds per iteration, 7103.65 MB peak memory\n",
            "PyG Coauthor Physics GCN (COO) on CPU: 0.526010 seconds per iteration, 7136.02 MB peak memory\n",
            "PyG Coauthor Physics GCN (COO) on GPU: 0.519269 seconds per iteration, 7136.02 MB peak memory\n",
            "PyG Coauthor Physics GCN (CSR) on CPU: 0.532442 seconds per iteration, 7136.02 MB peak memory\n",
            "PyG Coauthor Physics GCN (CSR) on GPU: 0.532388 seconds per iteration, 7136.02 MB peak memory\n",
            "PyG PPI GCN (COO) on CPU: 0.027576 seconds per iteration, 7103.65 MB peak memory\n",
            "PyG PPI GCN (COO) on GPU: 0.022332 seconds per iteration, 7103.65 MB peak memory\n",
            "PyG PPI GCN (CSR) on CPU: 0.022517 seconds per iteration, 7103.65 MB peak memory\n",
            "PyG PPI GCN (CSR) on GPU: 0.022008 seconds per iteration, 7103.65 MB peak memory\n",
            "PyG Flickr GCN (COO) on CPU: 0.435791 seconds per iteration, 7186.15 MB peak memory\n",
            "PyG Flickr GCN (COO) on GPU: 0.433755 seconds per iteration, 7204.89 MB peak memory\n",
            "PyG Flickr GCN (CSR) on CPU: 0.453797 seconds per iteration, 7186.15 MB peak memory\n",
            "PyG Flickr GCN (CSR) on GPU: 0.437365 seconds per iteration, 7186.15 MB peak memory\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "DGLError",
          "evalue": "There are 0-in-degree nodes in the graph, output for those nodes will be invalid. This is harmful for some applications, causing silent performance regression. Adding self-loop on the input graph by calling `g = dgl.add_self_loop(g)` will resolve the issue. Setting ``allow_zero_in_degree`` to be `True` when constructing this module will suppress the check and let the code run.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-ac8856f32839>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0moutput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_dgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mmodel_dgl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelDGL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mtime_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprofile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dgl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_dgl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mtime_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprofile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dgl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_dgl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'DGL {dataset_name} {model_name} ({fmt.upper()}) on CPU: {time_cpu:.6f} seconds per iteration, {mem_cpu:.2f} MB peak memory'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-33691815df73>\u001b[0m in \u001b[0;36mprofile_model\u001b[0;34m(model, data, device, dgl, format)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-33691815df73>\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-b959cedb35f5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, features)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dgl/nn/pytorch/conv/graphconv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graph, feat, weight, edge_weight)\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allow_zero_in_degree\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_degrees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                     raise DGLError(\n\u001b[0m\u001b[1;32m    409\u001b[0m                         \u001b[0;34m\"There are 0-in-degree nodes in the graph, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                         \u001b[0;34m\"output for those nodes will be invalid. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDGLError\u001b[0m: There are 0-in-degree nodes in the graph, output for those nodes will be invalid. This is harmful for some applications, causing silent performance regression. Adding self-loop on the input graph by calling `g = dgl.add_self_loop(g)` will resolve the issue. Setting ``allow_zero_in_degree`` to be `True` when constructing this module will suppress the check and let the code run."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K0-NRIeMXaDY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}